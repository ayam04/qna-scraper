[
    {
        "question": "1. Compare a database with Data Warehouse.",
        "answer": "Criteria Database Data Warehouse\nType of data Relational or object-oriented data Large volume with multiple data types\nData operations Transaction processing Data modeling and analysis\nDimensions of data Two-dimensional data Multidimensional data\nData design ER-based and application-oriented database design Star/Snowflake schema and subject-oriented database design\nSize of the data Small (in GB) Large (in TB)\nFunctionality High availability and performance High flexibility and user autonomy\nA database uses a relational model to store data, whereas a Data Warehouse uses various schemas such as star schema and others. In star schema, each dimension is represented by only the one-dimensional table. Data Warehouse supports dimensional modeling, which is a design technique to support end-user queries.\nCheck the full comparison on Data Warehouse vs Database Blog.",
        "reference": "intellipaat.com"
    },
    {
        "question": "2. What is the purpose of cluster analysis in Data Warehousing?",
        "answer": "Cluster analysis is used to define the object without giving the class label. It analyzes all the data that is present in the Data Warehouse and compares the cluster with the cluster that is already running. It performs the task of assigning some set of objects into groups, also known as clusters. It is used to perform the data mining job using a technique like statistical data analysis. It includes all the information and knowledge around many fields such as Machine Learning, pattern recognition, image analysis, and bio-informatics. Cluster analysis performs the iterative process of knowledge discovery and includes trials and failures. It is used with the pre-processing and other parameters to achieve the properties that are desired to be used.\nPurpose of cluster analysis:\nScalability\nAbility to deal with different kinds of attributes\nDiscovery of clusters with attribute shape\nHigh dimensionality\nAbility to deal with noise\nInterpretability\nLearn more about Data Warehousing in this insightful Data Warehouse Tutorial!",
        "reference": "intellipaat.com"
    },
    {
        "question": "3. What is the difference between agglomerative and divisive hierarchical clustering?",
        "answer": "Agglomerative hierarchical clustering method allows clusters to be read from bottom to top so that the program always reads from the sub-component first then moves to the parent; whereas, divisive hierarchical clustering uses top to bottom approach in which the parent is visited first then the child.\nAgglomerative hierarchical method consists of objects in which each object creates its own clusters, and these clusters are grouped together to create a large cluster. It is a process of continuous merging until all the single clusters are merged together into a complete big cluster that will consist of all the objects of child clusters. However, in divisive clustering, the parent cluster is divided into smaller clusters, and it keeps on dividing until each cluster has a single object to represent.\nLearn business analytics from this professional Business Analyst Certification in Bangalore and get started with your career journey.",
        "reference": "intellipaat.com"
    },
    {
        "question": "4. Explain the chameleon method used in Data Warehousing.",
        "answer": "Chameleon is a hierarchical clustering algorithm that overcomes the limitations of the existing models and methods present in Data Warehousing. This method operates on the sparse graph having nodes that represent data items and edges which represent the weights of the data items.\nThis representation allows large datasets to be created and operated successfully. The method finds the clusters that are used in the dataset using the two-phase algorithm.\nThe first phase consists of the graph partitioning that allows the clustering of the data items into a large number of sub-clusters.\nThe second phase uses an agglomerative hierarchical clustering algorithm to search for the clusters that are genuine and can be combined together with the sub-clusters that are produced.\nInterested in learning more about Data Warehousing? Well, we have an informative blog on Data Warehousing!\nGet 100% Hike!\nMaster Most in Demand Skills Now !\nBy providing your contact details, you agree to our Terms of Use & Privacy Policy",
        "reference": "intellipaat.com"
    },
    {
        "question": "5. What is Virtual Data Warehousing?",
        "answer": "A Virtual Data Warehouse provides a collective view of the completed data. A Virtual Data Warehouse has no historic data. It can be considered as a logical data model of the given metadata.\nVirtual Data Warehousing is a \u2018de facto\u2019 information system strategy for supporting analytical decision-making. It is one of the best ways for translating raw data and presenting it in the form that can be used by decision-makers. It provides a semantic map\u2014which allows the end user for viewing as virtualized.\nWatch this video on Data Warehouse Interview Questions and Answers:\n\n\nThinking of Learning Power BI? Here is the Power BI Certification provided by Intellpaat.",
        "reference": "intellipaat.com"
    },
    {
        "question": "6. What is Active Data Warehousing?",
        "answer": "An Active Data Warehouse represents a single state of a business. Active Data Warehousing considers the analytic perspectives of customers and suppliers. It helps deliver the updated data through reports.\nA form of repository of captured transactional data is known as \u2018Active Data Warehousing.\u2019 Using this concept, trends and patterns are found to be used for future decision-making. Active Data Warehouse has a feature which can integrate the changes of data while scheduled cycles refresh. Enterprises utilize an Active Data Warehouse in drawing the company\u2019s image in a statistical manner.\nCheck out the ETL Interview Questions and Answers to prepare for your next interview.",
        "reference": "intellipaat.com"
    },
    {
        "question": "7. What is a snapshot with reference to Data Warehouse?",
        "answer": "A snapshot refers to a complete visualization of data at the time of extraction. It occupies less space and can be used to back up and restore data quickly.\nA snapshot is a process of knowing about the activities performed. It is stored in a report format from a specific catalog. The report is generated soon after the catalog is disconnected.",
        "reference": "intellipaat.com"
    },
    {
        "question": "8. What is XMLA?",
        "answer": "XMLA is XML for Analysis which can be considered as a standard for accessing data in OLAP, data mining, or data sources on the Internet. It is Simple Object Access Protocol. XMLA uses \u2018Discover\u2019 and \u2018Execute\u2019 methods. Discover fetches information from the Internet, while \u2018Execute\u2019 allows the applications to execute against the data sources.\nXMLA is an industry standard for accessing data in analytical systems, such as OLAP. It is based on XML, SOAP, and HTTP.\nXMLA specifies MDXML as a query language. In the XMLA 1.1 version, the only construct in the MDXML is an MDX statement enclosed in the tag.\n\nIntermediate Data Warehouse Interview Questions and Answers",
        "reference": "intellipaat.com"
    },
    {
        "question": "9. What is ODS?",
        "answer": "An operational data store (ODS) is a database designed to integrate data from multiple sources for additional operations on the data. Unlike a master data store, the data is not sent back to operational systems. It may be passed for further operations and to the Data Warehouse for reporting.\nIn ODS, data can be scrubbed, resolved for redundancy, and checked for compliance with the corresponding business rules. This data store can be used for integrating disparate data from multiple sources so that business operations, analysis, and reporting can be carried out. This is the place where most of the data used in the current operation is housed before it\u2019s transferred to the Data Warehouse for longer-term storage or archiving.\nAn ODS is designed for relatively simple queries on small amounts of data (such as finding the status of a customer order), rather than the complex queries on large amounts of data typical of the Data Warehouse.\nAn ODS is similar to the short-term memory where it only stores very recent information. On the contrary, the Data Warehouse is more like long-term memory, storing relatively permanent information.\nWant to learn more about SQL? Here is the Online Microsoft SQL training provided by Intellipaat.",
        "reference": "intellipaat.com"
    },
    {
        "question": "10. What is the level of granularity of a fact table?",
        "answer": "A fact table is usually designed at a low level of granularity. This means that we need to find the lowest level of information that can be stored in a fact table  e.g., employee performance is a very high level of granularity. Employee_performance_daily and employee_perfomance_weekly can be considered as lower levels of granularity.\nThe granularity is the lowest level of information stored in the fact table. The depth of the data level is known as granularity. In date dimension, the level could be year, month, quarter, period, week, and day of granularity.\nThe process consists of the following two steps:\nDetermining the dimensions that are to be included\nDetermining the location to find the hierarchy of each dimension of the information\nThe above factors of determination will be re-sent as per the requirements.",
        "reference": "intellipaat.com"
    },
    {
        "question": "11. What is the difference between \u2018view\u2019 and \u2018materialized view\u2019?",
        "answer": "View:\nTail raid data representation is provided with a view to access data from its table.\nIt has logical structure that does not occupy space.\nChanges get affected in the corresponding tables.\nMaterialized view:\nPre-calculated data persists in the materialized view.\nIt has physical data space occupation.\nChanges will not get affected in the corresponding tables.\nEven check the difference between Data Lake and Data Warehouse.",
        "reference": "intellipaat.com"
    },
    {
        "question": "12. What is junk dimension?",
        "answer": "In scenarios where certain data may not be appropriate to store in the schema, the data (or attributes) can be stored in a junk dimension. The nature of the data of junk dimension is usually Boolean or flag values.\nA single dimension is formed by lumping a number of small dimensions. This is called a junk dimension. Junk dimension has unrelated attributes. The process of grouping random flags and text attributes in a dimension by transmitting them to a distinguished sub-dimension is related to junk dimension.",
        "reference": "intellipaat.com"
    },
    {
        "question": "13. What are the different types of SCDs used in Data Warehousing?",
        "answer": "SCDs (slowly changing dimensions) are the dimensions in which the data changes slowly, rather than changing regularly on a time basis.\nThree types of SCDs are used in Data Warehousing:\nSCD1: It is a record that is used to replace the original record even when there is only one record existing in the database. The current data will be replaced and the new data will take its place.\nSCD2: It is the new record file that is added to the dimension table. This record exists in the database with the current data and the previous data that is stored in the history.\nSCD3: This uses the original data that is modified to the new data. This consists of two records: one record that exists in the database and another record that will replace the old database record with the new information.",
        "reference": "intellipaat.com"
    },
    {
        "question": "14. Which one is faster, Multidimensional OLAP or Relational OLAP?",
        "answer": "Multidimensional OLAP (MOLAP) is faster than Relational OLAP (ROLAP).\nMOLAP: Here, data is stored in a multidimensional cube. The storage is not in the relational database but in proprietary formats (one example is PowerOLAP\u2019s .olp file). MOLAP products are compatible with Excel, which can make data interactions easy to learn.\nROLAP: ROLAP products access a relational database by using SQL (structured query language), which is the standard language that is used to define and manipulate data in an RDBMS. Subsequent processing may occur in the RDBMS or within a mid-tier server, which accepts requests from clients, translates them into SQL statements, and passes them on to the RDBMS.",
        "reference": "intellipaat.com"
    },
    {
        "question": "15. What is Hybrid SCD?",
        "answer": "Hybrid SCDs are a combination of both SCD1 and SCD2.\nIt may happen that in a table, some columns are important and we need to track changes for them, i.e., capture the historical data for them, whereas in some columns even if the data changes we do not have to bother. For such tables, we implement Hybrid SCDs, wherein some columns are Type 1 and some are Type 2.",
        "reference": "intellipaat.com"
    },
    {
        "question": "16. Why do we override the execute method in Struts?",
        "answer": "As part of Struts Framework, we can develop the Action Servlets and the ActionForm Servlets and other servlet classes.\nIn case of ActionForm class, we can develop the validate() method. This method will return the ActionErrors object. In this method, we can write the validation code.\nIf this method returns null or ActionErrors with size = 0, the web container will call execute() as part of the Action class.\nIf it returns size > 0, it will not call the execute() method. It will rather execute the jsp, servlet, or html file as the value for the input attribute as part of the attribute in the struts-config.xml file.\n\nAdvanced Data Warehouse Interview Questions and Answers for Experienced",
        "reference": "intellipaat.com"
    },
    {
        "question": "17. What is VLDB?",
        "answer": "A very large database (VLDB) is a database that contains an extremely large number of tuples (database rows) or occupies an extremely large physical file system storage space. A one terabyte database would normally be considered to be a VLDB.",
        "reference": "intellipaat.com"
    },
    {
        "question": "18. How do you load the time dimension?",
        "answer": "Time dimensions are usually loaded by a program that loops through all possible dates appearing in the data. It is not unusual for 100 years to be represented in a time dimension, with one row per day.",
        "reference": "intellipaat.com"
    },
    {
        "question": "19. What are conformed dimensions?",
        "answer": "Conformed dimensions are the dimensions which can be used across multiple data marts in combination with multiple fact tables accordingly.\nA conformed dimension is a dimension that has exactly the same meaning and content when being referred from different fact tables. It can refer to multiple tables in multiple data marts within the same organization.",
        "reference": "intellipaat.com"
    },
    {
        "question": "20. What is the main difference between Inmon and Kimball philosophies of Data Warehousing?",
        "answer": "Both differ in the concept of building the Data Warehouse.\nKimball views Data Warehousing as a constituency of data marts. Data marts are focused on delivering business objectives for departments in an organization, and the Data Warehouse is a conformed dimension of the data marts. Hence, a unified view of the enterprise can be obtained from the dimension modeling on a local departmental level.\nInmon explains in creating a Data Warehouse on a subject-by-subject area basis. Hence, the development of the Data Warehouse can start with data from the online store. Other subject areas can be added to the Data Warehouse as their needs arise. Point-of-sale (POS) data can be added later if management decides that it is necessary.\nHence, the process will be as follows:\nKimball > First Data Marts > Combined Ways > Data Warehouse\nInmon > First Data Warehouse > Data marts\nTake charge of your career by visiting our professionally designed Community!",
        "reference": "intellipaat.com"
    },
    {
        "question": "21. What is the difference between a data warehouse and a data mart?",
        "answer": "A data warehouse is a set of data isolated from operational systems. This helps an organization deal with its decision-making process. A data mart is a subset of a data warehouse that is geared to a particular business line. Data marts provide the stock of condensed data collected in the organization for research on a particular field or entity.\nA data warehouse typically has a size greater than 100 GB, while the size of a data mart is generally less than 100 GB. Due to the disparity in scope, the design and utility of data marts are comparatively simpler.\nHere, check out our comparison blog on data mart and data warehouse!",
        "reference": "intellipaat.com"
    },
    {
        "question": "22. Explain the ETL cycle's 3-layer architecture.",
        "answer": "The staging layer, the data integration layer, and the access layer are the three layers that are involved in an ETL cycle.\nStaging layer: It is used to store the data extracted from various data structures of the source.\nData integration layer: Data from the staging layer is transformed and transferred to the database using the integration layer. The data is arranged into hierarchical groups (often referred to as dimensions), facts, and aggregates. In a DW system, the combination of facts and dimensions tables is called a schema.\nAccess layer: For analytical reporting, end-users use the access layer to retrieve the data.",
        "reference": "intellipaat.com"
    },
    {
        "question": "23. What does data purging mean?",
        "answer": "Data purging is a process, involving methods that can erase data permanently from the storage. Several techniques and strategies are used for data purging.\nThe process of data purging often contrasts with data deletion. Deleting data is more of a temporary process, while data purging permanently removes data. This, in turn, frees up storage and/or memory space, which can be utilized for other purposes.\nThe purging process allows us to archive data even if it is permanently removed from the main source, giving us an option to retrieve the data from the archive if it is needed. The deleting process also permanently removes the data but does not necessarily involve keeping a backup, and it generally involves insignificant amounts of data.",
        "reference": "intellipaat.com"
    },
    {
        "question": "24. Can you define the five main testing phases of a project?",
        "answer": "The ETL test is performed in five stages as follows:\nThe identification of data sources and requirements\nThe acquisition of data\nImplementing business logic and dimensional modeling\nBuilding and publishing data\nReports building",
        "reference": "intellipaat.com"
    }
]