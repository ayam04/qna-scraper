[
    {
        "question": "1. How to do maintenance activity on the K8 node?",
        "answer": "Whenever there are security patches available the Kubernetes administrator has to perform the maintenance task to apply the security patch to the running container in order to prevent it from vulnerability, which is often an unavoidable part of the administration. The following two commands are useful to safely drain the K8s node. kubectl cordon\nkubectl drain \u2013ignore-daemon set kubectl cordon kubectl drain \u2013ignore-daemon set The first command moves the node to maintenance mode or makes the node unavailable, followed by kubectl drain which will finally discard the pod from the node. After the drain command is a success you can perform maintenance. Note: If you wish to perform maintenance on a single pod following two commands can be issued in order: kubectl get nodes: to list all the nodes\nkubectl drain <node name>: drain a particular node kubectl get nodes: to list all the nodes kubectl drain <node name>: drain a particular node",
        "reference": "interviewbit.com"
    },
    {
        "question": "2. How to get the central logs from POD?",
        "answer": "This architecture depends upon the application and many other factors. Following are the common logging patterns Node level logging agent.\nStreaming sidecar container.\nSidecar container with the logging agent.\nExport logs directly from the application. Node level logging agent. Streaming sidecar container. Sidecar container with the logging agent. Export logs directly from the application. In the setup, journalbeat and filebeat are running as daemonset. Logs collected by these are dumped to the kafka topic which is eventually dumped to the ELK stack. The same can be achieved using EFK stack and fluentd-bit.",
        "reference": "interviewbit.com"
    },
    {
        "question": "3. How to monitor the Kubernetes cluster?",
        "answer": "Prometheus is used for Kubernetes monitoring. The Prometheus ecosystem consists of multiple components. Mainly Prometheus server which scrapes and stores time-series data.\nClient libraries for instrumenting application code.\nPush gateway for supporting short-lived jobs.\nSpecial-purpose exporters for services like StatsD, HAProxy, Graphite, etc.\nAn alert manager to handle alerts on various support tools. Mainly Prometheus server which scrapes and stores time-series data. Client libraries for instrumenting application code. Push gateway for supporting short-lived jobs. Special-purpose exporters for services like StatsD, HAProxy, Graphite, etc. An alert manager to handle alerts on various support tools.",
        "reference": "interviewbit.com"
    },
    {
        "question": "4. What are the various things that can be done to increase Kubernetes security?",
        "answer": "By default, POD can communicate with any other POD, we can set up network policies to limit this communication between the PODs. RBAC (Role-based access control) to narrow down the permissions.\nUse namespaces to establish security boundaries.\nSet the admission control policies to avoid running the privileged containers.\nTurn on audit logging. RBAC (Role-based access control) to narrow down the permissions. Use namespaces to establish security boundaries. Set the admission control policies to avoid running the privileged containers. Turn on audit logging.",
        "reference": "interviewbit.com"
    },
    {
        "question": "5. What is the role of Load Balance in Kubernetes?",
        "answer": "Load balancing is a way to distribute the incoming traffic into multiple backend servers, which is useful to ensure the application available to the users. Load Balancer  Load Balancer In Kubernetes, as shown in the above figure all the incoming traffic lands to a single IP address on the load balancer which is a way to expose your service to outside the internet which routes the incoming traffic to a particular pod (via service) using an algorithm known as round-robin. Even if any pod goes down load balances are notified so that the traffic is not routed to that particular unavailable node. Thus load balancers in Kubernetes are responsible for distributing a set of tasks (incoming traffic) to the pods",
        "reference": "interviewbit.com"
    },
    {
        "question": "6. What\u2019s the init container and when it can be used?",
        "answer": "init containers will set a stage for you before running the actual POD. Wait for some time before starting the app Container with a command like sleep 60. Clone a git repository into a volume.",
        "reference": "interviewbit.com"
    },
    {
        "question": "7. What is PDB (Pod Disruption Budget)?",
        "answer": "A Kubernetes administrator can create a deployment of a kind: PodDisruptionBudget for high availability of the application, it makes sure that the minimum number is running pods are respected as mentioned by the attribute minAvailable spec file. This is useful while performing a drain where the drain will halt until the PDB is respected to ensure the High Availability(HA) of the application. The following spec file also shows minAvailable as 2 which implies the minimum number of an available pod (even after the election). Example: YAML Config using minAvailable => apiVersion: policy/v1beta1\nkind: PodDisruptionBudget\nmetadata:\n name: zk-pdb\nspec:\n minAvailable: 2\n selector:\n   matchLabels:\n     app: zookeeper apiVersion: policy/v1beta1\nkind: PodDisruptionBudget\nmetadata:\n name: zk-pdb\nspec:\n minAvailable: 2\n selector:\n   matchLabels:\n     app: zookeeper",
        "reference": "interviewbit.com"
    },
    {
        "question": "8. What are the various K8's services running on nodes and describe the role of each service?",
        "answer": "Mainly K8 cluster consists of two types of nodes, executor and master. Executor node: (This runs on master node) Executor node: (This runs on master node) Kube-proxy: This service is responsible for the communication of pods within the cluster and to the outside network, which runs on every node. This service is responsible to maintain network protocols when your pod establishes a network communication.\nkubelet: Each node has a running kubelet service that updates the running node accordingly with the configuration(YAML or JSON) file. NOTE: kubelet service is only for containers created by Kubernetes. Kube-proxy: This service is responsible for the communication of pods within the cluster and to the outside network, which runs on every node. This service is responsible to maintain network protocols when your pod establishes a network communication. kubelet: Each node has a running kubelet service that updates the running node accordingly with the configuration(YAML or JSON) file. NOTE: kubelet service is only for containers created by Kubernetes. Master services: Master services: Kube-apiserver: Master API service which acts as an entry point to K8 cluster.\nKube-scheduler: Schedule PODs according to available resources on executor nodes.\nKube-controller-manager:  is a control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired stable state Kube-apiserver: Master API service which acts as an entry point to K8 cluster. Kube-scheduler: Schedule PODs according to available resources on executor nodes. Kube-controller-manager:  is a control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired stable state",
        "reference": "interviewbit.com"
    },
    {
        "question": "9. How do we control the resource usage of POD?",
        "answer": "With the use of limit and request resource usage of a POD can be controlled. Request: The number of resources being requested for a container. If a container exceeds its request for resources, it can be throttled back down to its request. Limit: An upper cap on the resources a single container can use. If it tries to exceed this predefined limit it can be terminated if K8's decides that another container needs these resources. If you are sensitive towards pod restarts, it makes sense to have the sum of all container resource limits equal to or less than the total resource capacity for your cluster. Example: Example: apiVersion: v1\nkind: Pod\nmetadata:\n name: demo\nspec:\n containers:\n - name: example1\n image:example/example1\n resources:\n   requests:\n     memory: \"_Mi\"\n     cpu: \"_m\"\n   limits:\n     memory: \"_Mi\"\n     cpu: \"_m\" apiVersion: v1\nkind: Pod\nmetadata:\n name: demo\nspec:\n containers:\n - name: example1\n image:example/example1\n resources:\n   requests:\n     memory: \"_Mi\"\n     cpu: \"_m\"\n   limits:\n     memory: \"_Mi\"\n     cpu: \"_m\"",
        "reference": "interviewbit.com"
    },
    {
        "question": "1. What is Ingress Default Backend?",
        "answer": "It specifies what to do with an incoming request to the Kubernetes cluster that isn't mapped to any backend i.e what to do when no rules being defined for the incoming HTTP request If the default backend service is not defined, it's recommended to define it so that users still see some kind of message instead of an unclear error.",
        "reference": "interviewbit.com"
    },
    {
        "question": "2. What is GKE?",
        "answer": "GKE is Google Kubernetes Engine that is used for managing and orchestrating systems for Docker containers. With the help of Google Public Cloud, we can also orchestrate the container cluster.",
        "reference": "interviewbit.com"
    },
    {
        "question": "3. What is the purpose of operators?",
        "answer": "As compared to stateless applications, achieving desired status changes and upgrades are handled the same way for every replica, managing Kubernetes applications is more challenging. The stateful nature of stateful applications may require different handling for upgrading each replica, as each replica might be in a different state. Therefore, managing stateful applications often requires a human operator. This is supposed to be assisted by Kubernetes Operator. Moreover, this will pave the way for a standard process to be automated across several Kubernetes clusters.",
        "reference": "interviewbit.com"
    },
    {
        "question": "4. What is an Operator?",
        "answer": "As an extension to K8, the operator provides the capability of managing applications and their components using custom resources. Operators generally comply with all the principles relating to Kubernetes, especially those relating to the control loops.",
        "reference": "interviewbit.com"
    },
    {
        "question": "5. What service and namespace are referred to in the following file?",
        "answer": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: some-configmap\ndata:\n  some_url: silicon.chip apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: some-configmap\ndata:\n  some_url: silicon.chip It is clear from the above file that the service \u201csilicon\u201d is a reference to a namespace called \u201cchip\u201d.",
        "reference": "interviewbit.com"
    },
    {
        "question": "6. Why should namespaces be used? How does using the default namespace cause problems?",
        "answer": "Over the course of time, using the default namespace alone is proving to be difficult, since you are unable to get a good overview of all the applications you can manage within the cluster as a whole. The namespaces allow applications to be organized into groups that make sense, such as a namespace for all monitoring applications and another for all security applications. Additionally, namespaces can be used for managing Blue/Green environments, in which each namespace contains its own version of an app as well as sharing resources with other namespaces (such as logging or monitoring). It is also possible to have one cluster with multiple teams using namespaces. The use of the same cluster by multiple teams may lead to conflict.  Suppose they end up creating an app that has the same name, this means that one team will override the app created by the other team as Kubernetes prohibits two apps with the same name (within the same namespace).",
        "reference": "interviewbit.com"
    },
    {
        "question": "7. How should TLS be configured with Ingress?",
        "answer": "Add tls and secretName entries. spec:\n tls:\n - hosts:\n   - some_app.com\n   secretName: someapp-secret-tls spec:\n tls:\n - hosts:\n   - some_app.com\n   secretName: someapp-secret-tls",
        "reference": "interviewbit.com"
    },
    {
        "question": "8. Complete the following configurationspec file to make it Ingress",
        "answer": "metadata:\n  name: someapp-ingress\nspec: metadata:\n  name: someapp-ingress\nspec: Explanation - Explanation - One of the several ways to answer this question. apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n name: someapp-ingress\nspec:\n rules:\n - host: my.host\n   http:\n     paths:\n     - backend:\n         serviceName: someapp-internal-service\n         servicePort: 8080 apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n name: someapp-ingress\nspec:\n rules:\n - host: my.host\n   http:\n     paths:\n     - backend:\n         serviceName: someapp-internal-service\n         servicePort: 8080",
        "reference": "interviewbit.com"
    },
    {
        "question": "9. How to turn the service defined below in the spec into an external one?",
        "answer": "spec:\n  selector:\n    app: some-app\n  ports:\n    - protocol: UDP\n      port: 8080\n      targetPort: 8080 spec:\n  selector:\n    app: some-app\n  ports:\n    - protocol: UDP\n      port: 8080\n      targetPort: 8080 Explanation - Explanation - Adding type: LoadBalancer and nodePort as follows: spec:\n selector:\n   app: some-app\n type: LoadBalancer\n ports:\n   - protocol: UDP\n     port: 8080\n     targetPort: 8080\n     nodePort: 32412 spec:\n selector:\n   app: some-app\n type: LoadBalancer\n ports:\n   - protocol: UDP\n     port: 8080\n     targetPort: 8080\n     nodePort: 32412",
        "reference": "interviewbit.com"
    },
    {
        "question": "1. How to troubleshoot if the POD is not getting scheduled?",
        "answer": "In K8\u2019s scheduler is responsible to spawn pods into nodes. There are many factors that can lead to unstartable POD. The most common one is running out of resources, use the commands like kubectl describe <POD> -n <Namespace> to see the reason why POD is not started. Also, keep an eye on kubectl to get events to see all events coming from the cluster.",
        "reference": "interviewbit.com"
    },
    {
        "question": "2. How can we forward the port '8080 (container) -> 8080 (service) -> 8080 (ingress) -> 80 (browser)and how it can be done?",
        "answer": "The ingress is exposing port 80 externally for the browser to access, and connecting to a service that listens on 8080. The ingress will listen on port 80 by default. An \"ingress controller\" is a pod that receives external traffic and handles the ingress and is configured by an ingress resource For this you need to configure the ingress selector and if no 'ingress controller selector' is mentioned then no ingress controller will manage the ingress. Simple ingress Config will look like host: abc.org\nhttp:\npaths:\nbackend:\nserviceName: abc-service\nservicePort: 8080\nThen the service will look like\nkind: Service\napiVersion: v1\nmetadata:\nname: abc-service\nspec:\nports:\nprotocol: TCP\nport: 8080 # port to which the service listens to\ntargetPort: 8080 host: abc.org\nhttp:\npaths:\nbackend:\nserviceName: abc-service\nservicePort: 8080\nThen the service will look like\nkind: Service\napiVersion: v1\nmetadata:\nname: abc-service\nspec:\nports:\nprotocol: TCP\nport: 8080 # port to which the service listens to\ntargetPort: 8080 Additional Resources Kubernetes Vs Openshift Kubernetes Vs Openshift Kubernetes Cheat Sheet Kubernetes Cheat Sheet Kubectl Commands Kubectl Commands Kubernetes vs Docker Kubernetes vs Docker",
        "reference": "interviewbit.com"
    },
    {
        "question": "3. What are the different ways to provide external network connectivity to K8?",
        "answer": "By default, POD should be able to reach the external network but vice-versa we need to make some changes. Following options are available to connect with POD from the outer world. Nodeport (it will expose one port on each node to communicate with it)\nLoad balancers (L4 layer of TCP/IP protocol)\nIngress (L7 layer of TCP/IP Protocol) Nodeport (it will expose one port on each node to communicate with it) Load balancers (L4 layer of TCP/IP protocol) Ingress (L7 layer of TCP/IP Protocol) Another method is to use Kube-proxy which can expose a service with only cluster IP on the local system port. $ kubectl proxy --port=8080 $ http://localhost:8080/api/v1/proxy/namespaces//services/:/ $ $",
        "reference": "interviewbit.com"
    },
    {
        "question": "4. How to run a POD on a particular node?",
        "answer": "Various methods are available to achieve it. nodeName: specify the name of a node in POD spec configuration, it will try to run the POD on a specific node.\nnodeSelector: Assign a specific label to the node which has special resources and use the same label in POD spec so that POD will run only on that node.\nnodeaffinities: required DuringSchedulingIgnoredDuringExecution, preferredDuringSchedulingIgnoredDuringExecution are hard and soft requirements for running the POD on specific nodes. This will be replacing nodeSelector in the future. It depends on the node labels. nodeName: specify the name of a node in POD spec configuration, it will try to run the POD on a specific node. nodeSelector: Assign a specific label to the node which has special resources and use the same label in POD spec so that POD will run only on that node. nodeaffinities: required DuringSchedulingIgnoredDuringExecution, preferredDuringSchedulingIgnoredDuringExecution are hard and soft requirements for running the POD on specific nodes. This will be replacing nodeSelector in the future. It depends on the node labels.",
        "reference": "interviewbit.com"
    },
    {
        "question": "5. Can you explain the differences between Docker Swarm and Kubernetes?",
        "answer": "Below are the main difference between Kubernetes and Docker: The installation procedure of the K8s is very complicated but if it is once installed then the cluster is robust. On the other hand, the Docker swarm installation process is very simple but the cluster is not at all robust.\nKubernetes can process the auto-scaling but the Docker swarm cannot process the auto-scaling of the pods based on incoming load.\nKubernetes is a full-fledged Framework. Since it maintains the cluster states more consistently so autoscaling is not as fast as Docker Swarm. The installation procedure of the K8s is very complicated but if it is once installed then the cluster is robust. On the other hand, the Docker swarm installation process is very simple but the cluster is not at all robust. Kubernetes can process the auto-scaling but the Docker swarm cannot process the auto-scaling of the pods based on incoming load. Kubernetes is a full-fledged Framework. Since it maintains the cluster states more consistently so autoscaling is not as fast as Docker Swarm.",
        "reference": "interviewbit.com"
    },
    {
        "question": "6. What the following in the Deployment configuration file mean?",
        "answer": "spec:\n  containers:\n    - name: USER_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: some-secret\n          key: password spec:\n  containers:\n    - name: USER_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: some-secret\n          key: password Explanation - Explanation - USER_PASSWORD environment variable will store the value from the password key in the secret called \"some-secret\" In other words, you reference a value from a Kubernetes Secret. USER_PASSWORD",
        "reference": "interviewbit.com"
    },
    {
        "question": "7. What is Kubernetes Load Balancing?",
        "answer": "Load Balancing is one of the most common and standard ways of exposing the services. There are two types of load balancing in K8s and they are: Internal load balancer \u2013 This type of balancer automatically balances loads and allocates the pods with the required incoming load. Internal load balancer \u2013 External Load Balancer \u2013 This type of balancer directs the traffic from the external loads to backend pods. External Load Balancer \u2013",
        "reference": "interviewbit.com"
    },
    {
        "question": "8. How to run Kubernetes locally?",
        "answer": "Kubernetes can be set up locally using the Minikube tool. It runs a single-node bunch in a VM on the computer. Therefore, it offers the perfect way for users who have just ongoing learning Kubernetes.",
        "reference": "interviewbit.com"
    }
]