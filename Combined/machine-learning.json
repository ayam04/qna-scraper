[
    {
        "question": "1. What are Different Kernels in SVM?",
        "answer": "There are six types of kernels in SVM: Linear kernel - used when data is linearly separable. \nPolynomial kernel - When you have discrete data that has no natural notion of smoothness.\nRadial basis kernel - Create a decision boundary able to do a much better job of separating two classes than the linear kernel.\nSigmoid kernel - used as an activation function for neural networks. Linear kernel - used when data is linearly separable. Polynomial kernel - When you have discrete data that has no natural notion of smoothness. Radial basis kernel - Create a decision boundary able to do a much better job of separating two classes than the linear kernel. Sigmoid kernel - used as an activation function for neural networks.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "2. Why was Machine Learning Introduced?",
        "answer": "The simplest answer is to make our lives easier. In the early days of “intelligent” applications, many systems used hardcoded rules of “if” and “else” decisions to process data or adjust the user input. Think of a spam filter whose job is to move the appropriate incoming email messages to a spam folder. But with the machine learning algorithms, we are given ample information for the data to learn and identify the patterns from the data. Unlike the normal problems we don’t need to write the new rules for each problem in machine learning, we just need to use the same workflow but with a different dataset. Let’s talk about Alan Turing, in his 1950 paper, “Computing Machinery and Intelligence”, Alan asked, “Can machines think?” Full paper here here The paper describes the “Imitation Game”, which includes three participants - Human acting as a judge,\nAnother human, and\nA computer is an attempt to convince the judge that it is human. Human acting as a judge, Another human, and A computer is an attempt to convince the judge that it is human. The judge asks the other two participants to talk. While they respond the judge needs to decide which response came from the computer. If the judge could not tell the difference the computer won the game. The test continues today as an annual competition in artificial intelligence. The aim is simple enough: convince the judge that they are chatting to a human instead of a computer chatbot program.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "3. Explain the Difference Between Classification and Regression?",
        "answer": "Classification is used to produce discrete results, classification is used to classify data into some specific categories.\nFor example, classifying emails into spam and non-spam categories.  Whereas, regression deals with continuous data.\nFor example, predicting stock prices at a certain point in time.  Classification is used to predict the output into a group of classes. \nFor example, Is it Hot or Cold tomorrow?  Whereas, regression is used to predict the relationship that data represents. \nFor example, What is the temperature tomorrow? ",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "4. What is Bias in Machine Learning?",
        "answer": "Bias in data tells us there is inconsistency in data. The inconsistency may occur for several reasons which are not mutually exclusive. For example, a tech giant like Amazon to speed the hiring process they build one engine where they are going to give 100 resumes, it will spit out the top five, and hire those. When the company realized the software was not producing gender-neutral results it was tweaked to remove this bias.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "5. What is Cross-Validation?",
        "answer": "Cross-validation is a method of splitting all your data into three parts: training, testing, and validation data. Data is split into k subsets, and the model has trained on k-1of those datasets. The last subset is held for testing. This is done for each of the subsets. This is k-fold cross-validation. Finally, the scores from all the k-folds are averaged to produce the final score. Cross-validation  Cross-validation",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "6. What are Support Vectors in SVM?",
        "answer": "A Support Vector Machine (SVM) is an algorithm that tries to fit a line (or plane or hyperplane) between the different classes that maximizes the distance from the line to the points of the classes. In this way, it tries to find a robust separation between the classes. The Support Vectors are the points of the edge of the dividing hyperplane as in the below figure. Support Vector Machine (SVM)  Support Vector Machine (SVM)",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "7. Explain SVM Algorithm in Detail",
        "answer": "A Support Vector Machine (SVM) is a very powerful and versatile supervised machine learning model, capable of performing linear or non-linear classification, regression, and even outlier detection. Suppose we have given some data points that each belong to one of two classes, and the goal is to separate two classes based on a set of examples. In SVM, a data point is viewed as a p-dimensional vector (a list of p numbers), and we wanted to know whether we can separate such points with a (p-1)-dimensional hyperplane. This is called a linear classifier. There are many hyperplanes that classify the data. To choose the best hyperplane that represents the largest separation or margin between the two classes. \nIf such a hyperplane exists, it is known as a maximum-margin hyperplane and the linear classifier it defines is known as a maximum margin classifier. The best hyperplane that divides the data in H3  We have data (x1, y1), ..., (xn, yn), and different features (xii, ..., xip), and yiis either 1 or -1. The equation of the hyperplane H3 is the set of points satisfying: w. x-b = 0 Where w is the normal vector of the hyperplane. The parameter b||w||determines the offset of the hyperplane from the original along the normal vector w So for each i, either xiis in the hyperplane of 1 or -1. Basically, xisatisfies: w . xi - b = 1  or   w. xi - b = -1 Support Vector Machine (SVM)  Support Vector Machine (SVM)",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "8. What is PCA? When do you use it?",
        "answer": "Principal component analysis (PCA) is most commonly used for dimension reduction. In this case, PCA measures the variation in each variable (or column in the table). If there is little variation, it throws the variable out, as illustrated in the figure below: Principal component analysis (PCA)  Principal component analysis (PCA) Thus making the dataset easier to visualize. PCA is used in finance, neuroscience, and pharmacology. It is very useful as a preprocessing step, especially when there are linear correlations between features.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "9. What is ‘Naive’ in a Naive Bayes?",
        "answer": "The Naive Bayes method is a supervised learning algorithm, it is naive since it makes assumptions by applying Bayes’ theorem that all attributes are independent of each other. Bayes’ theorem states the following relationship, given class variable y and dependent vector x1  through xn: P(yi | x1,..., xn) =P(yi)P(x1,..., xn | yi)(P(x1,..., xn) Using the naive conditional independence assumption that each xiis independent: for all I this relationship is simplified to: P(xi | yi, x1, ..., xi-1, xi+1, ...., xn) = P(xi | yi) Since, P(x1,..., xn) is a constant given the input, we can use the following classification rule: P(yi | x1, ..., xn) = P(y) ni=1P(xi | yi)P(x1,...,xn) and we can also use Maximum A Posteriori (MAP) estimation to estimate P(yi)and P(yi | xi) the former is then the relative frequency of class yin the training set. P(yi | x1,..., xn)  P(yi) ni=1P(xi | yi) y = arg max P(yi)ni=1P(xi | yi) The different naive Bayes classifiers mainly differ by the assumptions they make regarding the distribution of P(yi | xi): can be Bernoulli, binomial, Gaussian, and so on.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "10. What is Unsupervised Learning?",
        "answer": "Unsupervised learning is also a type of machine learning algorithm used to find patterns on the set of data given. In this, we don’t have any dependent variable or label to predict. Unsupervised Learning Algorithms: Clustering, \nAnomaly Detection, \nNeural Networks and Latent Variable Models. Clustering, Anomaly Detection, Neural Networks and Latent Variable Models. Example: Example: In the same example, a T-shirt clustering will categorize as “collar style and V neck style”, “crew neck style” and “sleeve types”.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "11. What is Supervised Learning?",
        "answer": "Supervised learning is a machine learning algorithm of inferring a function from labeled training data. The training data consists of a set of training examples. Example: 01 Example: 01 Knowing the height and weight identifying the gender of the person. Below are the popular supervised learning algorithms. Support Vector Machines\nRegression\nNaive Bayes\nDecision Trees\nK-nearest Neighbour Algorithm and Neural Networks. Support Vector Machines Regression Naive Bayes Decision Trees K-nearest Neighbour Algorithm and Neural Networks. Example: 02 Example: 02 If you build a T-shirt classifier, the labels will be “this is an S, this is an M and this is L”, based on showing the classifier examples of S, M, and L.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "12. What are Different Types of Machine Learning algorithms?",
        "answer": "There are various types of machine learning algorithms. Here is the list of them in a broad category based on: Whether they are trained with human supervision (Supervised, unsupervised, reinforcement learning)\nThe criteria in the below diagram are not exclusive, we can combine them any way we like. Whether they are trained with human supervision (Supervised, unsupervised, reinforcement learning) The criteria in the below diagram are not exclusive, we can combine them any way we like. Types of Machine Learning algorithms  Types of Machine Learning algorithms",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "1. What is F1 score? How would you use it?",
        "answer": "Let’s have a look at this table before directly jumping into the F1 score. Prediction Predicted Yes Predicted No\nActual Yes True Positive (TP) False Negative (FN)\nActual No False Positive (FP) True Negative (TN) Prediction Predicted Yes Predicted No\nActual Yes True Positive (TP) False Negative (FN)\nActual No False Positive (FP) True Negative (TN) Prediction Predicted Yes Predicted No Prediction Predicted Yes Predicted No Prediction Predicted Yes Predicted No Actual Yes True Positive (TP) False Negative (FN)\nActual No False Positive (FP) True Negative (TN) Actual Yes True Positive (TP) False Negative (FN) Actual Yes True Positive (TP) False Negative (FN) Actual No False Positive (FP) True Negative (TN) Actual No False Positive (FP) True Negative (TN) In binary classification we consider the F1 score to be a measure of the model’s accuracy. The F1 score is a weighted average of precision and recall scores. F1 = 2TP/2TP + FP + FN We see scores for F1 between 0 and 1, where 0 is the worst score and 1 is the best score. \nThe F1 score is typically used in information retrieval to see how well a model retrieves relevant results and our model is performing.  ",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "2. Define Precision and Recall?",
        "answer": "Precision and recall are ways of monitoring the power of machine learning implementation. But they often used at the same time. Precision answers the question, “Out of the items that the classifier predicted to be relevant, how many are truly relevant?” Whereas, recall answers the question, “Out of all the items that are truly relevant, how many are found by the classifier? In general, the meaning of precision is the fact of being exact and accurate. So the same will go in our machine learning model as well. If you have a set of items that your model needs to predict to be relevant. How many items are truly relevant? The below figure shows the Venn diagram that precision and recall. Precision and recall  Precision and recall Mathematically, precision and recall can be defined as the following: precision = # happy correct answers/# total items returned by ranker recall = # happy correct answers/# total relevant answers",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "3. How to Tackle Overfitting and Underfitting?",
        "answer": "Overfitting means the model fitted to training data too well, in this case, we need to resample the data and estimate the model accuracy using techniques like k-fold cross-validation. data too well Whereas for the Underfitting case we are not able to understand or capture the patterns from the data, in this case, we need to change the algorithms, or we need to feed more data points to the model. not able to understand",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "4. What is a Neural Network?",
        "answer": "It is a simplified model of the human brain. Much like the brain, it has neurons that activate when encountering something similar. The different neurons are connected via connections that help information flow from one neuron to another.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "5. What are Loss Function and Cost Functions? Explain the key Difference Between them?",
        "answer": "When calculating loss we consider only a single data point, then we use the term loss function. Whereas, when calculating the sum of error for multiple data then we use the cost function. There is no major difference. In other words, the loss function is to capture the difference between the actual and predicted values for a single record whereas cost functions aggregate the difference for the entire training dataset. The Most commonly used loss functions are Mean-squared error and Hinge loss. Mean-Squared Error(MSE): In simple words, we can say how our model predicted values against the actual values. MSE = √(predicted value - actual value)2 Hinge loss: It is used to train the machine learning classifier, which is L(y) = max(0,1- yy) Where y = -1 or 1 indicating two classes and y represents the output form of the classifier. The most common cost function represents the total cost as the sum of the fixed costs and the variable costs in the equation y = mx + b",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "6. What is Ensemble learning?",
        "answer": "Ensemble learning is a method that combines multiple machine learning models to create more powerful models. There are many reasons for a model to be different. Few reasons are: Different Population\nDifferent Hypothesis\nDifferent modeling techniques Different Population Different Hypothesis Different modeling techniques When working with the model’s training and testing data, we will experience an error. This error might be bias, variance, and irreducible error. Now the model should always have a balance between bias and variance, which we call a bias-variance trade-off. This ensemble learning is a way to perform this trade-off. There are many ensemble techniques available but when aggregating multiple models there are two general methods: Bagging, a native method: take the training set and generate new training sets off of it.\nBoosting, a more elegant method: similar to bagging, boosting is used to optimize the best weighting scheme for a training set. Bagging, a native method: take the training set and generate new training sets off of it. Boosting, a more elegant method: similar to bagging, boosting is used to optimize the best weighting scheme for a training set.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "7. How do you make sure which Machine Learning Algorithm to use?",
        "answer": "It completely depends on the dataset we have. If the data is discrete we use SVM. If the dataset is continuous we use linear regression. So there is no specific way that lets us know which ML algorithm to use, it all depends on the exploratory data analysis (EDA). EDA is like “interviewing” the dataset; As part of our interview we do the following: Classify our variables as continuous, categorical, and so forth. \nSummarize our variables using descriptive statistics. \nVisualize our variables using charts. Classify our variables as continuous, categorical, and so forth. Summarize our variables using descriptive statistics. Visualize our variables using charts. Based on the above observations select one best-fit algorithm for a particular dataset.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "8. How to Handle Outlier Values?",
        "answer": "An Outlier is an observation in the dataset that is far away from other observations in the dataset. Tools used to discover outliers are Box plot\nZ-score\nScatter plot, etc. Box plot Z-score Scatter plot, etc. Typically, we need to follow three simple strategies to handle outliers: We can drop them. \nWe can mark them as outliers and include them as a feature. \nLikewise, we can transform the feature to reduce the effect of the outlier. We can drop them. We can mark them as outliers and include them as a feature. Likewise, we can transform the feature to reduce the effect of the outlier.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "9. What is a Random Forest? How does it work?",
        "answer": "Random forest is a versatile machine learning method capable of performing both regression and classification tasks. Like bagging and boosting, random forest works by combining a set of other tree models. Random forest builds a tree from a random sample of the columns in the test data. Here’s are the steps how a random forest creates the trees: Take a sample size from the training data.\nBegin with a single node.\nRun the following algorithm, from the start node:\nIf the number of observations is less than node size then stop.\nSelect random variables.\nFind the variable that does the “best” job of splitting the observations.\nSplit the observations into two nodes.\nCall step `a` on each of these nodes. Take a sample size from the training data. Begin with a single node. Run the following algorithm, from the start node:\nIf the number of observations is less than node size then stop.\nSelect random variables.\nFind the variable that does the “best” job of splitting the observations.\nSplit the observations into two nodes.\nCall step `a` on each of these nodes. If the number of observations is less than node size then stop.\nSelect random variables.\nFind the variable that does the “best” job of splitting the observations.\nSplit the observations into two nodes.\nCall step `a` on each of these nodes. If the number of observations is less than node size then stop. Select random variables. Find the variable that does the “best” job of splitting the observations. Split the observations into two nodes. Call step `a` on each of these nodes.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "10. What is Collaborative Filtering? And Content-Based Filtering?",
        "answer": "Collaborative filtering is a proven technique for personalized content recommendations. Collaborative filtering is a type of recommendation system that predicts new content by matching the interests of the individual user with the preferences of many users. Content-based recommender systems are focused only on the preferences of the user. New recommendations are made to the user from similar content according to the user’s previous choices. Collaborative Filtering and Content-Based Filtering  Collaborative Filtering and Content-Based Filtering",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "11. What is Clustering?",
        "answer": "Clustering is the process of grouping a set of objects into a number of groups. Objects should be similar to one another within the same cluster and dissimilar to those in other clusters. A few types of clustering are: Hierarchical clustering\nK means clustering\nDensity-based clustering\nFuzzy clustering, etc. Hierarchical clustering K means clustering Density-based clustering Fuzzy clustering, etc.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "12. How can you select K for K-means Clustering?",
        "answer": "There are two kinds of methods that include direct methods and statistical testing methods: Direct methods: It contains elbow and silhouette \nStatistical testing methods: It has gap statistics. Direct methods: It contains elbow and silhouette Statistical testing methods: It has gap statistics. The silhouette is the most frequently used while determining the optimal value of k.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "13. What are Recommender Systems?",
        "answer": "A recommendation engine is a system used to predict users’ interests and recommend products that are quite likely interesting for them. Data required for recommender systems stems from explicit user ratings after watching a film or listening to a song, from implicit search engine queries and purchase histories, or from other knowledge about the users/items themselves.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "14. How do check the Normality of a dataset?",
        "answer": "Visually, we can use plots. A few of the normality checks are as follows: Shapiro-Wilk Test\nAnderson-Darling Test\nMartinez-Iglewicz Test\nKolmogorov-Smirnov Test\nD’Agostino Skewness Test Shapiro-Wilk Test Anderson-Darling Test Martinez-Iglewicz Test Kolmogorov-Smirnov Test D’Agostino Skewness Test",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "15. Can logistic regression use for more than 2 classes?",
        "answer": "No, by default logistic regression is a binary classifier, so it cannot be applied to more than 2 classes. However, it can be extended for solving multi-class classification problems (multinomial logistic regression) (multinomial logistic regression)",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "16. Explain Correlation and Covariance?",
        "answer": "Correlation is used for measuring and also for estimating the quantitative relationship between two variables.  Correlation measures how strongly two variables are related. Examples like, income and expenditure, demand and supply, etc. Covariance is a simple way to measure the correlation between two variables. The problem with covariance is that they are hard to compare without normalization.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "17. What is P-value?",
        "answer": "P-values are used to make a decision about a hypothesis test. P-value is the minimum significant level at which you can reject the null hypothesis. The lower the p-value, the more likely you reject the null hypothesis.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "18. What are Parametric and Non-Parametric Models?",
        "answer": "Parametric models will have limited parameters and to predict new data, you only need to know the parameter of the model. Non-Parametric models have no limits in taking a number of parameters, allowing for more flexibility and to predict new data. You need to know the state of the data and model parameters.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "19. What is Reinforcement Learning?",
        "answer": "Reinforcement learning is different from the other types of learning like supervised and unsupervised. In reinforcement learning, we are given neither data nor labels. Our learning is based on the rewards given to the agent by the environment.",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "20. Difference Between Sigmoid and Softmax functions?",
        "answer": "The sigmoid function is used for binary classification. The probabilities sum needs to be 1. Whereas, Softmax function is used for multi-classification. The probabilities sum will be 1. Conclusion The above-listed questions are the basics of machine learning. Machine learning is advancing so fast hence new concepts will emerge. So to get up to date with that join communities, attend conferences, read research papers. By doing so you can crack any ML interview. Additional Resources Practice Coding\nBest Machine Learning Courses\nBest Data Science Courses\nFree Deep Learning Course with Certification\nPython Interview Questions\nAI MCQs\nMachine Learning Engineer: Career Guide\nDeep Learning Interview\nMachine Learning Engineer Salary\nMachine Learning Vs Data Science\nMachine Learning Vs Deep Learning\nDifference Between Artificial Intelligence and Machine Learning Practice Coding Practice Coding Best Machine Learning Courses Best Machine Learning Courses Best Data Science Courses Best Data Science Courses Free Deep Learning Course with Certification Free Deep Learning Course with Certification Python Interview Questions Python Interview Questions AI MCQs AI MCQs Machine Learning Engineer: Career Guide Machine Learning Engineer: Career Guide Deep Learning Interview Deep Learning Interview Machine Learning Engineer Salary Machine Learning Engineer Salary Machine Learning Vs Data Science Machine Learning Vs Data Science Machine Learning Vs Deep Learning Machine Learning Vs Deep Learning Difference Between Artificial Intelligence and Machine Learning Difference Between Artificial Intelligence and Machine Learning",
        "reference": "interviewbit.com",
        "role": "machine-learning"
    },
    {
        "question": "1) What do you understand by Machine learning?",
        "answer": "Machine learning is the form of Artificial Intelligence that deals with system programming and automates data analysis to enable computers to learn and act through experiences without being explicitly programmed.\nFor example, Robots are coded in such a way that they can perform the tasks based on data they collect from sensors. They automatically learn programs from data and improve with experiences.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "2) Differentiate between inductive learning and deductive learning?",
        "answer": "In inductive learning, the model learns by examples from a set of observed instances to draw a generalized conclusion. On the other side, in deductive learning, the model first applies the conclusion, and then the conclusion is drawn.\nADVERTISEMENT\nInductive learning is the method of using observations to draw conclusions.\nDeductive learning is the method of using conclusions to form observations.\nFor example, if we have to explain to a kid that playing with fire can cause burns. There are two ways we can explain this to a kid; we can show training examples of various fire accidents or images of burnt people and label them as \"Hazardous\". In this case, a kid will understand with the help of examples and not play with the fire. It is the form of Inductive machine learning. The other way to teach the same thing is to let the kid play with the fire and wait to see what happens. If the kid gets a burn, it will teach the kid not to play with fire and avoid going near it. It is the form of deductive learning.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "3) What is the difference between Data Mining and Machine Learning?",
        "answer": "Data mining can be described as the process in which the structured data tries to abstract knowledge or interesting unknown patterns. During this process, machine learning algorithms are used.\nMachine learning represents the study, design, and development of the algorithms which provide the ability to the processors to learn without being explicitly programmed.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "4) What is the meaning of Overfitting in Machine learning?",
        "answer": "Overfitting can be seen in machine learning when a statistical model describes random error or noise instead of the underlying relationship. Overfitting is usually observed when a model is excessively complex. It happens because of having too many parameters concerning the number of training data types. The model displays poor performance, which has been overfitted.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "5) Why overfitting occurs?",
        "answer": "The possibility of overfitting occurs when the criteria used for training the model is not as per the criteria used to judge the efficiency of a model.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "6) What is the method to avoid overfitting?",
        "answer": "Overfitting occurs when we have a small dataset, and a model is trying to learn from it. By using a large amount of data, overfitting can be avoided. But if we have a small database and are forced to build a model based on that, then we can use a technique known as cross-validation. In this method, a model is usually given a dataset of a known data on which training data set is run and dataset of unknown data against which the model is tested. The primary aim of cross-validation is to define a dataset to \"test\" the model in the training phase. If there is sufficient data, 'Isotonic Regression' is used to prevent overfitting.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "",
        "answer": "In supervised machine learning, the machine is trained using labeled data. Then a new dataset is given into the learning model so that the algorithm provides a positive outcome by analyzing the labeled data. For example, we first require to label the data which is necessary to train the model while performing classification.\nIn the unsupervised machine learning, the machine is not trained using labeled data and let the algorithms make the decisions without any corresponding output variables.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "8) How does Machine Learning differ from Deep Learning?",
        "answer": "Machine learning is all about algorithms which are used to parse data, learn from that data, and then apply whatever they have learned to make informed decisions.\nDeep learning is a part of machine learning, which is inspired by the structure of the human brain and is particularly useful in feature detection.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "9) How is KNN different from k-means?",
        "answer": "KNN or K nearest neighbors is a supervised algorithm which is used for classification purpose. In KNN, a test sample is given as the class of the majority of its nearest neighbors. On the other side, K-means is an unsupervised algorithm which is mainly used for clustering. In k-means clustering, it needs a set of unlabeled points and a threshold only. The algorithm further takes unlabeled data and learns how to cluster it into groups by computing the mean of the distance between different unlabeled points.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "10) What are the different types of Algorithm methods in Machine Learning?",
        "answer": "The different types of algorithm methods in machine earning are:\nSupervised Learning\nSemi-supervised Learning\nUnsupervised Learning\nTransduction\nReinforcement Learning",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "11) What do you understand by Reinforcement Learning technique?",
        "answer": "Reinforcement learning is an algorithm technique used in Machine Learning. It involves an agent that interacts with its environment by producing actions & discovering errors or rewards. Reinforcement learning is employed by different software and machines to search for the best suitable behavior or path it should follow in a specific situation. It usually learns on the basis of reward or penalty given for every action it performs.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "12) What is the trade-off between bias and variance?",
        "answer": "Both bias and variance are errors. Bias is an error due to erroneous or overly simplistic assumptions in the learning algorithm. It can lead to the model under-fitting the data, making it hard to have high predictive accuracy and generalize the knowledge from the training set to the test set.\nVariance is an error due to too much complexity in the learning algorithm. It leads to the algorithm being highly sensitive to high degrees of variation in the training data, which can lead the model to overfit the data.\nTo optimally reduce the number of errors, we will need to tradeoff bias and variance.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "13) How do classification and regression differ?",
        "answer": "Classification Regression\nClassification is the task to predict a discrete class label.\nRegression is the task to predict a continuous quantity.\nIn a classification problem, data is labeled into one of two or more classes.\nA regression problem needs the prediction of a quantity.\nA classification having problem with two classes is called binary classification, and more than two classes is called multi-class classification\nA regression problem containing multiple input variables is called a multivariate regression problem.\nClassifying an email as spam or non-spam is an example of a classification problem.\nPredicting the price of a stock over a period of time is a regression problem.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "14) What are the five popular algorithms we use in Machine Learning?",
        "answer": "Five popular algorithms are:\nDecision Trees\nProbabilistic Networks\nNeural Networks\nSupport Vector Machines\nNearest Neighbor",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "15) What do you mean by ensemble learning?",
        "answer": "Numerous models, such as classifiers are strategically made and combined to solve a specific computational program which is known as ensemble learning. The ensemble methods are also known as committee-based learning or learning multiple classifier systems. It trains various hypotheses to fix the same issue. One of the most suitable examples of ensemble modeling is the random forest trees where several decision trees are used to predict outcomes. It is used to improve the classification, function approximation, prediction, etc. of a model.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "16) What is a model selection in Machine Learning?",
        "answer": "The process of choosing models among diverse mathematical models, which are used to define the same data is known as Model Selection. Model learning is applied to the fields of statistics, data mining, and machine learning.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "17) What are the three stages of building the hypotheses or model in machine learning?",
        "answer": "There are three stages to build hypotheses or model in machine learning:\nModel building\nIt chooses a suitable algorithm for the model and trains it according to the requirement of the problem.\nApplying the model\nIt is responsible for checking the accuracy of the model through the test data.\nModel testing\nIt performs the required changes after testing and apply the final model.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "18) What according to you, is the standard approach to supervised learning?",
        "answer": "In supervised learning, the standard approach is to split the set of example into the training set and the test.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "",
        "answer": "In various areas of information of machine learning, a set of data is used to discover the potentially predictive relationship, which is known as 'Training Set'. The training set is an example that is given to the learner. Besides, the 'Test set' is used to test the accuracy of the hypotheses generated by the learner. It is the set of instances held back from the learner. Thus, the training set is distinct from the test set.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "20) What are the common ways to handle missing data in a dataset?",
        "answer": "Missing data is one of the standard factors while working with data and handling. It is considered as one of the greatest challenges faced by the data analysts. There are many ways one can impute the missing values. Some of the common methods to handle missing data in datasets can be defined as deleting the rows, replacing with mean/median/mode, predicting the missing values, assigning a unique category, using algorithms that support missing values, etc.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "21) What do you understand by ILP?",
        "answer": "ILP stands for Inductive Logic Programming. It is a part of machine learning which uses logic programming. It aims at searching patterns in data which can be used to build predictive models. In this process, the logic programs are assumed as a hypothesis.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "22) What are the necessary steps involved in Machine Learning Project?",
        "answer": "There are several essential steps we must follow to achieve a good working model while doing a Machine Learning Project. Those steps may include parameter tuning, data preparation, data collection, training the model, model evaluation, and prediction, etc.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "23) Describe Precision and Recall?",
        "answer": "Precision and Recall both are the measures which are used in the information retrieval domain to measure how good an information retrieval system reclaims the related data as requested by the user.\nPrecision can be said as a positive predictive value. It is the fraction of relevant instances among the received instances.\nOn the other side, recall is the fraction of relevant instances that have been retrieved over the total amount or relevant instances. The recall is also known as sensitivity.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "24) What do you understand by Decision Tree in Machine Learning?",
        "answer": "Decision Trees can be defined as the Supervised Machine Learning, where the data is continuously split according to a certain parameter. It builds classification or regression models as similar as a tree structure, with datasets broken up into ever smaller subsets while developing the decision tree. The tree can be defined by two entities, namely decision nodes, and leaves. The leaves are the decisions or the outcomes, and the decision nodes are where the data is split. Decision trees can manage both categorical and numerical data.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "25) What are the functions of Supervised Learning?",
        "answer": "Classification\nSpeech Recognition\nRegression\nPredict Time Series\nAnnotate Strings",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "26) What are the functions of Unsupervised Learning?",
        "answer": "Finding clusters of the data\nFinding low-dimensional representations of the data\nFinding interesting directions in data\nFinding novel observations/ database cleaning\nFinding interesting coordinates and correlations",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "27) What do you understand by algorithm independent machine learning?",
        "answer": "Algorithm independent machine learning can be defined as machine learning, where mathematical foundations are independent of any particular classifier or learning algorithm.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "",
        "answer": "A classifier is a case of a hypothesis or discrete-valued function which is used to assign class labels to particular data points. It is a system that inputs a vector of discrete or continuous feature values and outputs a single discrete value, the class.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "29) What do you mean by Genetic Programming?",
        "answer": "Genetic Programming (GP) is almost similar to an Evolutionary Algorithm, a subset of machine learning. Genetic programming software systems implement an algorithm that uses random mutation, a fitness function, crossover, and multiple generations of evolution to resolve a user-defined task. The genetic programming model is based on testing and choosing the best option among a set of results.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "30) What is SVM in machine learning? What are the classification methods that SVM can handle?",
        "answer": "SVM stands for Support Vector Machine. SVM are supervised learning models with an associated learning algorithm which analyze the data used for classification and regression analysis.\nThe classification methods that SVM can handle are:\nCombining binary classifiers\nModifying binary to incorporate multiclass learning",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "31) How will you explain a linked list and an array?",
        "answer": "An array is a datatype which is widely implemented as a default type, in almost all the modern programming languages. It is used to store data of a similar type.\nBut there are many use-cases where we don't know the quantity of data to be stored. For such cases, advanced data structures are required, and one such data structure is linked list.\nThere are some points which explain how the linked list is different from an array:\nARRAY LINKED LIST\nAn array is a group of elements of a similar data type.\nLinked List is an ordered group of elements of the same type, which are connected using pointers.\nElements are stored consecutively in the memory.\nNew elements can be stored anywhere in memory.\nAn Array supports Random Access. It means that the elements can be accessed directly using their index value, like arr[0] for 1st element, arr[5] for 6th element, etc.\nAs a result, accessing elements in an array is fast with constant time complexity of O(1).\nLinked List supports Sequential Access. It means that we have to traverse the complete linked list, up to that element sequentially which element/node we want to access in a linked list.\nTo access the nth element of a linked list, the time complexity is O(n).\nMemory is allocated at compile time as soon as the array is declared. It is known as Static Memory Allocation.\nMemory is allocated at runtime, whenever a new node is added. It is known as Dynamic Memory Allocation.\nInsertion and Deletion operation takes more time in the array, as the memory locations are consecutive and fixed.\nIn case of a linked list, a new element is stored at the first free available memory location.\nThus, Insertion and Deletion operations are fast in the linked list.\nSize of the array must be declared at the time of array declaration.\nSize of a Linked list is variable. It grows at runtime whenever nodes are added to it.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "32) What do you understand by the Confusion Matrix?",
        "answer": "A confusion matrix is a table which is used for summarizing the performance of a classification algorithm. It is also known as the error matrix.\n\nWhere,\nTN= True Negative\nTP= True Positive\nFN= False Negative\nFP= False Positive",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "",
        "answer": "True Positive\nWhen a model correctly predicts the positive class, it is said to be a true positive.\nFor example, Umpire gives a Batsman NOT OUT when he is NOT OUT.\nTrue Negative\nWhen a model correctly predicts the negative class, it is said to be a true negative.\nFor example, Umpire gives a Batsman OUT when he is OUT.\nFalse Positive\nWhen a model incorrectly predicts the positive class, it is said to be a false positive. It is also known as 'Type I' error.\nFor example, Umpire gives a Batsman NOT OUT when he is OUT.\nFalse Negative\nWhen a model incorrectly predicts the negative class, it is said to be a false negative. It is also known as 'Type II' error.\nFor example, Umpire gives a Batsman OUT when he is NOT OUT.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "34) What according to you, is more important between model accuracy and model performance?",
        "answer": "Model accuracy is a subset of model performance. The accuracy of the model is directly proportional to the performance of the model. Thus, better the performance of the model, more accurate are the predictions.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "35) What is Bagging and Boosting?",
        "answer": "Bagging is a process in ensemble learning which is used for improving unstable estimation or classification schemes.\nBoosting methods are used sequentially to reduce the bias of the combined model.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "36) What are the similarities and differences between bagging and boosting in Machine Learning?",
        "answer": "Similarities of Bagging and Boosting\nBoth are the ensemble methods to get N learns from 1 learner.\nBoth generate several training data sets with random sampling.\nBoth generate the final result by taking the average of N learners.\nBoth reduce variance and provide higher scalability.\nDifferences between Bagging and Boosting\nAlthough they are built independently, but for Bagging, Boosting tries to add new models which perform well where previous models fail.\nOnly Boosting determines the weight for the data to tip the scales in favor of the most challenging cases.\nOnly Boosting tries to reduce bias. Instead, Bagging may solve the problem of over-fitting while boosting can increase it.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "37) What do you understand by Cluster Sampling?",
        "answer": "Cluster Sampling is a process of randomly selecting intact groups within a defined population, sharing similar characteristics. Cluster sample is a probability where each sampling unit is a collection or cluster of elements.\nFor example, if we are clustering the total number of managers in a set of companies, in that case, managers (sample) will represent elements and companies will represent clusters.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "38) What do you know about Bayesian Networks?",
        "answer": "Bayesian Networks also referred to as 'belief networks' or 'casual networks', are used to represent the graphical model for probability relationship among a set of variables.\nFor example, a Bayesian network can be used to represent the probabilistic relationships between diseases and symptoms. As per the symptoms, the network can also compute the probabilities of the presence of various diseases.\nEfficient algorithms can perform inference or learning in Bayesian networks. Bayesian networks which relate the variables (e.g., speech signals or protein sequences) are called dynamic Bayesian networks.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "39) Which are the two components of Bayesian logic program?",
        "answer": "A Bayesian logic program consists of two components:\nLogical\nIt contains a set of Bayesian Clauses, which capture the qualitative structure of the domain.\nQuantitative\nIt is used to encode quantitative information about the domain.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "",
        "answer": "Dimension reduction is the process which is used to reduce the number of random variables under considerations.\nDimension reduction can be divided into feature selection and extraction.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "41) Why instance-based learning algorithm sometimes referred to as Lazy learning algorithm?",
        "answer": "In machine learning, lazy learning can be described as a method where induction and generalization processes are delayed until classification is performed. Because of the same property, an instance-based learning algorithm is sometimes called lazy learning algorithm.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "42) What do you understand by the F1 score?",
        "answer": "The F1 score represents the measurement of a model's performance. It is referred to as a weighted average of the precision and recall of a model. The results tending to 1 are considered as the best, and those tending to 0 are the worst. It could be used in classification tests, where true negatives don't matter much.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "43) How is a decision tree pruned?",
        "answer": "Pruning is said to occur in decision trees when the branches which may consist of weak predictive power are removed to reduce the complexity of the model and increase the predictive accuracy of a decision tree model. Pruning can occur bottom-up and top-down, with approaches such as reduced error pruning and cost complexity pruning.\nReduced error pruning is the simplest version, and it replaces each node. If it is unable to decrease predictive accuracy, one should keep it pruned. But, it usually comes pretty close to an approach that would optimize for maximum accuracy.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "44) What are the Recommended Systems?",
        "answer": "Recommended System is a sub-directory of information filtering systems. It predicts the preferences or rankings offered by a user to a product. According to the preferences, it provides similar recommendations to a user. Recommendation systems are widely used in movies, news, research articles, products, social tips, music, etc.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "45) What do you understand by Underfitting?",
        "answer": "Underfitting is an issue when we have a low error in both the training set and the testing set. Few algorithms work better for interpretations but fail for better predictions.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "46) When does regularization become necessary in Machine Learning?",
        "answer": "Regularization is necessary whenever the model begins to overfit/ underfit. It is a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and reduce cost term. It helps to reduce model complexity so that the model can become better at predicting (generalizing).",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "47) What is Regularization? What kind of problems does regularization solve?",
        "answer": "A regularization is a form of regression, which constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, it discourages learning a more complex or flexible model to avoid the risk of overfitting. It reduces the variance of the model, without a substantial increase in its bias.\nRegularization is used to address overfitting problems as it penalizes the loss function by adding a multiple of an L1 (LASSO) or an L2 (Ridge) norm of weights vector w.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "48) Why do we need to convert categorical variables into factor? Which functions are used to perform the conversion?",
        "answer": "Most Machine learning algorithms require number as input. That is why we convert categorical values into factors to get numerical values. We also don't have to deal with dummy variables.\nThe functions factor() and as.factor() are used to convert variables into factors.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "49) Do you think that treating a categorical variable as a continuous variable would result in a better predictive model?",
        "answer": "For a better predictive model, the categorical variable can be considered as a continuous variable only when the variable is ordinal in nature.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    },
    {
        "question": "50) How is machine learning used in day-to-day life?",
        "answer": "Most of the people are already using machine learning in their everyday life. Assume that you are engaging with the internet, you are actually expressing your preferences, likes, dislikes through your searches. All these things are picked up by cookies coming on your computer, from this, the behavior of a user is evaluated. It helps to increase the progress of a user through the internet and provide similar suggestions.\nThe navigation system can also be considered as one of the examples where we are using machine learning to calculate a distance between two places using optimization techniques. Surely, people are going to more engage with machine learning in the near future.",
        "reference": "javatpoint.com",
        "role": "machine-learning"
    }
]