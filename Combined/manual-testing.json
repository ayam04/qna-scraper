[
    {
        "question": "1. What do you understand by software testing?",
        "answer": "Software testing is a validation process that confirms that a system works as per the business requirements. It qualifies a system on various aspects such as usability, accuracy, completeness, efficiency, etc. ANSI/IEEE 1059 is the global standard that defines the basic principles of testing.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "2. What is a test plan and what does it include?",
        "answer": "A test plan stores all possible testing activities to ensure a quality product. It gathers data from the product description, requirement, and use case documents.\nThe test plan document includes the following:\nTesting objectives\nTest scope\nTesting the frame\nEnvironment\nReason for testing\nCriteria for entrance and exit\nDeliverables\nRisk factors",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "3. When should you stop the testing process?",
        "answer": "The testing activity ends when the testing team completes the following milestones.\nTest case execution\nThe successful completion of a full test cycle after the final bug fix marks the end of the testing phase.\nTesting deadline\nThe end date of the validation stage also declares the closure of the validation if no critical or high-priority defects remain in the system.\nCode Coverage(CC) ratio\nIt is the amount of code concealed via automated tests. If the team achieves the intended level of code coverage (CC) ratio, then it can choose to end the validation.\nMean Time Between Failure (MTBF) rate\nMean time between failure (MTBF) refers to the average amount of time that a device or product functions before failing. This unit of measurement includes only operational time between failures and does not include repair times, assuming the item is repaired and begins functioning again. MTBF figures are often used to project how likely it is for a single unit to fail within a certain period of time.\nHave a look at the API Testing Interview Question.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "4. What do verification and validation mean in software testing?",
        "answer": "Verification is a process that confirms that product development takes place as per the specifications and uses standard development procedures. The process comprises the following activities:\nInspections\nReviews\nWalk-throughs\nDemos\nValidation is a means to confirm that the developed product doesn’t have any bugs and works as expected. It comprises the following activities:\nFunctional testing\nNon-functional testing\nPreparing for a Job Interview! Check out our Top Software Testing Interview Questions.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "5. What is static testing? When does it start and what does it cover?",
        "answer": "Static testing is a white-box testing technique that directs developers to verify their code with the help of a checklist to find errors in it. Developers can start the static testing without actually finalizing the application or program. Static testing is more cost-effective than dynamic testing as it covers more areas than dynamic testing in a shorter time.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "6. Define black-box testing.",
        "answer": "It is a standard software testing approach that requires testers to assess the functionality of the software as per the business requirements. The software is treated as a black box and validated as per the end user’s point of view.\nCheck out our blog on Selenium tutorial to gain in-depth insights on Selenium!",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "7. What is meant by test coverage?",
        "answer": "Test coverage is a quality metric to represent the amount (in percentage) of testing that has been completed. It is relevant for both functional and non-functional testing activities. This metric is used to add missing test cases.\nDon’t miss out Automation Testing Interview Questions. Crack your interviews with ease.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "8. Is it possible to achieve 100% testing coverage? How would you ensure it?",
        "answer": "It’s considered impossible to perform 100% testing of any product. But, you can follow the below steps to come closer.\nSet a hard limit on the following factors:\nPercentage of test cases passed\nNumber of bugs found\nSet a red flag if:\nTest budget is depleted\nDeadlines are breached\nSet a green flag if:\nThe entire functionality gets covered in test cases\nAll critical and major bugs must have a ‘CLOSED’ status",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "9. What are unit testing and integration testing?",
        "answer": "Unit testing has many names such as module testing or component testing.\nMany times, it is the developers who test individual units or modules to check if they are working correctly.\nWhereas, integration testing validates how well two or more units of software interact with each other.\nThere are three ways to validate integration:\nBig Bang approach\nTop-down approach\nBottom-up approach",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "10. Can we do system testing at any stage?",
        "answer": "No. System testing should start only if all modules are in place and they work correctly. However, it should be performed before UAT (user acceptance testing).",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "11. Mention the different types of software testing.",
        "answer": "Various types of Software Testing used by manual testers are as follows:\nBlack Box Testing\nRegression testing\nSmoke testing\nFunctional testing\nExploratory Testing\nIntegration Testing\nSystem Testing\nGraphical User Interface Testing\nUser Acceptance Testing (UAT)\nAlpha and Beta testing\nUnit testing\nIntegration testing\nShakeout testing\nPerformance Testing",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "12. What is the difference between a test driver and a test stub?",
        "answer": "The test driver is a section of code that calls a software component under test. It is useful in testing that follows the bottom-up approach.\nThe test stub is a dummy program that integrates with an application to complete its functionality. It is relevant for testing that uses the top-down approach.\nFor example:\nLet’s assume a scenario where we have to test the interface between modules A and B and we have developed only Module A. Here, we can test module A if we have the real Module B or a dummy module for it. In this case, we call module B as the test stub.\nNow, module B can’t send or receive data directly from module A. In such a scenario, we have to move data from one module to another using some external features called test driver.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "13. What is agile testing and why is it important?",
        "answer": "Agile testing is a software testing process that evaluates software from the customers’ point of view. It is favorable as it does not require the development team to complete coding to start QA. Instead, both coding and testing go hand in hand. However, it may require continuous customer interaction.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "14. What do you know about data flow testing?",
        "answer": "It is a white-box testing techniques.\nData flow testing focuses on the creation of test cases that encompass the control flow paths involving variable declarations and their utilization within modules. It expects test cases to have the following attributes:\nThe input to the module\nThe control flow path for testing\nA pair of an appropriate variable definition and its use\nThe expected outcome of the test case",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "15. What is the purpose of the end-to-end testing?",
        "answer": "End-to-end testing is a testing strategy to execute tests that cover every possible flow of an application from its start to finish. The objective of performing end-to-end tests is to discover software dependencies and to assert that the correct input is getting passed between various software modules and sub-systems.\nAlso, check out the difference between automation and manual testing.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "16. Can you explain the importance of test cases in the manual testing process?",
        "answer": "In testing, test cases play a role due to various reasons:\nGuidance and Consistency: Test cases provide a framework that guides testers through defined steps and expected outcomes consistently. This approach promotes uniformity in testing procedures among testers and testing cycles.\nCoverage and Validation: Test cases methodically cover a range of functionalities, user scenarios, and error conditions to ensure test coverage. By validating these aspects, it confirms that the software meets specified requirements and functions correctly under certain situations.\nRepeatability and Reliability: documented test cases allow for the reproduction of test scenarios, ensuring consistent results. This reliability is essential for verifying fixes, conducting regression tests, and maintaining software quality in the long run.\nEffectiveness: Test cases streamline the testing process, helping testers execute tests efficiently without guesswork. This streamlined approach allows testers to focus on identifying defects and concentrate their testing efforts on specific areas of the software.\nDocumentation and Communication: Test cases serve as a form of documentation by detailing test scenarios, anticipated results, and actual findings. This helps to promote communication, among testers, developers, and stakeholders, ensuring that everyone is on the same page regarding testing goals and standards for assuring software quality.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "17. What is regression testing, and why is it important?",
        "answer": "Regression testing is vital for software stability and quality assurance. It ensures that recent code changes don’t introduce bugs or break existing features. By preventing regression issues, it supports agile development practices and continuous integration.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "18. How do you prioritize test cases when you have limited time for testing?",
        "answer": "We can prioritize test cases when we have limited time for testing in several scenario, including: \nIdentify critical functionalities: Focus on testing essential software features critical for user satisfaction and core operations.\nAssess risk impact: Prioritize test cases based on their potential impact on software stability, user experience, and business objectives.\nConsider frequency of use: Test functionalities frequently used to ensure thorough evaluation of critical aspects.\nFocus on high risk areas: Allocate more time in testing areas to defects, implemented features, or complex functionalities.\nEngage with stakeholders: Talk to project participants to coordinate testing strategies with business objectives and confirm that priorities match the requirements.\nLearn about DevOps Testing.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "19. Can you explain the concept of equivalence partitioning and give an example?",
        "answer": "Equivalence partitioning optimizes testing by dividing a system input domain into classes, reducing the number of test cases while ensuring thorough coverage. Here’s how it works:\nDivide Input Domain: System inputs are grouped into partitions, assuming similar behavior within each partition.\nSelect Representative Values: Test cases are chosen to represent each partition, ensuring comprehensive testing.\nExecute Test Cases: Testing with these values validates system behavior within each partition.\nIdentify Defects: Discrepancies are noted and addressed, with additional cases added as needed.\nExample: A login page partitions usernames and passwords into valid, invalid, and blank entries, enabling efficient testing.\nLearn about How to make a Career in Software Testing",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "20. How do you ensure adequate test coverage in your testing process?",
        "answer": "To ensure comprehensive test coverage in your testing process, consider the following strategies:\nThorough Requirement Analysis: Understand project requirements to identify all functionalities and scenarios requiring testing.\nRisk-Focused Testing: Arrange testing according to the consequences and chances of failure for each feature.\nThorough Test Scenario Development: Develop test scenarios that address negative and boundary conditions.\nExploratory Testing: Perform tests to uncover issues.\nCode Coverage Evaluation: Employ tools to track code execution during testing, guaranteeing that all code pathways are assessed.\nTraceability Matrix: Map test cases to requirements for tracking and ensuring all requirements are tested.\nContinuous Improvement: Regularly update test cases to reflect changes, ensuring evolving coverage over time.\nWatch this Selenium Automation Testing Tutorial to get a kick start:",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "21. The probability that a server-class application hosted on the cloud is up and running for six long months without crashing is 99.99 percent. To analyze this type of scenario, what test will you perform?",
        "answer": "Reliability testing",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "22. What will you do when a bug turns up during testing?",
        "answer": "When a bug occurs, we can follow the below steps.\nWe can run more tests to make sure that the problem has a clear description.\nWe can also run a few more tests to ensure that the same problem doesn’t exist with different inputs.\nOnce we are certain of the full scope of the bug, we can add details and report it.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "23. Why is it impossible to test a program thoroughly?",
        "answer": "Here are the two principal reasons that make it impossible to test a program entirely.\nSoftware specifications can be subjective and can lead to different interpretations.\nA software program may require too many inputs, outputs, and path combinations.\nLearn more about Salesforce Testing.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "24. How do you test a product if the requirements are yet to be freezed?",
        "answer": "If the required specifications are not available for a product, then a test plan can be created based on the assumptions made about the product. But all assumptions must be well-documented in the test plan.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "25. If a product is in the production stage and one of its modules gets updated, then is it necessary to perform regression testing?",
        "answer": "Yes, it is necessary to perform regression testing when a module of a product in the production stage gets updated. Regression testing helps ensure that the changes made to the updated module do not have unintended effects on other modules or the overall functionality of the product. By retesting the previously working functionalities, it helps identify any potential issues or regressions caused by the module update. This testing process helps maintain the quality and stability of the product throughout its lifecycle.\nThese were some basic manual testing interview questions. In the following section, we will present some Intermediate manual testing interview questions.\n\nIntermediate Manual Testing Interview Questions",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "26. How will you overcome the challenges faced due to the unavailability of proper documentation for testing?",
        "answer": "If standard documents like the system requirement specification or feature description document are not available, then QA may have to rely on the following references, if available.\nScreenshots\nA previous version of the application\nWireframes\nAnother reliable way is to have discussions with the developer and the business analyst. It helps in solving the doubts, and it opens a channel for bringing clarity on the requirements. Also, the emails exchanged could be useful as a testing reference.\nSmoke testing is yet another option that would help verify the main functionality of the application. It would reveal some very basic bugs in the application. If none of these work, then we can just test the application from our previous experiences.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "27. Is there any difference between retesting and regression testing?",
        "answer": "Differences between retesting and regression testing are as follows:\nWe perform retesting to verify the defect fixes. But, regression testing assures that the bug fix does not break other parts of the application.\nRegression test cases verify the functionality of some or all modules.\nRegression testing ensures the re-execution of passed test cases. Whereas, retesting involves the execution of test cases that are in a failed state.\nRetesting has a higher priority over regression. But in some cases, both get executed in parallel.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "28. What are the different types of functional testing?",
        "answer": "Functional testing covers the following types of validation techniques:\nUnit testing\nSmoke testing\nUAT\nSanity testing\nInterface testing\nIntegration testing\nSystem testing\nRegression testing\nUnderstand the Difference between Quality Assurance and Quality Control",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "29. What are functional test cases and non-functional test cases?",
        "answer": "Functional Test Cases: Functional test cases are designed to evaluate the functionality of a software system or application. These test cases focus on verifying whether the system performs its intended functions correctly and meets the specified functional requirements. Functional test cases typically involve validating inputs, testing different scenarios, and verifying expected outputs.\nNon-Functional Test Cases: Non-functional test cases, on the other hand, assess the non-functional aspects of a software system or application. These test cases evaluate performance, usability, reliability, security, scalability, and compatibility. Non-functional testing cases ensure the system meets the required quality standards and provides a satisfactory user experience.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "30. What do you understand about STLC?",
        "answer": "Software testing life cycle (STLC) proposes the test execution in a planned and systematic manner. In the STLC model, many activities occur to improve the quality of the product.\nThe STLC model lays down the following steps:\nRequirement Analysis\nTest Planning\nTest Case Development\nEnvironment Setup\nTest Execution\nTest Cycle Closure",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "31. In software testing, what does a fault mean?",
        "answer": "A fault is a condition that makes the software fail to execute while performing the considered function.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "32. Difference between bug, defect, and error.",
        "answer": "A slip in coding is indicated as an error. The error spotted by a manual tester becomes a defect. The defect which the development team admits is known as a bug. If a built code misses on the requirements, then it is a functional failure.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "33. How do severity and priority relate to each other?",
        "answer": "Severity: It represents the gravity/depth of a bug. It describes the application point of view.\nPriority: It specifies which bug should get fixed first. It defines the user’s point of view.\nEnroll now in Selenium course to learn more about selenium concepts!",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "34. List the different types of severity.",
        "answer": "The criticality of a bug can be low, medium, or high depending on the context.\nUser interface defects – Low\nBoundary-related defects – Medium\nError handling defects – Medium\nCalculation defects – High\nMisinterpreted data – High\nHardware failures – High\nCompatibility issues – High\nControl flow defects – High\nLoad conditions – High",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "35. What is the purpose of a traceability matrix, and how do you create and maintain one?",
        "answer": "The traceability matrix aligns requirements with test cases, ensuring thorough test coverage. To create and maintain it, identify project artifacts, establish traceability links, and update it continuously. Use the matrix for reporting and analysis to track test coverage effectively.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "36. How do you handle test data management and ensure data integrity during testing?",
        "answer": "Managing test data and ensuring its integrity is crucial for effective testing. Here’s a concise approach:\nIdentify Relevant Data: Identify necessary test data for scenarios.\nGenerate Data: Use tools/scripts to generate diverse test data.\nProtect Sensitive Information: Mask or anonymize PII to safeguard data.\nEnsure Data Separation: Keep test and production data isolated.\nValidate Data Integrity: Perform checks to validate data accuracy during testing.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "37. Can you describe the defect life cycle and the different stages involved in defect management?",
        "answer": "The defect life cycle outlines stages in defect management:\nIdentification: The defect is logged.\nAssignment: A team member analyzes the defect.\nOpen: The defect is confirmed.\nIn Progress:The developer fixes the defect.\nFixed: The defect is resolved.\nRetesting:The defect is ready for testing.\nReopened: If necessary, the defect is revisited.\nClosed: Verified defect closure.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "38. What techniques do you use to test database views and stored procedures using SQL queries? How do you ensure their correctness and efficiency?",
        "answer": "To test database views and stored procedures effectively:\nInput Validation: Validate inputs and outputs for expected results.\nFunctional Testing: Confirm views/procedures meet requirements.\nBoundary Testing: Test extreme input values for edge cases.\nPerformance Testing: Assess query execution time and resource usage.\nIntegration Testing: Verify compatibility with other components.\nTo ensure the correctness and efficiency of database views and stored procedures:\nCorrectness: Validate inputs and outputs against requirements. Compare the results with expectations to detect discrepancies. Ensure compliance with business rules.\nEfficiency: Analyze SQL queries for performance issues. Optimize queries by adding indexes, rewriting SQL, or restructuring the database schema. Monitor query execution time and resource usage for improvements.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "39. Describe the process you follow for creating and executing test cases in a manual testing environment.",
        "answer": "Creating and executing test cases in a manual testing environment involves several key steps:\nRequirement Analysis: Thoroughly understand project requirements.\nTest Planning: Develop a comprehensive test plan.\nTest Case Design: Create detailed test cases for various scenarios.\nTest Data Preparation: Gather or create the necessary test data.\nTest Environment Setup: Ensure the readiness of the testing environment.\nTest Execution: Meticulously execute test cases and record results.\nDefect Reporting: Document encountered defects with clear descriptions.\nDefect Tracking: Monitor progress in defect resolution.\nRegression Testing: Ensure changes don’t introduce new defects.\nTest Closure: Evaluate results and provide comprehensive summary reports.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "40. What do you mean by defect detection percentage in software testing?",
        "answer": "Defect detection percentage (DDP) is a type of testing metric. It indicates the effectiveness of a testing process by measuring the ratio of defects discovered before the release and reported after the release by customers.\nFor example, let’s say, the QA has detected 70 defects during the testing cycle and the customer reported 20 more after the release. Then, DDP would be: 70/(70 + 20) = 72.1%",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "41. What does defect removal efficiency mean in software testing?",
        "answer": "Defect removal efficiency (DRE) is an important testing metric. It is an indicator of the efficiency of the development team to fix issues before the release.\nIt gets measured as the ratio of defects fixed to total the number of issues discovered.\nFor example, let’s say, there were 75 defects discovered during the test cycle while 62 of them got fixed by the development team at the time of measurement. The DRE would be 62/75 = 82.6%\nGo through the Manual Testing Training to get a clear understanding of Weak AI and Strong AI.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "42. As per your understanding, list down the key challenges of software testing.",
        "answer": "Following are some of the key challenges of software testing:\nThe lack of availability of standard documents to understand the application\nLack of skilled testers\nUnderstanding the requirements: Testers require good listening and understanding capabilities to be able to communicate with the customers the application requirements.\nThe decision-making ability to analyze when to stop testing\nAbility to work under time constraints\nAbility to decide which tests to execute first\nTesting the entire application using an optimized number of test cases",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "43. What is the average age of a defect in software testing?",
        "answer": "Defect age is the time elapsed between the day the tester discovered a defect and the day the developer got it fixed.\nWhile estimating the age of a defect, consider the following points:\nThe day of birth of a defect is the day it got assigned and accepted by the development team.\nThe issues which got dropped are out of the scope.\nAge can be both in hours or days.\nThe end time is the day the defect got verified and closed, not just the day it got fixed by the development team.\nIf you have any doubts about these Manual Testing interview questions, feel free to comment about your problems.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "44. What is a silk test and why should you use it?",
        "answer": "Here are some facts about the silk test tool:\nA specialized tool has been created for conducting regression and functional testing of an application.\nIt is used when we are testing Windows-based, Java, web, and traditional client/server applications.\nSilk test helps in preparing the test plan and managing it to provide direct accessing of the database and validation of the field.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "45. On the basis of which factors would you consider choosing automated testing over manual testing?",
        "answer": "Choosing automation testing over manual testing depends on the following factors:\nTests require periodic execution.\nTests include repetitive steps.\nTests execute in a standard runtime environment.\nAutomation is expected to take less time.\nAutomation is increasing reusability.\nAutomation reports are available for every execution.\nSmall releases like service packs include a minor bug fix. In such cases, executing the regression test is sufficient for validation.\nIn such cases, executing the regression test is sufficient for validation.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "46. How do you prioritize test cases when you have limited time for testing?",
        "answer": "When it comes to prioritizing tests, I employ techniques such as risk-based testing and impact analysis. This entails giving priority to test cases based on their criticality to the applications functionality, frequency of usage, and potential consequences of failure. By addressing high-risk areas, I ensure that essential functionalities receive testing within the allocated time frame. This approach optimizes my testing efforts. Enhances the quality of the software product.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "47. What are the key components of a test plan document, and why is it essential to the testing process?",
        "answer": "A test plan document comprises the following elements:\nOverview: This part gives a summary of the project’s goals and the testing scope.\nApproach: It describes the strategy that will be used for conducting tests.\nTest Scope: In this part, we’ll give you an overview of the project, its goals and the testing scope.\nTest Schedule: The test schedule provides timelines and milestones for testing activities.\nResource Planning: This part focuses on allocating resources, tools, and environments required for testing purposes.\nTest Deliverables:Test deliverables include all the documents and artifacts produced during testing.\nRisk Management: Risk management involves strategies for identifying, assessing, and mitigating project risks.\nA test plan is essential, as it serves as a guide for carrying out testing activities. It helps define roles and responsibilities, set expectations, and ensure alignment with project goals.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "48. Can you explain the difference between smoke testing and sanity testing?",
        "answer": "Smoke Testing:\nSmoke testing is a form of software evaluation that aims to validate whether critical features of an application are working properly. It is usually carried out in the development phase immediately after deploying a build to ensure that vital functions are operational and that the application is sufficiently stable for testing.\nThe primary focus of smoke testing lies in identifying any issues that could impede the testing process.\nSanity Testing:\nSanity testing, a type of regression testing, focuses on assessing the functions or sections of the software after changes have been implemented. Its goal is to confirm that recent updates or repairs have not adversely affected the features of the software.\nCompared to smoke testing, sanity testing has scope. Specifically targets areas affected by recent changes.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "49. What are some common types of software defects you have encountered, and how do you typically categorize them?",
        "answer": "Common types of software defects are: \nFunctional Defects: Failures to meet specified requirements.\nInterface Defects: Issues with user interface elements.\nPerformance Defects: Problems related to software speed or resource usage.\nCompatibility Defects: Incompatibility with certain systems or browsers.\nSecurity Defects: Vulnerabilities compromising system security.\nUsability Defects: Challenges users face while using the software.\nDocumentation Defects: Errors or omissions in documentation.\nWe can categorize defects by severity, priority, and impact, which aids in effective resolution and resource allocation.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "50. How do you ensure adequate test coverage in your testing process?",
        "answer": "Several strategies used to ensure adequate test coverage are: \nRequirement Coverage: Ensure test cases cover all specified requirements and functionalities.\nRisk Prioritization: Focus testing on high-risk areas or critical functionalities.\nBoundary and Edge Cases: Test inputs at boundaries and edge conditions for accurate behavior.\nCode Coverage Analysis: Measure the code exercise by the test suite to identify gaps.\nRegular Reviews and Feedback: Review and enhance test cases periodically for improved coverage.\n\nAdvanced Manual Testing Interview Questions for Experienced",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "51. What are the key elements to consider while writing a bug report?",
        "answer": "An ideal bug report should consist of the following key points:\nA unique ID\nDefect description: A short description of the bug\nSteps to reproduce: They include the detailed test steps to emulate the issue. They also provide the test data and the time when the error has occurred\nEnvironment: Add any system settings that could help in reproducing the issue\nModule/section of the application in which the error has occurred\nSeverity\nScreenshots\nResponsible QA: This person is a point of contact in case you want to follow-up regarding this issue",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "52. Is there any difference between bug leakage and bug release?",
        "answer": "Bug leakage:  Bug leakage is when the bug is discovered by the end user/customer and missed by the testing team. It is a defect that exists in the application and not detected by the tester, which is eventually found by the customer/end user.\nBug release: A bug release is when a particular version of the software is released with a set of known bug(s). These bugs are usually of low severity/priority. It is done when a software company can afford the existence of bugs in the released software but not the time/cost for fixing it in that particular version.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "53. What is exploratory testing?",
        "answer": "Exploratory testing is an approach to software testing, where in testers learn simultaneously about the test design and test execution. In other words, it is a hands-on approach where testers are involved more in the test execution part than in planning.\nAlso, check out the blog on Test Data Management.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "54. What is meant by system testing?",
        "answer": "System testing is a black-box testing technique, used on a complete integrated system. It tests system compliance as per the requirement.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "55. What are the benefits of test reports?",
        "answer": "Test reports will help us find the current status of a project and its quality. This can help stakeholders and customers take necessary actions. The complete documentation of test reports will help analyze different phases of the project.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "56. What is meant by latent defect?",
        "answer": "A latent defect is a hidden defect in an application or software which cannot be identified by a user. However, this will not cause any failure to the application because the conditions will never be met.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "57. Describe a scenario where you had to perform exploratory testing. What approach did you take, and what were the outcomes?",
        "answer": "Recently, you had the opportunity to work on a project involving the testing of an e-commerce platform. To start off, you familiarize yourself with the features and functionalities of the application through testing. By sticking to predefined test cases you opted for a flexible approach and freely explored the application to identify any potential issues.\nDuring your testing, you focused on aspects such as user registration, product search, and the checkout process. You simulated user scenarios and tried out various combinations of inputs and actions to uncover any unexpected behavior.\nThe results of your testing were quite significant. You came across usability issues, including navigation paths and inconsistencies, in error messaging. By reporting these issues, you were able to address them before launching the platform, thus improving the user experience.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "58. How do you ensure that your test cases are robust and cover various scenarios adequately?",
        "answer": "To ensure that the test cases are robust, you follow an approach. First, you thoroughly analyze the project requirements. Work closely with stakeholders. You make sure to understand the requirements in detail and identify user scenarios that match them with test cases.\nYour goal is to cover a range of scenarios, including negative and boundary cases. This way, you can validate how the application behaves under certain conditions. You also consider edge cases and real-world user interactions to improve the coverage of your testing.\nRegular reviews and feedback sessions with colleagues and experts in the domain help ensure that your test cases are comprehensive and cover all scenarios. Additionally, you use techniques, like equivalence partitioning and boundary value analysis, to refine and optimize your test cases.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "59. What strategies do you use to manage and prioritize defects during the testing process?",
        "answer": "During the testing process, you follow an approach to effectively handle and prioritize issues. First, you promptly document all identified problems by providing descriptions, step-by-step instructions for reproduction, and assessments of their severity.\nYou classify the issues according to how they affect the functionality of the application and assign them priorities such as critical, high, medium, or low. Critical defects that significantly impact core functionalities are given priority. Next in line are high-risk issues and those that have an impact on the user experience.\nThrough collaboration with developers and stakeholders, you ensure communication regarding the status of each issue, estimated timelines for resolution, and any dependencies involved. Regular triage meetings help determine which issues should be tackled first based on project goals, risk factors involved, and available resources. This approach ensures that critical problems are addressed promptly in order to keep the project moving.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "60. Can you discuss a challenging defect you encountered in your previous projects and how you resolved it?",
        "answer": "In a project, I came across a problem with the payment processing module of a banking application. Users complained about failures when transferring funds between accounts, which caused discrepancies in transactions and left customers unhappy.\nTo tackle this issue, I conducted investigations and tests by examining server logs, transaction records and system interactions. By working with developers and conducting regression testing, I discovered a problem related to concurrency in the payment processing logic that only occurred under specific load conditions.\nFixing the defect required refactoring the code. Enhancing synchronization to ensure both thread safety and transaction integrity. Once the fixes were implemented, I carried out testing and validation to ensure that the solution was stable and correct. In the end, we successfully resolved the defect, restoring reliability and trustworthiness to the application.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "61. How do you handle test data management and ensure data integrity during testing?",
        "answer": "Effective management of test data is vital to ensure the accuracy and reliability of testing results. To handle test data efficiently, you employ a combination of strategies and tools, for generating, manipulating and cleaning up data.\nYou collaborate closely with stakeholders to identify scenarios for test data that encompass application functionalities and edge cases. Utilizing tools or scripts for data generation, you create datasets that represent user profiles, input scenarios and system configurations.\nTo maintain the integrity of the data, you ensure isolation and separation between test environments to prevent any cross contamination or interference. Additionally, you implement techniques, such as data masking or anonymization to safeguard information and comply with privacy regulations.\nRegular sanity checks and validation procedures are conducted to verify the consistency and accuracy of the data throughout the testing lifecycle. Automated scripts or utilities for cleaning up data streamline management tasks while ensuring that test environments remain clean.\nBy adopting these practices, you guarantee that your test data remains reliable and relevant. This enables testing and accurate validation of application functionalities.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "62. How do you perform automated testing in your environment?",
        "answer": "Automation testing is a process of executing tests automatically. It reduces human intervention to a great extent. We use different test automation tools like QTP, Selenium, and WinRunner. Testing tools help in speeding up the testing tasks. These tools allow you to create test scripts to verify the application automatically and also to generate the test reports.\nPreparing for a Job Interview! Check out our blog on Selenium Interview Questions now.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "63. Is there any difference between quality assurance, quality control, and software testing. If so, what is it?",
        "answer": "Quality Assurance (QA) refers to the planned and systematic way of monitoring the quality of the process which is followed to produce a quality product. QA tracks the test reports and modifies the process to meet the expectation.\nQuality Control (QC) is relevant to the quality of the product. QC not only finds the defects but suggests improvements too. Thus, a process that is set by QA is implemented by QC. QC is the responsibility of the testing team.\nSoftware testing is the process of ensuring that the product which is developed by developers meets the users’ requirements. The aim of performing testing is to find bugs and make sure that they get fixed. Thus, it helps to maintain the quality of the product to be delivered to the customer.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "64. Can you explain the principles of black-box testing and white-box testing, and when would you use each approach?",
        "answer": "Black box testing evaluates software functionality without knowledge of the code structure.  Testers verify system behavior by examining inputs and outputs simulating user interactions. This approach is ideal for validating requirements. Ensure that the software satisfies the user’s expectations.\nIn contrast, white-box testing involves analyzing the structure and logic of the software. Testers have access to the source code and design, enabling them to create test cases based on code paths and coverage. This method is valuable for identifying errors in code implementation and ensuring coverage.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "65. How do you verify data integrity and accuracy during manual testing of database-driven applications?",
        "answer": "To ensure the integrity and accuracy of data, in testing  applications driven by databases, you conduct checks:\nCompare the data entered through the application, with the data stored in the database to make sure they are consistent.\nValidate that data transformations and calculations are correct.\nVerify that any updates or deletions of data are accurately reflected in the database.\nPerform testing to ensure that data inputs within specified ranges are handled appropriately.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "66. Can you explain the importance of SQL queries in manual testing, and provide an example of how you've used SQL queries to validate data in a testing scenario?",
        "answer": "SQL queries play a crucial role in testing because they allow direct access to the database, making it easier to validate the accuracy and integrity of data. For example, in an e-commerce setting, you can utilize SQL queries to fetch order details from the database and compare them against expected values.\nTo illustrate, consider this query:\n“SELECT * FROM Orders WHERE OrderID = ‘834’;” \nThis particular query retrieves order details so that you can ensure that the recorded information aligns with what’s anticipated based on the test scenario. By conducting validation, we guarantee that orders are processed and recorded correctly within the system.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "67. Describe your experience with database testing. What types of SQL queries do you commonly use to retrieve and manipulate data for testing purposes?",
        "answer": "In the field of database testing, you possess expertise in validating the integrity, functionality, and performance of data. You employ SQL queries to retrieve and manipulate data, guaranteeing its precision and reliability. This involves executing a range of query types, like retrieval, modification, aggregation, and join queries, to cover testing scenarios. Additionally, you verify the integrity constraints on the data. Conduct validation of applications driven by databases to ensure they fulfill all requirements.\nCommonly used SQL queries in manual testing are:\nSELECT: This query is used to retrieve data, for validation and verification purposes.\nINSERT: It allows you to add test data to the database.\nUPDATE: This query helps in modifying existing data and testing scenarios that involve updating data.\nDELETE: It is used to remove test data once the testing process is complete.\nJOIN: This query enables you to retrieve data from tables, which proves useful for testing.\nAGGREGATE FUNCTIONS (e.g., COUNT, SUM, AVG): These functions are employed for performing calculations and validating data.\nCONSTRAINTS (UNIQUE, NOT NULL): They ensure the integrity of the data. Enforce business rules.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "68. Can you explain the difference between positive testing and negative testing in manual testing, and provide examples of when you would use each approach?",
        "answer": "Testing can be categorized into two types:\n Positive testing\n Negative testing\nPositive testing involves validating the system using inputs to ensure it performs as expected. An example of testing is entering an email address during the login process.\nOn the other hand, negative testing focuses on validating the system using inputs or unexpected conditions to assess how it handles errors gracefully. For instance, entering a password during a login falls under testing.\nPositive testing predominantly aims to confirm expected behaviors, while negative testing plays a role in assessing error handling and resilience capabilities. Both types of testing are essential for achieving coverage in software testing.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "69. Tell me about some of the essential qualities an experienced QA or Test Lead must possess.",
        "answer": "A QA or Test Lead should have the following qualities:\nWell-versed in software testing processes\nAbility to accelerate teamwork to increase productivity\nImprove coordination between QA and Dev engineers\nProvide ideas to refine QA processes\nSkill to conduct RCA meetings and draw conclusions\nExcellent written and interpersonal communication skills\nAbility to learn fast and to groom the team members",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "70. What is the difference between performance testing and monkey testing?",
        "answer": "Performance Testing checks the speed, scalability, maybe even the stability characteristics of a system. Performance is identified with achieving response time, throughput, and resource-utilization levels that meet the performance objectives for a project or a product.\nMonkey testing is a technique in software testing where the user tests the application by providing random inputs, checking the behavior of the application (or trying to crash the application).\n\nScenario Based Manual Testing Interview Questions",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "71. How do you ensure effective communication and collaboration between testing and development teams during the software development lifecycle?",
        "answer": "To ensure communication and collaboration, between the testing and development teams throughout the software development lifecycle, strategies include:\nMeetings: We schedule meetings, such as daily stand-ups and sprint planning sessions, to encourage open communication and alignment regarding project goals and progress.\nDocumentation: We maintain regularly updated documentation, including test plans, user stories, and bug reports. This ensures that everyone involved has a shared understanding of the requirements and priorities.\nUtilization of Collaboration Tools: We leverage collaboration tools like Slack, Microsoft Teams, or project management platforms such as Jira. These tools facilitate real time communication, file sharing, and issue tracking for collaboration.\nCross-Functional Teams: We foster an environment by promoting functional teams where testers and developers work closely together throughout the entire development process. This approach encourages a sense of ownership and collective responsibility for maintaining product quality.\nContinuous Feedback: Timely feedback is crucial in our process. We provide feedback on test results, bug fixes and feature implementations to nurture a culture of improvement and iteration, within our teams. This enables us to address issues while enhancing product quality.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "72. What strategies do you employ for ensuring comprehensive test coverage, particularly in large and complex software systems?",
        "answer": "To ensure testing of complex software systems it is important to follow a systematic approach. Here are some strategies that can be employed:\nRequirement Analysis: Carefully examine the project requirements to identify all aspects, both non functional that require testing.\nRisk Based Testing: Prioritize testing efforts based on risk assessment. This involves focusing on functionalities and areas that’re more likely to have defects.\nTest Planning: Develop test plans that outline the objectives, scope, available resources and timelines. It is essential to cover all aspects of the testing process.\nTest Case Design: Create test cases that encompass a range of scenarios such as positive, negative, boundary and edge cases.\nAutomation Testing: Implement automated tests for tasks like regression testing and performance testing. This does not increase test coverage. Also improves efficiency.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "73. How do you ensure thorough test coverage in a manual testing scenario, particularly when dealing with complex software functionalities?",
        "answer": "To achieve test coverage in a testing scenario particularly when dealing with complex software functionalities there are several strategies that can be employed:\nUnderstanding the Requirements; It is crucial to comprehend the project requirements in order to identify functionalities and potential edge cases that necessitate testing.\nCreating a Comprehensive Test Plan; Developing a test plan is essential. This plan should outline objectives, scope, available resources and timelines. Test scenarios should be prioritized based on their criticality and complexity.\nDesigning Detailed Test Cases; The creation of test cases is paramount. These test cases should encompass scenarios such, as negative, boundary and edge cases.\nConducting Exploratory Testing: This approach helps us discover any defects that might have slipped through unnoticed otherwise.\nImplementing Risk Based Testing; Prioritizing testing efforts based on risk assessment is essential for resource allocation. Critical functionalities and areas prone to defects should receive attention in terms of time and resources in order to ensure coverage.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "74. How do you use SQL queries to validate data integrity and accuracy during manual testing, and can you provide an example of how you've used SQL queries to verify data in a testing scenario?",
        "answer": "To validate data integrity and accuracy during manual testing using SQL queries, testers follow a systematic approach:\nUnderstanding the Data Requirements: It is important to have an understanding of what data needed and what outcomes are expected for the testing scenario.\nCreating SQL Queries: Develop SQL queries that can retrieve the data from the database tables based on the requirements of the testing scenario.\nComparing Data: Execute the SQL queries to retrieve data from the database and then compare it with the expected data in order to ensure accuracy and integrity.\nVerifying Constraints: Validate data integrity constraints, such as ensuring uniqueness, maintaining relationships and confirming appropriate data types. This can be done using SQL queries.\nExample Scenario: Let’s take an example related to an e-commerce application. Using SQL queries, we can verify that when a successful purchase transaction occurs there is a decrease in the quantity of items in the inventory table. \nTo do this, we will write a SQL query to get the quantity of a product from the database. After simulating a purchase transaction,  we would execute another query to confirm that the quantity has been decremented by an amount.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "75. When performing SQL manual testing, what are some common challenges you've faced, and how have you overcome them to ensure effective testing of database-driven applications?",
        "answer": "When it comes to testing of SQL, you encounter a common challenges:\nDealing with Complex Query Execution: Writing and executing SQL queries to validate data scenarios can be quite a challenge.\nEnsuring Data Integrity: It can be tricky to maintain accurate test data throughout the testing process, especially when dealing with datasets.\nOptimizing Performance: Identifying and optimizing SQL queries for performance can pose a challenge in situations involving large databases or complex data retrieval operations.\nManaging Data Dependencies: Handling data dependencies between test cases or scenarios can be tricky, particularly when making changes to interconnected data.\nTo tackle these challenges and ensure the testing of applications driven by databases, you utilize a range of strategies, including:\nThorough Planning: Meticulously plan test scenarios and queries in advance to address obstacles and achieve coverage.\nTest Data Management: Maintain organized and representative sets of test data, utilizing appropriate tools or scripts, for data generation and manipulation as required.\nImproving Query Performance: Optimize SQL queries for performance by analyzing query execution plans, employing indexing strategies, and optimizing database configurations.\nVersion Control Implementation: Implement version control for database schemas and scripts to track changes and enable rollback if necessary during the testing phase.\nCollaboration: Close collaboration with developers and stakeholders is crucial. By understanding the application logic, data models, and requirements, we ensure alignment and effective communication, throughout the testing process.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "76. How would you test the login page to ensure it properly handles invalid credentials? Describe the steps you would take and any expected outcomes.",
        "answer": "To ensure the login page handles invalid credentials effectively:\nSet up the Test Environment: Ensure the application is deployed and accessible for testing.\nDefine Test Cases: Create test cases covering various scenarios of invalid credentials, such as incorrect username/password and blank fields.\nExecute Tests: Enter invalid credentials into the login form and submit it to observe the application’s response.\nObserve Behavior: Verify if appropriate error messages are displayed for different types of invalid credentials.\nAnticipated Results: Be prepared to receive error notifications that specify the type of input, like “Username or password’s invalid” or “Password entered is incorrect.”\nDocument Results: Record observed behavior and any deviations from expected outcomes.\nRepeat Testing: Perform testing for all identified scenarios to ensure thorough coverage.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "77. How would you test the product search functionality to ensure it returns accurate results? Explain your approach and any test cases you would consider.",
        "answer": "To ensure the product search functionality delivers accurate results, employ the following SEO-friendly approach:\nTest Preparation: Ensure accessibility of the application and the availability of the search feature.\nPositive Test Scenarios:\nValid Search Term: Test with precise search terms matching existing products for accurate results.\nPartial Match: Validate the functionality with partial search terms, ensuring relevant products are displayed.\nCase Insensitivity: Confirm case insensitivity in search terms for a seamless user experience.\nCategory-based Search: Validate search within specific categories for tailored results.\nPrice Range Search: Ensure the accurate display of products falling within specified price ranges.\nNegative Test Scenarios:\nInvalid Search Term: Test with nonexistent or invalid search terms, ensuring appropriate error messages are shown.\nEmpty Search: Validate the application’s response when the search field is empty, prompting users to input search terms.\nSpecial Characters Handling: Verify the graceful handling of special characters, providing meaningful feedback.\nPagination Testing:\nEfficient Navigation: Assess pagination functionality with large result sets, ensuring smooth navigation between pages.\nPerformance Evaluation:\nLoad Testing: Gauge performance under varying loads to ensure swift response times.\nResponse Time Analysis: Measure response times, adhering to acceptable thresholds for an optimal user experience.\nCross Device Testing:\nConsistent Experience: Verify functionality across browsers and devices to maintain consistency and accessibility.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "78. Walk me through the testing process for the checkout process. What aspects would you focus on to ensure a smooth and error-free transaction?",
        "answer": "When aiming for an accurate checkout experience, keep these points in mind:\nPreparation: Ensure the website is accessible and the checkout feature is operational.\nTest Scenarios:\nAdding Items to Cart: Confirm the ability to add items from product pages.\nCart Review: Validate the accuracy of displayed items, quantities, and prices.\nUser Authentication: Test login and guest checkout options.\nAddress Entry: Verify address form validation and error handling.\nShipping Options: Ensure correct options based on the entered address.\nPayment Methods: Test secure processing and error handling for various payment methods.\nOrder Summary: Confirm the accuracy of the order details.\nOrder Confirmation: Validate the generation of order pages and emails.\nEdge Cases:\nOut-of-stock Items: Test handling for unavailable items during checkout.\nPartial Payments: Validate split payment capabilities.\nSession Timeouts: Ensure data retention during session timeouts.\nNetwork Failures: Test error recovery during transaction processing.\nPerformance Testing:\nLoad Testing: Assess responsiveness under different loads.\nTransaction Time Analysis: Measure processing times to ensure efficiency.\nSecurity Testing:\nData Encryption: Verify the secure transmission of sensitive information.\nPayment Gateway Integration: Validate integration with secure payment gateways.\nCross Device Testing:\nBrowser Compatibility: Test across browsers for consistency.\nDevice Compatibility: Validate usability on different devices for responsiveness.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "79. How would you test the user registration process to ensure it functions correctly? What validations and verifications would you perform?",
        "answer": "To ensure the user registration process works flawlessly, consider the following steps:\nSetup: Ensure the registration feature is accessible and operational.\nPositive Tests:\nValid Registration: Verify the successful registration with the correct details.\nUsername Uniqueness: Confirm usernames are unique.\nPassword Strength: Validate password complexity requirements for security.\nEmail Validation: Ensure correct email formatting and validation.\nConfirmation Email: Verify users receive confirmation emails post-registration.\nNegative Tests:\nInvalid Email Format: Test registration with incorrectly formatted emails.\nExisting Username: Attempt registration with an already used username.\nWeak Password: Test with passwords that do not meet complexity criteria.\nEmpty Fields: Validate mandatory fields and corresponding error messages for empty inputs.\nEdge Cases:\nLong Username/Password: Test with unusually long inputs for system stability.\nSpecial Characters: Validate registration with special characters in inputs.\nSession Timeout: Ensure registration can be completed after session timeouts.\nPerformance:\nLoad Testing: Assess registration performance under different loads.\nResponse Time: Measure response times for prompt feedback.\nSecurity:\nData Encryption: Ensure sensitive data encryption during storage.\nSQL Injection: Test for protection against SQL injection attacks.\nCross Device Testing:\nBrowser Compatibility: Validate across browsers for consistency.\nDevice Compatibility: Test on various devices for responsiveness.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "80. Describe your approach to testing form submissions to ensure data validation. How would you handle scenarios where invalid data is entered?",
        "answer": "To effectively test form submissions for data validation, consider the following SEO-friendly approach:\nUnderstanding Requirements: Gain clarity on form requirements, including mandatory fields and validation rules.\nPositive Test Cases:\nEnter valid data according to the specified requirements.\nConfirm successful form submission and accurate data processing.\nNegative Test Cases:\nInput invalid data that violates validation rules.\nValidate appropriate error messages indicating validation failures.\nEdge Cases:\nTest extreme or boundary scenarios to ensure robust validation.\nAssess behavior with unexpected inputs or special characters.\nCross device Testing:\nValidate form submissions across browsers and devices.\nEnsure responsiveness and usability across several screen sizes.\nHandling Invalid Data Scenarios:\nProvide clear error messages with corrective actions.\nImplement client-side validation for immediate feedback.\nValidate data on the client and server sides for integrity.\nLog and track validation errors for resolution.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "81. How do you test error handling mechanisms to ensure users receive meaningful error messages? Provide examples of error scenarios you would test.",
        "answer": "To ensure users receive meaningful error messages, follow this SEO-friendly approach to test error handling mechanisms:\nUnderstand Requirements: Clarify expected behaviors and error messages outlined in requirements or design documents.\nPositive Test Cases:\nConfirm that no unnecessary error messages are displayed during valid actions like form submissions or navigation.\nNegative Test Cases:\nIntentionally trigger errors by providing incorrect inputs or accessing restricted features.\nValidate appropriate error messages explaining errors and suggesting fixes.\nEdge Cases:\nTest extreme scenarios like data exceeding limits or unexpected server responses.\nEvaluate application responses and error messages in these situations.\nCross Device Testing:\nEnsure error handling consistency across browsers and devices.\nVerify usability on different screen sizes.\nSpecific Error Scenarios:\nTest scenarios like invalid login credentials or unauthorized resource access.\nValidate the handling of network issues or input validation errors in forms.",
        "reference": "intellipaat.com",
        "role": "manual-testing"
    },
    {
        "question": "1. Explain Test Driver and Test Stub.",
        "answer": "A test driver and a test stub are both types of test harnesses that simulate an environment for testing a module or component. Both are dummy modules designed specifically for testing. Test stubs: A test stub is used in a top-down testing approach and allows testing of the upper levels of code when the lower code levels have not been developed yet. It serves as a 'called program' when subprograms are being developed. \nTest drivers: A test driver is used in a bottom-up testing approach and allows testing of the lower levels of the code when the upper code levels have not been developed yet. It serves as a 'called program' when main programs are being developed. Test stubs: A test stub is used in a top-down testing approach and allows testing of the upper levels of code when the lower code levels have not been developed yet. It serves as a 'called program' when subprograms are being developed. Test stubs: Test drivers: A test driver is used in a bottom-up testing approach and allows testing of the lower levels of the code when the upper code levels have not been developed yet. It serves as a 'called program' when main programs are being developed. Test drivers:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "2. What are the advantages and Disadvantages of Manual Testing?",
        "answer": "Advantages of Manual Testing Advantages of Manual Testing Preferable for products with a short life cycle.\nSaves time, money, and resources.\nEnsure the error-free product.\nUsable for exploratory testing, ad hoc testing, and usability testing.\nNo need to change the entire code to make minor changes. \nGet accurate user interface feedback.  \nAbility to handle difficult use case situations in a better way. \nGUI testing can be done accurately.\nHighly reliable. \nMake user-friendliness better. \nEasy to learn for new testers. Preferable for products with a short life cycle. Saves time, money, and resources. Ensure the error-free product. Usable for exploratory testing, ad hoc testing, and usability testing. No need to change the entire code to make minor changes. Get accurate user interface feedback. Ability to handle difficult use case situations in a better way. GUI testing can be done accurately. Highly reliable. Make user-friendliness better. Easy to learn for new testers. Disadvantages of Manual Testing Disadvantages of Manual Testing Not suitable for time-bounded projects and large organizations  \nMore prone to human errors and mistakes \nLess efficient as the choice of recording the testing process is not available \nLess Reliable \nRegression testing is time-consuming \nDoes not cover all the aspects of testing \nLoad testing and performance testing can be performed manually \nMore expensive in the long run process Not suitable for time-bounded projects and large organizations More prone to human errors and mistakes Less efficient as the choice of recording the testing process is not available Less Reliable Regression testing is time-consuming Does not cover all the aspects of testing Load testing and performance testing can be performed manually More expensive in the long run process",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "3. Name some of the manual testing tools.",
        "answer": "Some of the top manual testing tools include: manual testing manual testing Postman\nMessage queue monitors\nDB tools, etc. Postman Message queue monitors DB tools, etc.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "4. What types of manual testing are there?",
        "answer": "In the course of the test life cycle, there are different manual testing types or manual testing techniques that may be used. Following is a list of them:   Black Box Testing\nWhite Box Testing\nUnit Testing\nSystem Testing\nIntegration Testing\nAcceptance Testing Black Box Testing White Box Testing Unit Testing System Testing Integration Testing Acceptance Testing",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "5. Who is a manual tester? Write its roles and responsibilities.",
        "answer": "The manual tester is a professional who conducts quality checks on software applications without using automation tools or scripting. In essence, the speciality involves manually checking software for errors and fixing them. Manual testers must have the appropriate skills and be able to meet the company's requirements. Manual Tester Roles and Responsibilities Manual Tester Roles and Responsibilities Analyzing client requirements.\nReviewing written code for compliance with project specifications.\nCreating a test environment for executing test cases.\nEstablishing quality assurance strategies and organizing phased testing.\nOrganizing and conducting review meetings.\nExecuting and analyzing test cases.\nDetecting and fixing bugs.\nMonitor system errors and discuss them with colleagues.\nKeeping in touch with the test manager, etc. Analyzing client requirements. Reviewing written code for compliance with project specifications. Creating a test environment for executing test cases. Establishing quality assurance strategies and organizing phased testing. Organizing and conducting review meetings. Executing and analyzing test cases. Detecting and fixing bugs. Monitor system errors and discuss them with colleagues. Keeping in touch with the test manager, etc.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "6. Describe the manual testing process.",
        "answer": "Among the steps involved in manual testing are:   Requirement analysis\nTest plan creation\nDesign test scenarios and test cases\nTest execution and defect reporting\nEvaluating exit criteria and reporting\nTest closure activities Requirement analysis Test plan creation Design test scenarios and test cases Test execution and defect reporting Evaluating exit criteria and reporting Test closure activities",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "7. Can you tell me what the different levels of manual testing are?",
        "answer": "Different levels of testing can be carried out during the development process. Multilevel testing facilitates the identification of bugs early in the development process. The four levels of testing are as follows:   Unit testing: Essentially, it is a way of testing logically isolated pieces of code within a system called units. Mainly, it focuses on the standalone module's functional accuracy.\nIntegration Testing: Software testing at this level involves combining and testing individual units to see if they work together as they should. This test focuses on the interface between modules.\nSystem Testing: It involves testing all components of the product as a whole to ensure that overall product requirements are met. The types of system testing include regression testing, usability testing, and functional testing.\nUser Acceptance Testing: Acceptance testing, also known as UAT (User Acceptance Testing), is the final step in the software testing process. This test determines if the software is ready for release. Unit testing: Essentially, it is a way of testing logically isolated pieces of code within a system called units. Mainly, it focuses on the standalone module's functional accuracy. Unit testing: Integration Testing: Software testing at this level involves combining and testing individual units to see if they work together as they should. This test focuses on the interface between modules. Integration Testing: System Testing: It involves testing all components of the product as a whole to ensure that overall product requirements are met. The types of system testing include regression testing, usability testing, and functional testing. System Testing: User Acceptance Testing: Acceptance testing, also known as UAT (User Acceptance Testing), is the final step in the software testing process. This test determines if the software is ready for release. User Acceptance Testing:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "8. In order to perform manual testing, what skills are required?",
        "answer": "The following are the important manual testing skills to acquire: Detail-oriented and able to report test results in a professional manner.\nA strong analytical ability.\nAbility to perform technical testing.\nFamiliarity with Agile methodologies.\nPlan and track the testing process.\nKnowledge of SDLC, STLC, SQL, and manual concepts.\nAn understanding of test management tools, test tracking tools, and testing techniques. Detail-oriented and able to report test results in a professional manner. A strong analytical ability. Ability to perform technical testing. Familiarity with Agile methodologies. Plan and track the testing process. Knowledge of SDLC, STLC, SQL, and manual concepts. An understanding of test management tools, test tracking tools, and testing techniques.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "9. What is the difference between developer vs tester?",
        "answer": "Software developers and testers differ in the following ways:   Developer Tester\nSoftware developers write and maintain source code for computer programming. A software tester is responsible for identifying the quality, correctness, and completeness of software.\nIts responsibility is to create individual software applications. Its responsibility is to evaluate individual software programs.\nBasically, it involves developing software through successive phases in an orderly manner. This test evaluates how well a software application works.\nThey solve problems quickly, reduce costs, increase flexibility, and improve the quality of business. By reporting problems as soon as possible, they help save money, provide security, and ensure the quality of the software.\nAdditionally, they provide suggestions on how to improve software applications. Not only do they find bugs, but they also identify their root causes, so bugs can be permanently fixed.\nCoding skills, time management skills, and programming skills are all essential for developers. An ideal tester should be well versed in the system being developed, possess good communication skills, be a critical thinker, etc.\nAs part of the software development process, they mostly focus on the requirements of the users. In testing software applications, they are primarily concerned with the behavior of the end-user. Developer Tester\nSoftware developers write and maintain source code for computer programming. A software tester is responsible for identifying the quality, correctness, and completeness of software.\nIts responsibility is to create individual software applications. Its responsibility is to evaluate individual software programs.\nBasically, it involves developing software through successive phases in an orderly manner. This test evaluates how well a software application works.\nThey solve problems quickly, reduce costs, increase flexibility, and improve the quality of business. By reporting problems as soon as possible, they help save money, provide security, and ensure the quality of the software.\nAdditionally, they provide suggestions on how to improve software applications. Not only do they find bugs, but they also identify their root causes, so bugs can be permanently fixed.\nCoding skills, time management skills, and programming skills are all essential for developers. An ideal tester should be well versed in the system being developed, possess good communication skills, be a critical thinker, etc.\nAs part of the software development process, they mostly focus on the requirements of the users. In testing software applications, they are primarily concerned with the behavior of the end-user. Developer Tester Developer Tester Developer Tester Software developers write and maintain source code for computer programming. A software tester is responsible for identifying the quality, correctness, and completeness of software.\nIts responsibility is to create individual software applications. Its responsibility is to evaluate individual software programs.\nBasically, it involves developing software through successive phases in an orderly manner. This test evaluates how well a software application works.\nThey solve problems quickly, reduce costs, increase flexibility, and improve the quality of business. By reporting problems as soon as possible, they help save money, provide security, and ensure the quality of the software.\nAdditionally, they provide suggestions on how to improve software applications. Not only do they find bugs, but they also identify their root causes, so bugs can be permanently fixed.\nCoding skills, time management skills, and programming skills are all essential for developers. An ideal tester should be well versed in the system being developed, possess good communication skills, be a critical thinker, etc.\nAs part of the software development process, they mostly focus on the requirements of the users. In testing software applications, they are primarily concerned with the behavior of the end-user. Software developers write and maintain source code for computer programming. A software tester is responsible for identifying the quality, correctness, and completeness of software. Software developers write and maintain source code for computer programming. A software tester is responsible for identifying the quality, correctness, and completeness of software. Its responsibility is to create individual software applications. Its responsibility is to evaluate individual software programs. Its responsibility is to create individual software applications. Its responsibility is to evaluate individual software programs. Basically, it involves developing software through successive phases in an orderly manner. This test evaluates how well a software application works. Basically, it involves developing software through successive phases in an orderly manner. This test evaluates how well a software application works. They solve problems quickly, reduce costs, increase flexibility, and improve the quality of business. By reporting problems as soon as possible, they help save money, provide security, and ensure the quality of the software. They solve problems quickly, reduce costs, increase flexibility, and improve the quality of business. By reporting problems as soon as possible, they help save money, provide security, and ensure the quality of the software. Additionally, they provide suggestions on how to improve software applications. Not only do they find bugs, but they also identify their root causes, so bugs can be permanently fixed. Additionally, they provide suggestions on how to improve software applications. Not only do they find bugs, but they also identify their root causes, so bugs can be permanently fixed. Coding skills, time management skills, and programming skills are all essential for developers. An ideal tester should be well versed in the system being developed, possess good communication skills, be a critical thinker, etc. Coding skills, time management skills, and programming skills are all essential for developers. An ideal tester should be well versed in the system being developed, possess good communication skills, be a critical thinker, etc. As part of the software development process, they mostly focus on the requirements of the users. In testing software applications, they are primarily concerned with the behavior of the end-user. As part of the software development process, they mostly focus on the requirements of the users. In testing software applications, they are primarily concerned with the behavior of the end-user.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "10. What is test coverage?",
        "answer": "Test coverage is a metric that indicates how much of the source code is covered by the tests, allowing the tester to verify the quality of their testing. Testers can use it to determine whether they're testing everything they're supposed to. Depending on the way people approach testing, test coverage can mean different things to different people. Product: It means looking at test coverage to answer the question: Which features or areas of the software do your tests cover?\nRequirements: The software might work well, but it's not useful to the customer if it doesn't satisfy their needs. Requirements coverage indicates how many of the requirements are tested.\nSource Code: This is usually a developer's domain and is a white-box testing technique. The developer can check how much of their source code is covered by the unit tests. Product: It means looking at test coverage to answer the question: Which features or areas of the software do your tests cover? Product: Requirements: The software might work well, but it's not useful to the customer if it doesn't satisfy their needs. Requirements coverage indicates how many of the requirements are tested. Requirements: Source Code: This is usually a developer's domain and is a white-box testing technique. The developer can check how much of their source code is covered by the unit tests. Source Code:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "11. Name some methods that can be used in code coverage.",
        "answer": "Code coverage is a software testing metric that measures how many blocks, lines, or arcs of code are executed when a test suite runs. Code coverage can be determined by several methods, including: Statement Coverage.\nDecision Coverage.\nBranch Coverage.\nToggle Coverage. Statement Coverage. Decision Coverage. Branch Coverage. Toggle Coverage.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "12. Define Latent Defect.",
        "answer": "Latent defect, as the name suggests, is a type of defect or bug which has been in the software system for a long time but is discovered now. A latent defect is an existing defect that can be found effectively with inspections. It usually remains hidden or dormant and is a low-priority defect.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "13. Name some attributes of the test case.",
        "answer": "There are various attributes of test cases that make them more reliable, clear, and concise, avoiding any sort of redundancy. Some of them are given below: Test Case Id: Unique identifier of the test case.\nTest Summary: One-liner summary of the test case.\nDescription: Detailed description of the test case.\nPrerequisite or pre-condition: Set of conditions to be followed before implementing the test steps.\nTest Steps: Detailed steps for performing test cases.\nTest Data: Test data value used in the test case.\nExpected Result: Estimated result to pass the test.\nActual Result: Actual result after executing the test steps.\nTest Result: Status of the test execution (Pass or Fail).\nAutomation Status: Identifier for automation.\nDate: Test execution date.\nExecuted By: Person name executing the test case. Test Case Id: Unique identifier of the test case. Test Case Id: Test Summary: One-liner summary of the test case. Test Summary: Description: Detailed description of the test case. Description: Prerequisite or pre-condition: Set of conditions to be followed before implementing the test steps. Prerequisite or pre-condition: Test Steps: Detailed steps for performing test cases. Test Steps: Test Data: Test data value used in the test case. Test Data: Expected Result: Estimated result to pass the test. Expected Result: Actual Result: Actual result after executing the test steps. Actual Result: Test Result: Status of the test execution (Pass or Fail). Test Result: Automation Status: Identifier for automation. Automation Status: Date: Test execution date. Date: Executed By: Person name executing the test case. Executed By:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "14. What is Positive and Negative Testing?",
        "answer": "Positive Testing: It is a type of testing process where a software application is validated against the valid data sets as input. It is simply used to check whether the application does what it is supposed to do or not. Positive Testing: It is a type of testing process where a software application is validated against the valid data sets as input. It is simply used to check whether the application does what it is supposed to do or not. Positive Testing:   Negative Testing: It is a type of testing process where a software application is validated against invalid data sets as input. It is simply used to check whether the system shows an error when it is supposed to do or not. In test case execution, negative testing is considered a very crucial factor. Negative Testing: It is a type of testing process where a software application is validated against invalid data sets as input. It is simply used to check whether the system shows an error when it is supposed to do or not. In test case execution, negative testing is considered a very crucial factor. Negative Testing:   Positive vs Negative Testing Positive vs Negative Testing Positive Testing  Negative Testing\nIt tests the application or system by giving valid data.  It tests the application or system by giving invalid data. \nIt accepts all the numeric and alphabetic values.  It does not accept any special character. \nThis type of testing is performed to identify a known set of test conditions. This type of testing is performed to identify an unknown set of test conditions. \nIt is usually performed on each and every application.   It is usually performed where the chances of unexpected conditions or errors are more. \nIt requires less time and can be performed by people having less knowledge.   It requires more time and can only be performed by professionals.  \nIt makes sure that the software application is normal.   It makes sure that the software applications are 100% detect-free.\nIt does not encompass all the possible cases.  It encompasses all the possible cases.\nIt is less significant or vital than negative testing.  It is more significant and vital than positive testing. Positive Testing  Negative Testing\nIt tests the application or system by giving valid data.  It tests the application or system by giving invalid data. \nIt accepts all the numeric and alphabetic values.  It does not accept any special character. \nThis type of testing is performed to identify a known set of test conditions. This type of testing is performed to identify an unknown set of test conditions. \nIt is usually performed on each and every application.   It is usually performed where the chances of unexpected conditions or errors are more. \nIt requires less time and can be performed by people having less knowledge.   It requires more time and can only be performed by professionals.  \nIt makes sure that the software application is normal.   It makes sure that the software applications are 100% detect-free.\nIt does not encompass all the possible cases.  It encompasses all the possible cases.\nIt is less significant or vital than negative testing.  It is more significant and vital than positive testing. Positive Testing  Negative Testing Positive Testing  Negative Testing Positive Testing Negative Testing It tests the application or system by giving valid data.  It tests the application or system by giving invalid data. \nIt accepts all the numeric and alphabetic values.  It does not accept any special character. \nThis type of testing is performed to identify a known set of test conditions. This type of testing is performed to identify an unknown set of test conditions. \nIt is usually performed on each and every application.   It is usually performed where the chances of unexpected conditions or errors are more. \nIt requires less time and can be performed by people having less knowledge.   It requires more time and can only be performed by professionals.  \nIt makes sure that the software application is normal.   It makes sure that the software applications are 100% detect-free.\nIt does not encompass all the possible cases.  It encompasses all the possible cases.\nIt is less significant or vital than negative testing.  It is more significant and vital than positive testing. It tests the application or system by giving valid data.  It tests the application or system by giving invalid data. It tests the application or system by giving valid data. It tests the application or system by giving invalid data. It accepts all the numeric and alphabetic values.  It does not accept any special character. It accepts all the numeric and alphabetic values. It does not accept any special character. This type of testing is performed to identify a known set of test conditions. This type of testing is performed to identify an unknown set of test conditions. This type of testing is performed to identify a known set of test conditions. This type of testing is performed to identify an unknown set of test conditions. It is usually performed on each and every application.   It is usually performed where the chances of unexpected conditions or errors are more. It is usually performed on each and every application. It is usually performed where the chances of unexpected conditions or errors are more. It requires less time and can be performed by people having less knowledge.   It requires more time and can only be performed by professionals. It requires less time and can be performed by people having less knowledge. It requires more time and can only be performed by professionals. It makes sure that the software application is normal.   It makes sure that the software applications are 100% detect-free. It makes sure that the software application is normal. It makes sure that the software applications are 100% detect-free. It does not encompass all the possible cases.  It encompasses all the possible cases. It does not encompass all the possible cases. It encompasses all the possible cases. It is less significant or vital than negative testing.  It is more significant and vital than positive testing. It is less significant or vital than negative testing. It is more significant and vital than positive testing.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "15. What is UAT (User Acceptance Testing)?",
        "answer": "A user acceptance test, also known as an end-user test, is a testing methodology undertaken by the client or end-user to approve the production release. As the last step in the SDLC, it takes place only after testing the software thoroughly. This tool is primarily used to validate end-to-end business processes. It verifies whether or not the developed software is ready to float into the market.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "16. What is Manual Testing?",
        "answer": "In manual testing, a tester manually verifies the functionality of the software. The tester has a comprehensive list of all the manual testing test cases they should test, along with the test data. They go through each case, one by one. They launch the software as an end-user would, enter the input, and manually verify the output. It may seem that manual testing is inefficient when compared to automated testing. It is slow, not repeatable in a consistent manner, and prone to human misjudgment. However, manual testing allows the tester to realistically test the software, using actual user data in a natural user environment, subject to similar external conditions. Only a human, not a computer, can evaluate the usability and accessibility of the application and how it looks and feels to the end-user. It also gives a broader perspective of the system. Finally, some test scenarios just can't be automated and need to be manually tested. Thus, it is always recommended that you test the software manually before attempting to automate it.  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "17. What is the importance of Localization Testing?",
        "answer": "In localization testing, a software product is tested to ensure whether it offers full functionality and usability within a specific locale. Simply, it verifies the content's accuracy and suitability. In addition to linguistics, it addresses traditions, common herd behaviour, and other similar factors. Generally, it deals with the application's functionality and GUI.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "18. What do you mean by Baseline Testing and Benchmark testing?",
        "answer": "Baseline Testing: It is a type of non-functional testing in which a set of tests are run to capture performance information. Using this gathered information, we can make required changes in the application and ultimately improve the performance and capabilities of the application. Generally, it refers to a benchmark that is used as a starting point for new works. This testing uncovers and resolves many errors.\nBenchmark Testing: It is a type of testing that involves both the developers and DBAs (Database Administrators) to determine current performance information. Using this information, one can improve the performance of the same by matching it with the benchmarks (industry standards). Its main objective is to compare the present and future software releases with their specific benchmark. Baseline Testing: It is a type of non-functional testing in which a set of tests are run to capture performance information. Using this gathered information, we can make required changes in the application and ultimately improve the performance and capabilities of the application. Generally, it refers to a benchmark that is used as a starting point for new works. This testing uncovers and resolves many errors. Baseline Testing: Benchmark Testing: It is a type of testing that involves both the developers and DBAs (Database Administrators) to determine current performance information. Using this information, one can improve the performance of the same by matching it with the benchmarks (industry standards). Its main objective is to compare the present and future software releases with their specific benchmark. Benchmark Testing:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "19. Describe what Fuzz Testing is and how important it is.",
        "answer": "Fuzz testing is a software testing technique that uses a lot of random data, called fuzz, as input to find or detect security loopholes and coding errors in a software application. This is more useful for larger projects, but it only detects serious faults or defects. It is simply used to check the vulnerability of software and gives more effective results when used with beta testing, black box testing, etc.  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "20. Explain Configuration Testing.",
        "answer": "Configuration testing is a software testing technique that is used to evaluate the configurational requirements of the software. It discovers the optimal configuration of the system under which the application performs at its best, therefore configuration testing is considered important. It also helps in identifying and resolving any compatibility issues.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "21. Name two parameters that can be useful to check the quality of test execution.",
        "answer": "Two parameters required to check the quality of test execution include: Defect leakage ratio: It represents the ratio of total potential rejections to the total overall production.\nDefect reject ratio: It represents the ratio of total rejections to the total overall production. Defect leakage ratio: It represents the ratio of total potential rejections to the total overall production. Defect leakage ratio: Defect reject ratio: It represents the ratio of total rejections to the total overall production. Defect reject ratio:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "22. What is API testing?",
        "answer": "An API (Application Programming Interface) test involves testing API directly and as part of an integration test to ensure they meet reliable, functional, performance, and security requirements. Due to the lack of a GUI, APIs are tested at the message layer. The tester writes code that makes an API request to the server that provides the API, provides the required inputs, collects the output from the response, and matches the actual output with the expected output. API testing primarily concerns the business logic of the software that’s exposing the API. It does not involve the look and feel, accessibility, or usability of the software. API testing can be automated to make it repeatable and reproducible each time they run.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "23. Explain use-case testing.",
        "answer": "Use-case testing is basically a technique for developers and testers to identify test cases that exercise the entire system right from the very beginning to the very end of each transaction. Generally, it is part of black-box testing, which is used to develop tests or systems that achieve acceptable performance levels.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "24. Explain Path testing.",
        "answer": "A path test is a type of test designed specifically for designing test cases. It involves the use of a control flow chart designed specifically to identify a set of linearly independent paths of execution leading to the completion of a program. The main objective of this process is to ensure that all paths are covered and executed well. In addition, it reduces or minimizes the likelihood of redundant tests occurring.  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "25. Explain Endurance Testing or Soak Testing?",
        "answer": "Endurance testing, also known as Soak testing, is a type of performance testing usually performed to check the performance of the system that is under constant use. Its main purpose is to determine whether a system can sustain a continuous high load or not. Memory utilization is also monitored to identify potential leaks during this testing. Some of the endurance testing tools include: WebLOAD\nLoadUI\nOpenSTA\nLoadComplete\nApache JMeter, etc. WebLOAD LoadUI OpenSTA LoadComplete Apache JMeter, etc.  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "1. Name some of the most popular integration testing tools.",
        "answer": "Among the most commonly used integration testing tools are: DBUnit \nMockito \nGreenmail \nREST-Assured \nJUnit 5 \nH2 Database, etc. DBUnit Mockito Greenmail REST-Assured JUnit 5 H2 Database, etc.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "2. What do you mean by Critical bug?",
        "answer": "The term critical bug refers to a bug that affects the majority of an application's functionality. When a critical defect occurs, testing cannot proceed until the defect is fixed. These block the functionality of an entire system or module. An application returning a server error message after an attempt to log in is an example of a critical defect.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "3. What do you mean by Data flow testing?",
        "answer": "Data flow testing involves analyzing the flow of data within a program. It is a type of structural testing. It is possible, thus, for a programmer to perform various tests on data values and variables. This method provides a way to identify the variables that are used at every stage of the program's control flow. It helps us in the following ways: Eliminate or remove variables that are never used after being declared.\nPinpoint variables that are used but never declared.\nDeallocate variable before it is used.\nPinpoint variables that are defined multiple times before it is used. Eliminate or remove variables that are never used after being declared. Pinpoint variables that are used but never declared. Deallocate variable before it is used. Pinpoint variables that are defined multiple times before it is used.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "4. What are the differences between manual and automated testing?",
        "answer": "Manual and automated testing differ in the following ways: Manual Testing Automated Testing\nA human tester tests the software by manually running the test cases and observing and comparing the actual and expected outputs.  A tester or a programmer uses scripts and tools that execute the software and compares the actual and expected outputs. \nA manual test cannot be reproducible and repeated.  Automated testing can be consistently reproduced and repeated since it is programmed. Testers can run it as many times as they want. \nIt is easy for testers to test new features manually, without much configuration or setup. Automated testing requires an initial investment in creating tests and preparing a testing environment. \nA manual test can help identify bugs in the user interface or accessibility issues. The automated testing method is more effective at catching bugs that humans would miss, such as software bugs or errors in business logic. \nTests conducted manually are prone to human error and take a long time.  Compared to manual testing, automated testing is more reliable since there is no human involvement involved (apart from writing tests). It is significantly faster than manual testing. Manual Testing Automated Testing\nA human tester tests the software by manually running the test cases and observing and comparing the actual and expected outputs.  A tester or a programmer uses scripts and tools that execute the software and compares the actual and expected outputs. \nA manual test cannot be reproducible and repeated.  Automated testing can be consistently reproduced and repeated since it is programmed. Testers can run it as many times as they want. \nIt is easy for testers to test new features manually, without much configuration or setup. Automated testing requires an initial investment in creating tests and preparing a testing environment. \nA manual test can help identify bugs in the user interface or accessibility issues. The automated testing method is more effective at catching bugs that humans would miss, such as software bugs or errors in business logic. \nTests conducted manually are prone to human error and take a long time.  Compared to manual testing, automated testing is more reliable since there is no human involvement involved (apart from writing tests). It is significantly faster than manual testing. Manual Testing Automated Testing Manual Testing Automated Testing Manual Testing Automated Testing A human tester tests the software by manually running the test cases and observing and comparing the actual and expected outputs.  A tester or a programmer uses scripts and tools that execute the software and compares the actual and expected outputs. \nA manual test cannot be reproducible and repeated.  Automated testing can be consistently reproduced and repeated since it is programmed. Testers can run it as many times as they want. \nIt is easy for testers to test new features manually, without much configuration or setup. Automated testing requires an initial investment in creating tests and preparing a testing environment. \nA manual test can help identify bugs in the user interface or accessibility issues. The automated testing method is more effective at catching bugs that humans would miss, such as software bugs or errors in business logic. \nTests conducted manually are prone to human error and take a long time.  Compared to manual testing, automated testing is more reliable since there is no human involvement involved (apart from writing tests). It is significantly faster than manual testing. A human tester tests the software by manually running the test cases and observing and comparing the actual and expected outputs.  A tester or a programmer uses scripts and tools that execute the software and compares the actual and expected outputs. A human tester tests the software by manually running the test cases and observing and comparing the actual and expected outputs. A tester or a programmer uses scripts and tools that execute the software and compares the actual and expected outputs. A manual test cannot be reproducible and repeated.  Automated testing can be consistently reproduced and repeated since it is programmed. Testers can run it as many times as they want. A manual test cannot be reproducible and repeated. Automated testing can be consistently reproduced and repeated since it is programmed. Testers can run it as many times as they want. It is easy for testers to test new features manually, without much configuration or setup. Automated testing requires an initial investment in creating tests and preparing a testing environment. It is easy for testers to test new features manually, without much configuration or setup. Automated testing requires an initial investment in creating tests and preparing a testing environment. A manual test can help identify bugs in the user interface or accessibility issues. The automated testing method is more effective at catching bugs that humans would miss, such as software bugs or errors in business logic. A manual test can help identify bugs in the user interface or accessibility issues. The automated testing method is more effective at catching bugs that humans would miss, such as software bugs or errors in business logic. Tests conducted manually are prone to human error and take a long time.  Compared to manual testing, automated testing is more reliable since there is no human involvement involved (apart from writing tests). It is significantly faster than manual testing. Tests conducted manually are prone to human error and take a long time. Compared to manual testing, automated testing is more reliable since there is no human involvement involved (apart from writing tests). It is significantly faster than manual testing.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "5. State difference between static and dynamic testing.",
        "answer": "Static and Dynamic testing differ in the following ways: Static and Dynamic testing Static Testing Dynamic Testing\nIn static testing, software applications are tested without executing any code at the very beginning of the SDLC. The test checks software functionality, memory/CPU usage, and system performance at the end of the development cycle.\nIt is performed during the verification stage. It is performed during the validation stage.\nThis is performed prior to the deployment of the code. Following the deployment of the code, dynamic testing is performed.\nA static test prevents defects from occurring. In dynamic testing, defects are detected and fixed.\nA walkthrough, technical review, and inspection are all part of this process. Functional and non-functional testing is involved in this process.\nErrors are found early in the development process, thereby improving the quality of software applications. The main objective is to ensure that the software product meets the business requirements. Static Testing Dynamic Testing\nIn static testing, software applications are tested without executing any code at the very beginning of the SDLC. The test checks software functionality, memory/CPU usage, and system performance at the end of the development cycle.\nIt is performed during the verification stage. It is performed during the validation stage.\nThis is performed prior to the deployment of the code. Following the deployment of the code, dynamic testing is performed.\nA static test prevents defects from occurring. In dynamic testing, defects are detected and fixed.\nA walkthrough, technical review, and inspection are all part of this process. Functional and non-functional testing is involved in this process.\nErrors are found early in the development process, thereby improving the quality of software applications. The main objective is to ensure that the software product meets the business requirements. Static Testing Dynamic Testing Static Testing Dynamic Testing Static Testing Dynamic Testing In static testing, software applications are tested without executing any code at the very beginning of the SDLC. The test checks software functionality, memory/CPU usage, and system performance at the end of the development cycle.\nIt is performed during the verification stage. It is performed during the validation stage.\nThis is performed prior to the deployment of the code. Following the deployment of the code, dynamic testing is performed.\nA static test prevents defects from occurring. In dynamic testing, defects are detected and fixed.\nA walkthrough, technical review, and inspection are all part of this process. Functional and non-functional testing is involved in this process.\nErrors are found early in the development process, thereby improving the quality of software applications. The main objective is to ensure that the software product meets the business requirements. In static testing, software applications are tested without executing any code at the very beginning of the SDLC. The test checks software functionality, memory/CPU usage, and system performance at the end of the development cycle. In static testing, software applications are tested without executing any code at the very beginning of the SDLC. The test checks software functionality, memory/CPU usage, and system performance at the end of the development cycle. It is performed during the verification stage. It is performed during the validation stage. It is performed during the verification stage. It is performed during the validation stage. This is performed prior to the deployment of the code. Following the deployment of the code, dynamic testing is performed. This is performed prior to the deployment of the code. Following the deployment of the code, dynamic testing is performed. A static test prevents defects from occurring. In dynamic testing, defects are detected and fixed. A static test prevents defects from occurring. In dynamic testing, defects are detected and fixed. A walkthrough, technical review, and inspection are all part of this process. Functional and non-functional testing is involved in this process. A walkthrough, technical review, and inspection are all part of this process. Functional and non-functional testing is involved in this process. Errors are found early in the development process, thereby improving the quality of software applications. The main objective is to ensure that the software product meets the business requirements. Errors are found early in the development process, thereby improving the quality of software applications. The main objective is to ensure that the software product meets the business requirements.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "6. What is the term ‘quality’ mean when testing?",
        "answer": "In general, quality software is usually free of bugs, is delivered on time and on budget, meets most of the requirements and/or expectations, and is easy to maintain. However, 'quality' is a subjective concept. A lot depends on whom the \"customer\" is as well as the extent to which they are influential in general. For instance, a user may define quality as user-friendliness and bug-free while an accounting department might define quality as profits.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "7. What is the difference between Quality Control(QC) and Quality Assurance(QA)?",
        "answer": "Quality Assurance: Quality Assurance: QA stands for Quality Assurance. As part of a software development team, a QA ensures that the software is thoroughly tested before being released to the end-user. It ensures that the shipped software is of high quality. QA stands for Quality Assurance. As part of a software development team, a QA ensures that the software is thoroughly tested before being released to the end-user. It ensures that the shipped software is of high quality.   It focuses on improving the software development process and is typically carried out during the development phase. It is possible for testers and quality assurance personnel to be the same person in many software organizations, although the roles may differ depending on the organization's size. It focuses on improving the software development process and is typically carried out during the development phase. It is possible for testers and quality assurance personnel to be the same person in many software organizations, although the roles may differ depending on the organization's size. Quality Control: Quality Control: QC stands for Quality Control. The main goal of this process is to verify that the developed products meet the required standards. QC stands for Quality Control. The main goal of this process is to verify that the developed products meet the required standards.   Software quality-control tests and reviews the functional and non-functional requirements of a software product to ensure its quality. QC activities are typically performed after a product is developed to assess the quality of end products. Software quality-control tests and reviews the functional and non-functional requirements of a software product to ensure its quality. QC activities are typically performed after a product is developed to assess the quality of end products.   Check out more differences here: QA vs QC. QA vs QC QA vs QC",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "8. State difference between alpha testing and beta testing.",
        "answer": "Alpha and beta testing differ in the following ways:   Alpha Testing Beta Testing\nDuring this type of testing, bugs are identified before the product is released to users. An example of a user acceptance test is Alpha Testing.  The test is conducted by real users of the software application in a real environment. An example of a User Acceptance Test is beta testing. \nBoth white box and black box testing are involved in Alpha testing. A black-box testing is commonly used in beta testing.\nIn most cases, alpha testing is done by internal testers within an organization. Clients who are not affiliated with the organization perform beta testing.\nAs the activities are performed on the developer's site, they can be controlled. Because activities are performed in the real world, in the end, the user's environment, cannot be controlled. \nAlpha testing does not include robustness and security tests. Beta testing includes robustness and security tests.\nThe quality evaluation is the main objective. Customer satisfaction is the main objective.\nAlpha testing allows developers to quickly address critical issues. Most of the issues or feedback gathered during beta testing will be incorporated into future versions. Alpha Testing Beta Testing\nDuring this type of testing, bugs are identified before the product is released to users. An example of a user acceptance test is Alpha Testing.  The test is conducted by real users of the software application in a real environment. An example of a User Acceptance Test is beta testing. \nBoth white box and black box testing are involved in Alpha testing. A black-box testing is commonly used in beta testing.\nIn most cases, alpha testing is done by internal testers within an organization. Clients who are not affiliated with the organization perform beta testing.\nAs the activities are performed on the developer's site, they can be controlled. Because activities are performed in the real world, in the end, the user's environment, cannot be controlled. \nAlpha testing does not include robustness and security tests. Beta testing includes robustness and security tests.\nThe quality evaluation is the main objective. Customer satisfaction is the main objective.\nAlpha testing allows developers to quickly address critical issues. Most of the issues or feedback gathered during beta testing will be incorporated into future versions. Alpha Testing Beta Testing Alpha Testing Beta Testing Alpha Testing Beta Testing During this type of testing, bugs are identified before the product is released to users. An example of a user acceptance test is Alpha Testing.  The test is conducted by real users of the software application in a real environment. An example of a User Acceptance Test is beta testing. \nBoth white box and black box testing are involved in Alpha testing. A black-box testing is commonly used in beta testing.\nIn most cases, alpha testing is done by internal testers within an organization. Clients who are not affiliated with the organization perform beta testing.\nAs the activities are performed on the developer's site, they can be controlled. Because activities are performed in the real world, in the end, the user's environment, cannot be controlled. \nAlpha testing does not include robustness and security tests. Beta testing includes robustness and security tests.\nThe quality evaluation is the main objective. Customer satisfaction is the main objective.\nAlpha testing allows developers to quickly address critical issues. Most of the issues or feedback gathered during beta testing will be incorporated into future versions. During this type of testing, bugs are identified before the product is released to users. An example of a user acceptance test is Alpha Testing.  The test is conducted by real users of the software application in a real environment. An example of a User Acceptance Test is beta testing. During this type of testing, bugs are identified before the product is released to users. An example of a user acceptance test is Alpha Testing. The test is conducted by real users of the software application in a real environment. An example of a User Acceptance Test is beta testing. Both white box and black box testing are involved in Alpha testing. A black-box testing is commonly used in beta testing. Both white box and black box testing are involved in Alpha testing. A black-box testing is commonly used in beta testing. In most cases, alpha testing is done by internal testers within an organization. Clients who are not affiliated with the organization perform beta testing. In most cases, alpha testing is done by internal testers within an organization. Clients who are not affiliated with the organization perform beta testing. As the activities are performed on the developer's site, they can be controlled. Because activities are performed in the real world, in the end, the user's environment, cannot be controlled. As the activities are performed on the developer's site, they can be controlled. Because activities are performed in the real world, in the end, the user's environment, cannot be controlled. Alpha testing does not include robustness and security tests. Beta testing includes robustness and security tests. Alpha testing does not include robustness and security tests. Beta testing includes robustness and security tests. The quality evaluation is the main objective. Customer satisfaction is the main objective. The quality evaluation is the main objective. Customer satisfaction is the main objective. Alpha testing allows developers to quickly address critical issues. Most of the issues or feedback gathered during beta testing will be incorporated into future versions. Alpha testing allows developers to quickly address critical issues. Most of the issues or feedback gathered during beta testing will be incorporated into future versions.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "9. Explain Monkey Testing and Performance Testing.",
        "answer": "Monkey Testing: Monkey testing, also known as Random Testing, is a type of software testing technique in which data is generated randomly using a tool or some automated mechanism. This randomly generated input is used to test the system, and the results are analyzed accordingly. Testing of this type does not follow any rules. Monkey Testing:   Performance Testing: It is a type of non-functional software testing technique that is used to determine the system parameters like speed, scalability, and stability under different workload conditions. Its main purpose is to eliminate performance bottlenecks, not to find bugs. Some of the key parameters of performance testing include: Performance Testing: CPU Utilization\nMemory Utilization\nQPS/TPS (Transaction per second)\nAverage load time\nSystem throughput, etc. CPU Utilization Memory Utilization QPS/TPS (Transaction per second) Average load time System throughput, etc.  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "10. What is the role of documentation in manual testing?",
        "answer": "Effective software testing relies heavily on documentation. Documentation should include details such as requirements specifications, business rules, configurations, designs, test plans, code changes, test cases, bug reports, inspection reports, user manuals, etc. As part of software testing, the following documentation artifacts are commonly applied: Test Plan: It is essentially a dynamic document controlled and monitored by the testing manager. A well-written test plan that describes the scope and activities of software testing is crucial for the success of a testing project. In essence, it serves as a blueprint for all aspects of the testing process, such as what, when, how, and more.\nTest Scenario: A test scenario is a detailed description of a set of test cases or use cases. It involves testing a software application from the end user's perspective. It is usually the basis for constructing lower-level test cases or use cases. The test scenario can also be referred to as the test condition or the testing possibility. Taking a look at it will help you understand what we need to test.\nTest Case: As the name implies, a test case is a document that contains test data, expected results, preconditions, and postconditions. The purpose of this document is to ensure the software product meets the specific requirements for a specific test scenario. Manual testing involves executing test cases manually by a tester without relying on automated tools. In the process of developing test cases, it is possible to identify loopholes in the specifications.\nTraceability Matrix: This is a document, usually contained in a form table, that illustrates the relationship between requirements and other project artifacts from start to finish. To put it simply, it maps customer requirements to test cases. Test Plan: It is essentially a dynamic document controlled and monitored by the testing manager. A well-written test plan that describes the scope and activities of software testing is crucial for the success of a testing project. In essence, it serves as a blueprint for all aspects of the testing process, such as what, when, how, and more. Test Plan: Test Scenario: A test scenario is a detailed description of a set of test cases or use cases. It involves testing a software application from the end user's perspective. It is usually the basis for constructing lower-level test cases or use cases. The test scenario can also be referred to as the test condition or the testing possibility. Taking a look at it will help you understand what we need to test. Test Scenario: Test Case: As the name implies, a test case is a document that contains test data, expected results, preconditions, and postconditions. The purpose of this document is to ensure the software product meets the specific requirements for a specific test scenario. Manual testing involves executing test cases manually by a tester without relying on automated tools. In the process of developing test cases, it is possible to identify loopholes in the specifications. Test Case: Traceability Matrix: This is a document, usually contained in a form table, that illustrates the relationship between requirements and other project artifacts from start to finish. To put it simply, it maps customer requirements to test cases. Traceability Matrix:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "11. Explain RTM (Requirement Traceability Matrix).",
        "answer": "The RTM (Requirements Traceability Matrix) is defined as a tool used to identify and track the requirements and deliverables of a project. This is accomplished by establishing a thread for each component.  In addition, it manages the overall requirements of the project. There is nothing complicated about this method, and anyone can do it. RTMs come in many forms. A test matrix, for example, proves that tests were conducted. Additionally, it can be used during the software development process to identify issues and requirements.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "12. What is the importance of agile testing?",
        "answer": "The agile testing process involves software testing that adheres to agile software development principles. The software is evaluated from the customer's perspective. This software development practice involves frequent, automated testing of new code and the immediate fixing of defects as soon as they are discovered. Each feature is tested as it is developed. Among its advantages are: All testers and developers can work together, boosting performance.\nEach feature is tested as it is developed. \nEnsures a high-quality product that meets customer expectations. \nReduces costs and saves time.\nHighly adaptable and flexible. \nAssists developers with releasing software as soon as possible and improves product quality. All testers and developers can work together, boosting performance. Each feature is tested as it is developed. Ensures a high-quality product that meets customer expectations. Reduces costs and saves time. Highly adaptable and flexible. Assists developers with releasing software as soon as possible and improves product quality.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "13. What is the difference between Regression and Retesting?",
        "answer": "Regression Testing: Regression testing, also known as generic testing, revolves around re-running functional and non-functional tests. It is especially done to ensure whether previously developed and tested software still performs the same after a change or not. It can be performed either manually or using automated tests\nRe-testing: Re-testing, also known as planned testing, is used for specific bugs after it has been fixed by the developers. Re-testing is performed to check the scenario under the same environmental conditions after detection has been fixed. Regression Testing: Regression testing, also known as generic testing, revolves around re-running functional and non-functional tests. It is especially done to ensure whether previously developed and tested software still performs the same after a change or not. It can be performed either manually or using automated tests Regression Testing: Re-testing: Re-testing, also known as planned testing, is used for specific bugs after it has been fixed by the developers. Re-testing is performed to check the scenario under the same environmental conditions after detection has been fixed. Re-testing: Regression vs Retesting Regression vs Retesting Regression Retesting \nIt is performed to make sure that the changes haven't affected the unchanged part.  This is done to ensure that the test cases which were filed during the last execution are passed after the detected bugs have been fixed by developers. \nIt is not carried out to fix specific detects.  Usually, it is based on fixing defects. \nIt is only the previous version functionality centric.  It is current or previous version functionality centric.\nIt can be performed parallel with retesting.  It is needed to perform before regression testing. \nIt does not include the verification of bugs.  It includes the verification of bugs. \nIn this type of testing, test cases can be automated and the testing style is generic. In this type of testing, test cases cannot be automated and the testing is done in a planned manner. \nIt is only used for passed test cases.  It is only used for failed test cases. Regression Retesting \nIt is performed to make sure that the changes haven't affected the unchanged part.  This is done to ensure that the test cases which were filed during the last execution are passed after the detected bugs have been fixed by developers. \nIt is not carried out to fix specific detects.  Usually, it is based on fixing defects. \nIt is only the previous version functionality centric.  It is current or previous version functionality centric.\nIt can be performed parallel with retesting.  It is needed to perform before regression testing. \nIt does not include the verification of bugs.  It includes the verification of bugs. \nIn this type of testing, test cases can be automated and the testing style is generic. In this type of testing, test cases cannot be automated and the testing is done in a planned manner. \nIt is only used for passed test cases.  It is only used for failed test cases. Regression Retesting Regression Retesting Regression Retesting It is performed to make sure that the changes haven't affected the unchanged part.  This is done to ensure that the test cases which were filed during the last execution are passed after the detected bugs have been fixed by developers. \nIt is not carried out to fix specific detects.  Usually, it is based on fixing defects. \nIt is only the previous version functionality centric.  It is current or previous version functionality centric.\nIt can be performed parallel with retesting.  It is needed to perform before regression testing. \nIt does not include the verification of bugs.  It includes the verification of bugs. \nIn this type of testing, test cases can be automated and the testing style is generic. In this type of testing, test cases cannot be automated and the testing is done in a planned manner. \nIt is only used for passed test cases.  It is only used for failed test cases. It is performed to make sure that the changes haven't affected the unchanged part.  This is done to ensure that the test cases which were filed during the last execution are passed after the detected bugs have been fixed by developers. It is performed to make sure that the changes haven't affected the unchanged part. This is done to ensure that the test cases which were filed during the last execution are passed after the detected bugs have been fixed by developers. It is not carried out to fix specific detects.  Usually, it is based on fixing defects. It is not carried out to fix specific detects. Usually, it is based on fixing defects. It is only the previous version functionality centric.  It is current or previous version functionality centric. It is only the previous version functionality centric. It is current or previous version functionality centric. It can be performed parallel with retesting.  It is needed to perform before regression testing. It can be performed parallel with retesting. It is needed to perform before regression testing. It does not include the verification of bugs.  It includes the verification of bugs. It does not include the verification of bugs. It includes the verification of bugs. In this type of testing, test cases can be automated and the testing style is generic. In this type of testing, test cases cannot be automated and the testing is done in a planned manner. In this type of testing, test cases can be automated and the testing style is generic. In this type of testing, test cases cannot be automated and the testing is done in a planned manner. It is only used for passed test cases.  It is only used for failed test cases. It is only used for passed test cases. It is only used for failed test cases.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "14. What is System testing and Unit Testing? Write the difference between them.",
        "answer": "System Testing: It is a typical black box testing technique that is performed in a complete and fully integrated system to evaluate the system’s compliance with its specific requirements. It must investigate both functional requirements and non-functional requirements. Generally, it is performed by both testers and developers.\nUnit Testing: In unit testing, each component of the software is individually tested. Generally, unit testing is performed by developers. Those systems that have a lot of interdependencies between their modules cannot be tested by unit testing. System Testing: It is a typical black box testing technique that is performed in a complete and fully integrated system to evaluate the system’s compliance with its specific requirements. It must investigate both functional requirements and non-functional requirements. Generally, it is performed by both testers and developers. System Testing: Unit Testing: In unit testing, each component of the software is individually tested. Generally, unit testing is performed by developers. Those systems that have a lot of interdependencies between their modules cannot be tested by unit testing. Unit Testing: System vs Integration Testing System vs Integration Testing System Testing Unit Testing \nThe system testing method involves treating each module as a separate target for testing, and integrating the modules after each has been tested. The purpose of unit testing is to test only one module at a time, rather than the integrated version of the application.\nGenerally, when it comes to unit testing, a single module testing approach is taken. For System test cases, it includes both top-down approach testing and bottom-up approach testing with all modules in integrated mode.\nIt focuses on system validation.   It focuses on functional verification.\nIt usually follows the requirements specification. It usually follows the specification of modules.\nIt is also known as black-box testing. It is also known as white-box testing.\nIt is a low-level test as compared to unit testing. It is a high-level test as compared to system testing. System Testing Unit Testing \nThe system testing method involves treating each module as a separate target for testing, and integrating the modules after each has been tested. The purpose of unit testing is to test only one module at a time, rather than the integrated version of the application.\nGenerally, when it comes to unit testing, a single module testing approach is taken. For System test cases, it includes both top-down approach testing and bottom-up approach testing with all modules in integrated mode.\nIt focuses on system validation.   It focuses on functional verification.\nIt usually follows the requirements specification. It usually follows the specification of modules.\nIt is also known as black-box testing. It is also known as white-box testing.\nIt is a low-level test as compared to unit testing. It is a high-level test as compared to system testing. System Testing Unit Testing System Testing Unit Testing System Testing Unit Testing The system testing method involves treating each module as a separate target for testing, and integrating the modules after each has been tested. The purpose of unit testing is to test only one module at a time, rather than the integrated version of the application.\nGenerally, when it comes to unit testing, a single module testing approach is taken. For System test cases, it includes both top-down approach testing and bottom-up approach testing with all modules in integrated mode.\nIt focuses on system validation.   It focuses on functional verification.\nIt usually follows the requirements specification. It usually follows the specification of modules.\nIt is also known as black-box testing. It is also known as white-box testing.\nIt is a low-level test as compared to unit testing. It is a high-level test as compared to system testing. The system testing method involves treating each module as a separate target for testing, and integrating the modules after each has been tested. The purpose of unit testing is to test only one module at a time, rather than the integrated version of the application. The system testing method involves treating each module as a separate target for testing, and integrating the modules after each has been tested. The purpose of unit testing is to test only one module at a time, rather than the integrated version of the application. Generally, when it comes to unit testing, a single module testing approach is taken. For System test cases, it includes both top-down approach testing and bottom-up approach testing with all modules in integrated mode. Generally, when it comes to unit testing, a single module testing approach is taken. For System test cases, it includes both top-down approach testing and bottom-up approach testing with all modules in integrated mode. It focuses on system validation.   It focuses on functional verification. It focuses on system validation. It focuses on functional verification. It usually follows the requirements specification. It usually follows the specification of modules. It usually follows the requirements specification. It usually follows the specification of modules. It is also known as black-box testing. It is also known as white-box testing. It is also known as black-box testing. It is also known as white-box testing. It is a low-level test as compared to unit testing. It is a high-level test as compared to system testing. It is a low-level test as compared to unit testing. It is a high-level test as compared to system testing.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "15. What are the types of Integration Testing?",
        "answer": "Integration testing includes the following types: Big bang testing: It involves integrating all the modules and components at once and then testing them as a whole (single unit). When testing these components together, they are treated as an entity. The integration process will not proceed if all the components of the unit are not completed.\nBottom-Up Testing: This strategy involves testing lower-level modules first, then moving on to higher-level modules. As long as top-level modules have been tested, the process continues. Upon integrating and testing the lower-level modules, the next level of modules will be created. Big bang testing: It involves integrating all the modules and components at once and then testing them as a whole (single unit). When testing these components together, they are treated as an entity. The integration process will not proceed if all the components of the unit are not completed. Big bang testing: Bottom-Up Testing: This strategy involves testing lower-level modules first, then moving on to higher-level modules. As long as top-level modules have been tested, the process continues. Upon integrating and testing the lower-level modules, the next level of modules will be created. Bottom-Up Testing:   Top-Down Testing: This strategy involves testing software systems from top to bottom according to the control flow. Tests are conducted first on the higher-level modules, followed by tests and integration of the lower-level modules to verify the functionality of the software. Testing is carried out using stubs when some modules are not yet ready. Top-Down Testing: This strategy involves testing software systems from top to bottom according to the control flow. Tests are conducted first on the higher-level modules, followed by tests and integration of the lower-level modules to verify the functionality of the software. Testing is carried out using stubs when some modules are not yet ready. Top-Down Testing:  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "16. State the difference between bug leakage and bug release.",
        "answer": "Bug leakage and bug release differ in the following ways: Bug Leakage Bug Release \nBug leakage refers to a defect that exists during testing yet is not discovered by the tester but is eventually discovered by the end-user. When a piece of software is released with a known bug(s) or defect(s), it is termed a bug release.\nIt is usually a high priority/severity bug. It is not a high priority/severity bug.\nThe bugs need to be addressed immediately and resolved as soon as possible. Software companies do this when they can afford to release software with bugs, but cannot afford to fix them in that version. Bug Leakage Bug Release \nBug leakage refers to a defect that exists during testing yet is not discovered by the tester but is eventually discovered by the end-user. When a piece of software is released with a known bug(s) or defect(s), it is termed a bug release.\nIt is usually a high priority/severity bug. It is not a high priority/severity bug.\nThe bugs need to be addressed immediately and resolved as soon as possible. Software companies do this when they can afford to release software with bugs, but cannot afford to fix them in that version. Bug Leakage Bug Release Bug Leakage Bug Release Bug Leakage Bug Release Bug leakage refers to a defect that exists during testing yet is not discovered by the tester but is eventually discovered by the end-user. When a piece of software is released with a known bug(s) or defect(s), it is termed a bug release.\nIt is usually a high priority/severity bug. It is not a high priority/severity bug.\nThe bugs need to be addressed immediately and resolved as soon as possible. Software companies do this when they can afford to release software with bugs, but cannot afford to fix them in that version. Bug leakage refers to a defect that exists during testing yet is not discovered by the tester but is eventually discovered by the end-user. When a piece of software is released with a known bug(s) or defect(s), it is termed a bug release. Bug leakage refers to a defect that exists during testing yet is not discovered by the tester but is eventually discovered by the end-user. When a piece of software is released with a known bug(s) or defect(s), it is termed a bug release. It is usually a high priority/severity bug. It is not a high priority/severity bug. It is usually a high priority/severity bug. It is not a high priority/severity bug. The bugs need to be addressed immediately and resolved as soon as possible. Software companies do this when they can afford to release software with bugs, but cannot afford to fix them in that version. The bugs need to be addressed immediately and resolved as soon as possible. Software companies do this when they can afford to release software with bugs, but cannot afford to fix them in that version.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "17. What is Test Harness and Test Closure?",
        "answer": "Test Harness: Test harness, also known as the automated test framework, is a collection of software and test data required to unit test software modules during development. It is mostly used by the developers and helps in the automation and execution of unit test cases. It generally includes two main parts as given below: Test Harness: Test execution engine \nTest script repository Test execution engine Test script repository Test Closure: Test closure is basically a document that provides the summary of all the tests that are performed during SDLC. It gives full detailed analysis reports of the bugs that are discovered and removed. It is usually performed prior to the end of the testing process. Test Closure:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "18. Explain different stages of the defect life cycle.",
        "answer": "The defect life cycle consists of the following stages: New: Potential defect that hasn't been validated.\nAssigned: Assigned to a team for resolution, but not yet resolved.\nActive: Developers are currently investigating the defect and addressing it. Deferred or Rejected are the two possible outcomes at this stage.\nTest: The defect has been fixed and can be tested.\nVerified: The defect has been retested and the results have been verified by QA.\nClosed: Defect in its final state, which can be closed after retesting by QA or when considered duplicate or not a defect.\nReopened: QA reopens/reactivates a defect when it has not been fixed.\nDeferred: A defect that can't be addressed in the current cycle is deferred to a future release.\nRejected: There are three common reasons for rejecting a defect: duplicate, not a defect, and not reproducible. New: Potential defect that hasn't been validated. New: Assigned: Assigned to a team for resolution, but not yet resolved. Assigned: Active: Developers are currently investigating the defect and addressing it. Deferred or Rejected are the two possible outcomes at this stage. Active: Test: The defect has been fixed and can be tested. Test: Verified: The defect has been retested and the results have been verified by QA. Verified: Closed: Defect in its final state, which can be closed after retesting by QA or when considered duplicate or not a defect. Closed: Reopened: QA reopens/reactivates a defect when it has not been fixed. Reopened: Deferred: A defect that can't be addressed in the current cycle is deferred to a future release. Deferred: Rejected: There are three common reasons for rejecting a defect: duplicate, not a defect, and not reproducible. Rejected:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "19. Explain Experienced-based testing techniques.",
        "answer": "The experience-based testing technique is a type of testing that is based on the tester’s experience with testing to understand the essential areas of a system. This type of testing is generally used in a low-risk system. Individuals’ information, abilities, and foundation knowledge are prime supporters of the test conditions and experiments in experienced-based techniques. There are four different experienced-based testing techniques as shown below:  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "20. Write the difference between smoke testing and sanity testing.",
        "answer": "Smoke Testing: This is a type of testing performed to ensure that the acute functionalities of the program are working well. It acts as a confirmation of whether the quality assurance team can further proceed with testing or not.\nSanity Testing: It is an unscripted form of testing performed to ensure that the code changes that are made are working well. It is performed by the test team for some basic tests. This testing focuses on one or a few areas of functionality and is usually narrow and deep. Smoke Testing: This is a type of testing performed to ensure that the acute functionalities of the program are working well. It acts as a confirmation of whether the quality assurance team can further proceed with testing or not. Smoke Testing: Sanity Testing: It is an unscripted form of testing performed to ensure that the code changes that are made are working well. It is performed by the test team for some basic tests. This testing focuses on one or a few areas of functionality and is usually narrow and deep. Sanity Testing: Smoke Testing  Sanity Testing\nIn this test, the test team measures the system's stability before moving on to more rigorous testing. In this testing, the test team measures the rationality of the system before moving on to more rigorous testing.\nDevelopers or testers usually perform this task. Testers usually perform this task.\nBoth manual and automated methods can be used to execute it. Automated tools cannot be used to execute it; they must be done manually.\nIn most cases, it takes place during the development of a new product. The test is generally performed after the regression test.\nThere is documentation, and it is used to test the application's end-to-end functionality. There is no documentation, and it is used to test only functions that have been modified or have been fixed.\nIt is also considered a subset of acceptance testing.  It is also considered a subset of regression testing. Smoke Testing  Sanity Testing\nIn this test, the test team measures the system's stability before moving on to more rigorous testing. In this testing, the test team measures the rationality of the system before moving on to more rigorous testing.\nDevelopers or testers usually perform this task. Testers usually perform this task.\nBoth manual and automated methods can be used to execute it. Automated tools cannot be used to execute it; they must be done manually.\nIn most cases, it takes place during the development of a new product. The test is generally performed after the regression test.\nThere is documentation, and it is used to test the application's end-to-end functionality. There is no documentation, and it is used to test only functions that have been modified or have been fixed.\nIt is also considered a subset of acceptance testing.  It is also considered a subset of regression testing. Smoke Testing  Sanity Testing Smoke Testing  Sanity Testing Smoke Testing Sanity Testing In this test, the test team measures the system's stability before moving on to more rigorous testing. In this testing, the test team measures the rationality of the system before moving on to more rigorous testing.\nDevelopers or testers usually perform this task. Testers usually perform this task.\nBoth manual and automated methods can be used to execute it. Automated tools cannot be used to execute it; they must be done manually.\nIn most cases, it takes place during the development of a new product. The test is generally performed after the regression test.\nThere is documentation, and it is used to test the application's end-to-end functionality. There is no documentation, and it is used to test only functions that have been modified or have been fixed.\nIt is also considered a subset of acceptance testing.  It is also considered a subset of regression testing. In this test, the test team measures the system's stability before moving on to more rigorous testing. In this testing, the test team measures the rationality of the system before moving on to more rigorous testing. In this test, the test team measures the system's stability before moving on to more rigorous testing. In this testing, the test team measures the rationality of the system before moving on to more rigorous testing. Developers or testers usually perform this task. Testers usually perform this task. Developers or testers usually perform this task. Testers usually perform this task. Both manual and automated methods can be used to execute it. Automated tools cannot be used to execute it; they must be done manually. Both manual and automated methods can be used to execute it. Automated tools cannot be used to execute it; they must be done manually. In most cases, it takes place during the development of a new product. The test is generally performed after the regression test. In most cases, it takes place during the development of a new product. The test is generally performed after the regression test. There is documentation, and it is used to test the application's end-to-end functionality. There is no documentation, and it is used to test only functions that have been modified or have been fixed. There is documentation, and it is used to test the application's end-to-end functionality. There is no documentation, and it is used to test only functions that have been modified or have been fixed. It is also considered a subset of acceptance testing.  It is also considered a subset of regression testing. It is also considered a subset of acceptance testing. It is also considered a subset of regression testing. Check out More Differences. Check out More Differences",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "21. What do you mean by pesticide paradox?  What you can do to overcome it.",
        "answer": "The pesticide paradox is basically a phenomenon where the more one tests the software, the more it becomes immune to its tests. To overcome this, testers should always find new strategies, approaches, and test cases, so that they can identify bugs and resolve them. The following methods can be used to prevent the pesticide paradox: Create a new set of test cases for different components of the software.\nAdding new test cases to the existing test cases. Create a new set of test cases for different components of the software. Adding new test cases to the existing test cases. The use of these methods can lead to finding more defects in the areas where defect levels have declined.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "22. Explain the term testbed.",
        "answer": "Testbed is generally referred to as a digital platform that is used for testing an application. It includes an operating system, database,  hardware, network configuration, software application under test, and all other software-related issues.  ",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "23. Explain bugs, defects, and errors.",
        "answer": "Error: The error occurs when there is a programming mistake in the code that prevents the program from executing or compiling.\nDefect: A defect is any variation between the actual result and the expected result determined by a tester or developer. Defects are typically detected after the product enters production and are resolved only during the development phase.\nBug: A software bug is detected during the testing phase as a fault or mismatch. This affects the functionality and performance of the software. Error: The error occurs when there is a programming mistake in the code that prevents the program from executing or compiling. Error: Defect: A defect is any variation between the actual result and the expected result determined by a tester or developer. Defects are typically detected after the product enters production and are resolved only during the development phase. Defect: Bug: A software bug is detected during the testing phase as a fault or mismatch. This affects the functionality and performance of the software. Bug:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "24. What is the software testing life cycle?",
        "answer": "STLC (Software Testing Life Cycle) is a fundamental part of SDLC which is used to test software and ensure that the quality standards are met. Verification and validation are generally involved in this process. In this, different activities are executed in a specific order throughout the software testing process. There are basically six different phases in STLC Model as shown below:   Requirement Analysis: The QA team analyzes the requirements to determine what we are going to test and what the testable requirements are.\nTest Planning: This phase involves defining the test strategy. This step determines the project's objective and scope.\nTest Case Development: This stage involves defining and developing detailed test cases. Test data is also prepared by the testing team for testing.\nTest Environment Setup: This is the software and hardware setup that the testing teams use to execute test cases.\nTest Execution: This involves executing code and comparing it with the expected results.\nTest Cycle Closure: This involves calling out a meeting of the testing team members to evaluate and assess cycle completion criteria based on cost, time, test coverage, quality, and critical business objectives and software. Requirement Analysis: The QA team analyzes the requirements to determine what we are going to test and what the testable requirements are. Requirement Analysis: Test Planning: This phase involves defining the test strategy. This step determines the project's objective and scope. Test Planning: Test Case Development: This stage involves defining and developing detailed test cases. Test data is also prepared by the testing team for testing. Test Case Development: Test Environment Setup: This is the software and hardware setup that the testing teams use to execute test cases. Test Environment Setup: Test Execution: This involves executing code and comparing it with the expected results. Test Execution: Test Cycle Closure: This involves calling out a meeting of the testing team members to evaluate and assess cycle completion criteria based on cost, time, test coverage, quality, and critical business objectives and software. Test Cycle Closure:",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "25. What is black-box testing?",
        "answer": "In black-box testing, the tester views the software as a black box, ignoring all the internal structure and behaviour. It is solely concerned with the input provided by the user and the output generated by the system. Black-box testing verifies the program’s behaviour against the specified requirements.   As part of black-box testing, test conditions are created based on the software's functionality without knowing how it works internally. In this approach, the software is tested from the point of view of the end-user and provides a broader view of the entire system. In light of the fact that users are only concerned with whether the software meets their needs, rather than how it works, black-box testing is an excellent way to test software usability and anticipate how customers will use it.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "26. What white-box testing?",
        "answer": "White-box testing is an alternative to black-box testing that involves viewing the system as a transparent box. It is possible for the testers to observe the internal implementation of the system, which helps them conduct the test. In most cases, white-box testing is performed by the software developers during the development process. It is also referred to as closed-box testing.   In white-box testing, we assume that the tester has some programming knowledge. The test covers all possible branches a program could follow in a running system. The more you know about the inside of a system, such as its source code and implementation details, the more thoroughly you can test it.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "1. When to choose manual testing over automation testing and vice versa?",
        "answer": "Choosing Manual Testing over Automation Testing Choosing Manual Testing over Automation Testing When test cases need to be run for a short duration of time (once or twice). \nWhen one needs to perform exploratory testing, usability testing, or ad-hoc testing.\nWhen assessing an application's user-friendliness.\nWhenever flexibility is needed. \nWhenever one wants to better manage complex situations/scenarios. When test cases need to be run for a short duration of time (once or twice). When one needs to perform exploratory testing, usability testing, or ad-hoc testing. When assessing an application's user-friendliness. Whenever flexibility is needed. Whenever one wants to better manage complex situations/scenarios. Choosing Automation Testing over Manual Testing Choosing Automation Testing over Manual Testing Whenever test cases have to be run repeatedly over a long period of time. \nWhen one needs to perform performance testing, load testing, or regression testing. \nWhenever one wishes to record the testing process.\nWhen one has a limited amount of time to complete the testing phase. \nWhen tests are needed to be executed in a standard runtime environment. \nWhen tests involve repetitive steps. \nWhen there are multiple and quick deployments for the product, the manual becomes very time taking and redundant. Whenever test cases have to be run repeatedly over a long period of time. When one needs to perform performance testing, load testing, or regression testing. Whenever one wishes to record the testing process. When one has a limited amount of time to complete the testing phase. When tests are needed to be executed in a standard runtime environment. When tests involve repetitive steps. When there are multiple and quick deployments for the product, the manual becomes very time taking and redundant.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "2. In what way will you determine when to stop testing?",
        "answer": "Testing can be quite challenging when it comes to determining when to stop. In the modern world, many software applications are so complex and run in so many interdependent environments, that complete testing is impossible. The following factors are often considered when deciding when to stop testing: If deadlines are met (release deadlines, testing deadlines, etc.) and there are no high-priority issues left in the system.\nCompletion of test cases with a certain passing percentage.\nAs soon as the test budget is depleted.\nThe mean time between two inherent failures is known as the MTBF (Mean Time Between Failure). When the MTBF is quite high, the testing phase may be stopped depending on stakeholder decisions.\nAs soon as the automated code coverage meets a specified threshold value and there are no critical bugs.\nIf the bug rate drops below a certain level.\nAfter the Beta or Alpha testing period has ended. If deadlines are met (release deadlines, testing deadlines, etc.) and there are no high-priority issues left in the system. Completion of test cases with a certain passing percentage. As soon as the test budget is depleted. The mean time between two inherent failures is known as the MTBF (Mean Time Between Failure). When the MTBF is quite high, the testing phase may be stopped depending on stakeholder decisions. As soon as the automated code coverage meets a specified threshold value and there are no critical bugs. If the bug rate drops below a certain level. After the Beta or Alpha testing period has ended.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "3. Can 100% testing coverage be achieved? How do you ensure test coverage?",
        "answer": "Testing a product 100% is considered impossible. You can, however, get closer to your goal by following the steps below. Developing an effective testing strategy.\nPrepare a checklist for all activities related to testing.\nEstablish a priority list for the application's critical areas.\nList all application requirements.\nIdentify the risks associated with the application.\nUtilize automated testing. Developing an effective testing strategy. Prepare a checklist for all activities related to testing. Establish a priority list for the application's critical areas. List all application requirements. Identify the risks associated with the application. Utilize automated testing.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "4. System testing can be done at any stage. Yes or No?",
        "answer": "No, system testing cannot be conducted at any stage of the development process. In system testing, all components of the software are tested together to ensure that the overall product meets the specified specifications. Therefore, system testing cannot take place at any stage; instead, it must be done only after all modules or units are in place and are working properly, but before User Acceptance Testing (UAT).",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "5. If proper documentation is not available for testing, what steps will you take to overcome the challenge?",
        "answer": "QAs should refer to the following references if they cannot find standard documents such as System Requirements Specification or Feature Description Document. Screenshots\nWireframes\nA previous version of the application. Screenshots Wireframes A previous version of the application. In addition, having discussions with the business analyst and the developer is another reliable method. This is helpful in resolving doubts and bringing clarity to requirements. The emails exchanged could also serve as testing references. Another option for verifying the application's functionality is to perform smoke testing. This would expose a few very basic bugs in the application. In cases where none of the above options work, we can simply use our previous experience to test the software application.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "6. What are some best practices that you should follow when writing test cases?",
        "answer": "When writing test cases, you should follow the following guidelines: Assess the project's risks and deadlines before planning and prioritizing test cases and write accordingly.\nKeep the 80/20 rule in mind. For the best coverage of your application, 20% of your tests should cover 80% of its functionality.\nMake sure you don't try to test all cases at once, but rather improvise them as you go.\nCreate a list of your test cases and categorize them according to business scenarios and functionality.\nModularity and granularity are important when designing test cases.\nProvide test cases in a way that can easily be understood by others and modified if necessary.\nRemember that the software designed is ultimately for customers, so keep their requirements in mind.\nManage a stable release cycle by using a test management tool.\nKeep track of your test cases on a regular basis. Test cases must be unique and irrelevant or duplicated must be removed. Assess the project's risks and deadlines before planning and prioritizing test cases and write accordingly. Keep the 80/20 rule in mind. For the best coverage of your application, 20% of your tests should cover 80% of its functionality. Make sure you don't try to test all cases at once, but rather improvise them as you go. Create a list of your test cases and categorize them according to business scenarios and functionality. Modularity and granularity are important when designing test cases. Provide test cases in a way that can easily be understood by others and modified if necessary. Remember that the software designed is ultimately for customers, so keep their requirements in mind. Manage a stable release cycle by using a test management tool. Keep track of your test cases on a regular basis. Test cases must be unique and irrelevant or duplicated must be removed.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "7. When the requirements are still in flux, what is the best way to test a product?",
        "answer": "For some products, a requirement stack is not available. It may require considerable effort to identify if an application has unexpected functionality, which indicates a deeper problem with the software development process. Removing functionality that isn't necessary for the purpose of the application is a good idea. Otherwise, create a test plan based on the assumptions you've made about the product. But, it is important that you thoroughly document all assumptions in the test plan.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "8. What makes boundary value analysis a good method for providing test cases?",
        "answer": "A boundary value analysis is defined as a software testing technique that uses the boundary values of equivalence classes as input to test cases. Black box testing uses boundary value analysis as one of the most commonly used case design techniques. In boundary value analysis, values at the boundaries are included in test cases. It is generally true that there are more errors at the boundaries of an input domain than in its center, which makes boundary value analysis an excellent method for generating test cases. In boundary value analysis, values at the boundaries are included in test cases. When the input lies within the boundary range, it is a positive test, but if it lies outside, it is a negative test. The values may include the maximum, the minimum, the inside edge, the outside edge, the typical value or the error value. Example: Assume you're testing an input box accepting numbers from 1 to 20. As a result of boundary value analysis, we can divide test cases into three categories: The test data will be the same as the input boundaries of input: 1 and 20.\nInput values above the extreme edges: 2 and 21.\nInput values below the extreme edges: 0 and 19. The test data will be the same as the input boundaries of input: 1 and 20. Input values above the extreme edges: 2 and 21. Input values below the extreme edges: 0 and 19. Therefore, the boundary values are 0, 1, 2, and 19, 20, 21.",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    },
    {
        "question": "9. How do you know the code has met specifications?",
        "answer": "Code that is maintainable, readable, and bug-free is considered good.  Almost every organization has 'coding standards' that developers should adhere to, but everyone has different ideas about what's best and what's too many or too few. Many tools are available that ensure that test cases map to requirements, such as traceability matrixes. In the event that all test cases are successfully executed, then the code fulfils the requirement. Conclusion QAs should add manual testing to any test strategy as it enables them to gain deeper insights from the end user's perspective that can be extremely useful. As manual testing relies on human testers without the aid of test automation frameworks, it is a powerful tool for judging software based on the most important metric: customer/user experience. The agile software development process continuously demands a shift towards automated testing, but manual testing will never cease to exist. An experienced, well-rounded candidate that can provide both manual and automation testing skills can assist QAs in quickly and efficiently completing the necessary tests. When you prepare for the manual interview, you are more likely to impress the hiring manager and progress to the next stage of the process. In light of this, we have put together a comprehensive list of interview questions frequently asked during manual testing interviews. Here we have given an overview of manual testing and compiled a list of the top 50+ manual testing interview questions for job seekers at all stages of their careers. The candidate should have a thorough understanding of key concepts, as well as the ability to clearly and persuasively present their ideas. So, prepare yourself accordingly. Good luck with your future endeavours. Additional Interview Resources https://www.interviewbit.com/automation-testing-interview-questions/\nhttps://www.interviewbit.com/api-testing-interview-questions/\nhttps://www.interviewbit.com/java-interview-questions-for-5-years-experience/\nhttps://www.interviewbit.com/sdlc-interview-questions/\nhttps://www.interviewbit.com/functional-testing-interview-questions/\nhttps://www.interviewbit.com/jira-interview-questions/\nhttps://www.interviewbit.com/mobile-testing-interview-questions/\nhttps://www.interviewbit.com/performance-testing-interview-questions/\nhttps://www.interviewbit.com/qa-interview-questions/\nhttps://www.interviewbit.com/database-testing-interview-questions/\nhttps://www.interviewbit.com/technical-interview-questions/\nhttps://www.interviewbit.com/blog/qa-engineer/\nhttps://www.interviewbit.com/blog/software-testing-methodologies/\nhttps://www.interviewbit.com/blog/principles-of-software-testing/\nhttps://www.interviewbit.com/software-testing-mcq/ https://www.interviewbit.com/automation-testing-interview-questions/ https://www.interviewbit.com/automation-testing-interview-questions/ https://www.interviewbit.com/api-testing-interview-questions/ https://www.interviewbit.com/api-testing-interview-questions/ https://www.interviewbit.com/java-interview-questions-for-5-years-experience/ https://www.interviewbit.com/java-interview-questions-for-5-years-experience/ https://www.interviewbit.com/sdlc-interview-questions/ https://www.interviewbit.com/sdlc-interview-questions/ https://www.interviewbit.com/functional-testing-interview-questions/ https://www.interviewbit.com/functional-testing-interview-questions/ https://www.interviewbit.com/jira-interview-questions/ https://www.interviewbit.com/jira-interview-questions/ https://www.interviewbit.com/mobile-testing-interview-questions/ https://www.interviewbit.com/mobile-testing-interview-questions/ https://www.interviewbit.com/performance-testing-interview-questions/ https://www.interviewbit.com/performance-testing-interview-questions/ https://www.interviewbit.com/qa-interview-questions/ https://www.interviewbit.com/qa-interview-questions/ https://www.interviewbit.com/database-testing-interview-questions/ https://www.interviewbit.com/database-testing-interview-questions/ https://www.interviewbit.com/technical-interview-questions/ https://www.interviewbit.com/technical-interview-questions/ https://www.interviewbit.com/blog/qa-engineer/ https://www.interviewbit.com/blog/qa-engineer/ https://www.interviewbit.com/blog/software-testing-methodologies/ https://www.interviewbit.com/blog/software-testing-methodologies/ https://www.interviewbit.com/blog/principles-of-software-testing/ https://www.interviewbit.com/blog/principles-of-software-testing/ https://www.interviewbit.com/software-testing-mcq/ https://www.interviewbit.com/software-testing-mcq/ https://www.interviewbit.com/software-testing-mcq/",
        "reference": "interviewbit.com",
        "role": "manual-testing"
    }
]