[
    {
        "question": "1. What is Deep Learning?",
        "answer": "Deep learning is a subset of machine learning that is entirely based on artificial neural networks. Because neural networks are designed to mimic the human brain, deep learning is likewise a human brain mimic. We don't have to explicitly program everything in deep learning. We train a model on a training dataset and improvise it until the model predicts almost correctly on the testing and validation dataset as well. Deep learning Deep learning   Deep learning models are capable of focusing on accurate features on their own, with only a little input from the programmer, and are highly useful in resolving the dimensionality problem. Deep learning is not a new concept. It has been around for quite some time. It's all the rage these days since we don't have nearly as much processing power or as much data as we do now. As processing power has increased tremendously over the last 20 years, deep learning and machine learning have entered the scene. Here is a free deep learning fundamental course that can help you with the basics of deep learning. fundamental course fundamental course",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "2. What are the Applications of deep learning?",
        "answer": "Following are some of the applications of deep learning: Pattern recognition and natural language processing.\nRecognition and processing of images.\nAutomated translation.\nAnalysis of sentiment.\nSystem for answering questions.\nClassification and Detection of Objects.\nHandwriting Generation by Machine.\nAutomated text generation.\nColorization of Black and White images. Pattern recognition and natural language processing. Recognition and processing of images. Automated translation. Analysis of sentiment. System for answering questions. Classification and Detection of Objects. Handwriting Generation by Machine. Automated text generation. Colorization of Black and White images. Learn More. Learn More Learn More",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "3. What are Neural Networks?",
        "answer": "Neural Networks are artificial systems that have a lot of resemblance to the biological neural networks in the human body. A neural network is a set of algorithms that attempts to recognize underlying relationships in a batch of data using a method that mimics how the human brain works. Without any task-specific rules, these systems learn to do tasks by being exposed to a variety of datasets and examples. The notion is that instead of being programmed with a pre-coded understanding of these datasets, the system derives identifying traits from the data it is fed to. Neural networks are built on threshold logic computational models.  Because neural networks can adapt to changing input, they can produce the best possible outcome without requiring the output criteria to be redesigned.  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "4. What are the advantages of neural networks?",
        "answer": "Following are the advantages of neural networks: Neural networks are extremely adaptable, and they may be used for both classification and regression problems, as well as much more complex problems. Neural networks are also quite scalable. We can create as many layers as we wish, each with its own set of neurons. When there are a lot of data points, neural networks have been shown to generate the best outcomes. They are best used with non-linear data such as images, text, and so on. They can be applied to any data that can be transformed into a numerical value.\nOnce the neural network mode has been trained, they deliver output very fast. Thus, they are time-effective. Neural networks are extremely adaptable, and they may be used for both classification and regression problems, as well as much more complex problems. Neural networks are also quite scalable. We can create as many layers as we wish, each with its own set of neurons. When there are a lot of data points, neural networks have been shown to generate the best outcomes. They are best used with non-linear data such as images, text, and so on. They can be applied to any data that can be transformed into a numerical value. Once the neural network mode has been trained, they deliver output very fast. Thus, they are time-effective.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "5. What are the disadvantages of neural networks?",
        "answer": "Following are the disadvantages of neural networks:- The \"black box\" aspect of neural networks is a well-known disadvantage. That is, we have no idea how or why our neural network produced a certain result. When we enter a dog image into a neural network and it predicts that it is a duck, we may find it challenging to understand what prompted it to make this prediction.\nIt takes a long time to create a neural network model.\nNeural networks models are computationally expensive to build because a lot of computations need to be done at each layer.\nA neural network model requires significantly more data than a traditional machine learning model to train. The \"black box\" aspect of neural networks is a well-known disadvantage. That is, we have no idea how or why our neural network produced a certain result. When we enter a dog image into a neural network and it predicts that it is a duck, we may find it challenging to understand what prompted it to make this prediction. It takes a long time to create a neural network model. Neural networks models are computationally expensive to build because a lot of computations need to be done at each layer. A neural network model requires significantly more data than a traditional machine learning model to train.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "6. Explain learning rate in the context of neural network models. What happens if the learning rate is too high or too low?",
        "answer": "Learning rate is a number that ranges from 0 to 1. It is one of the most important tunable hyperparameters in neural network training models. The learning rate determines how quickly or slowly a neural network model adapts to a given situation and learns. A higher learning rate value indicates that the model only needs a few training epochs and produces rapid changes, whereas a lower learning rate indicates that the model may take a long time to converge or may never converge and become stuck on a poor solution. As a result, it is recommended that a good learning rate value be established by trial and error rather than using a learning rate that is too low or too high.   In the above image, we can clearly see that a big learning rate leads us to move away from the desired output. However, having a small learning rate leads us to the desired output eventually.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "7. Explain what a deep neural network is.",
        "answer": "An artificial neural network (ANN) having numerous layers between the input and output layers is known as a deep neural network (DNN). Deep neural networks are neural networks that use deep architectures. The term \"deep\" refers to functions that have a higher number of layers and units in a single layer. It is possible to create more accurate models by adding more and larger layers to capture higher levels of patterns. The below image depicts a deep neural network.  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "8. What are the different types of deep neural networks?",
        "answer": "Following are the different types of deep neural networks:- FeedForward Neural Network:- This is the most basic type of neural network, in which flow control starts at the input layer and moves to the output layer. These networks only have a single layer or a single hidden layer. There is no backpropagation mechanism in this network because data only flows in one way. The input layer of this network receives the sum of the weights present in the input. These networks are utilised in the computer vision-based facial recognition method. FeedForward Neural Network:- This is the most basic type of neural network, in which flow control starts at the input layer and moves to the output layer. These networks only have a single layer or a single hidden layer. There is no backpropagation mechanism in this network because data only flows in one way. The input layer of this network receives the sum of the weights present in the input. These networks are utilised in the computer vision-based facial recognition method. FeedForward Neural Network:-   Radial Basis Function Neural Network:- This type of neural network usually has more than one layer, preferably two. The relative distance from any location to the center is determined in this type of network and passed on to the next layer. In order to avoid blackouts, radial basis networks are commonly employed in power restoration systems to restore power in the shortest period possible.\nMulti-Layer Perceptrons (MLP):- A multilayer perceptron (MLP) is a type of feedforward artificial neural network (ANN). MLPs are the simplest deep neural networks, consisting of a succession of completely linked layers. Each successive layer is made up of a collection of nonlinear functions that are the weighted sum of all the previous layer's outputs (completely linked). Speech recognition and other machine learning systems rely heavily on these networks. Radial Basis Function Neural Network:- This type of neural network usually has more than one layer, preferably two. The relative distance from any location to the center is determined in this type of network and passed on to the next layer. In order to avoid blackouts, radial basis networks are commonly employed in power restoration systems to restore power in the shortest period possible. Radial Basis Function Neural Network:- Multi-Layer Perceptrons (MLP):- A multilayer perceptron (MLP) is a type of feedforward artificial neural network (ANN). MLPs are the simplest deep neural networks, consisting of a succession of completely linked layers. Each successive layer is made up of a collection of nonlinear functions that are the weighted sum of all the previous layer's outputs (completely linked). Speech recognition and other machine learning systems rely heavily on these networks. Multi-Layer Perceptrons (MLP):-   Convolutional Neural Network (CNN):- Convolutional Neural Networks are mostly used in computer vision. In contrast to fully linked layers in MLPs, one or more convolution layers extract simple characteristics from input by performing convolution operations in CNN models. Each layer is made up of nonlinear functions of weighted sums at various coordinates of spatially close subsets of the previous layer's outputs, allowing the weights to be reused.\nThe AI system learns to automatically extract the properties of these inputs to fulfill a specific task, such as picture classification, face identification, and image semantic segmentation, given a sequence of images or videos from the actual world. Convolutional Neural Network (CNN):- Convolutional Neural Networks are mostly used in computer vision. In contrast to fully linked layers in MLPs, one or more convolution layers extract simple characteristics from input by performing convolution operations in CNN models. Each layer is made up of nonlinear functions of weighted sums at various coordinates of spatially close subsets of the previous layer's outputs, allowing the weights to be reused.\nThe AI system learns to automatically extract the properties of these inputs to fulfill a specific task, such as picture classification, face identification, and image semantic segmentation, given a sequence of images or videos from the actual world. Convolutional Neural Network (CNN):-    Recurrent Neural Network (RNN):- Recurrent Neural Networks were created to solve the sequential input data time-series problem. RNN's input is made up of the current input and prior samples. As a result, the node connections create a directed graph. Furthermore, each neuron in an RNN has an internal memory that stores the information from previous samples' computations. Because of their superiority in processing data with a variable input length, RNN models are commonly employed in natural language processing (NLP). The goal of AI in this case is to create a system that can understand human-spoken natural languages, such as natural language modeling, word embedding, and machine translation.\nEach successive layer in an RNN is made up of nonlinear functions of weighted sums of outputs and the preceding state. As a result, the basic unit of RNN is termed \"cell,\" and each cell is made up of layers and a succession of cells that allow recurrent neural network models to be processed sequentially. Recurrent Neural Network (RNN):- Recurrent Neural Networks were created to solve the sequential input data time-series problem. RNN's input is made up of the current input and prior samples. As a result, the node connections create a directed graph. Furthermore, each neuron in an RNN has an internal memory that stores the information from previous samples' computations. Because of their superiority in processing data with a variable input length, RNN models are commonly employed in natural language processing (NLP). The goal of AI in this case is to create a system that can understand human-spoken natural languages, such as natural language modeling, word embedding, and machine translation.\nEach successive layer in an RNN is made up of nonlinear functions of weighted sums of outputs and the preceding state. As a result, the basic unit of RNN is termed \"cell,\" and each cell is made up of layers and a succession of cells that allow recurrent neural network models to be processed sequentially. Recurrent Neural Network (RNN):-    Modular Neural Network:- This network is made up of numerous tiny neural networks, rather than being a single network. The sub-networks combine to form a larger neural network, which operates independently to achieve a common goal. These networks are extremely useful for breaking down a large-small problem into smaller chunks and then solving it. Modular Neural Network:- This network is made up of numerous tiny neural networks, rather than being a single network. The sub-networks combine to form a larger neural network, which operates independently to achieve a common goal. These networks are extremely useful for breaking down a large-small problem into smaller chunks and then solving it. Modular Neural Network:-   Sequence to Sequence Model:-  In most cases, this network is made up of two RNN networks. The network is based on encoding and decoding, which means it has an encoder that processes the input and a decoder that processes the output. This type of network is commonly employed for text processing when the length of the inputting text differs from the length of the outputted text. Sequence to Sequence Model:-  In most cases, this network is made up of two RNN networks. The network is based on encoding and decoding, which means it has an encoder that processes the input and a decoder that processes the output. This type of network is commonly employed for text processing when the length of the inputting text differs from the length of the outputted text. Sequence to Sequence Model:-",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "9. What do you mean by end-to-end learning?",
        "answer": "It's a deep learning procedure in which a model is fed raw data and the entire data is trained at the same time to create the desired result with no intermediate steps. It is a deep learning method in which all of the different steps are trained simultaneously rather than sequentially. End-to-end learning has the advantage of eliminating the requirement for implicit feature engineering, which usually results in lower bias. Driverless automobiles are an excellent example that you may use in your end-to-end learning content. They are guided by human input and are programmed to learn and interpret information automatically using a CNN to fulfill tasks. Another good example is the generation of a written transcript (output) from a recorded audio clip (input). The model here skips all of the steps in the middle, focusing instead on the fact that it can manage the entire sequence of steps and tasks.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "10. What do you understand about gradient clipping in the context of deep learning?",
        "answer": "Gradient Clipping is a technique for dealing with the problem of exploding gradients (a situation in which huge error gradients build up over time, resulting in massive modifications to neural network model weights during training) that happens during backpropagation. The problem of exploding gradients occurs when the gradients get excessively big during training, causing the model to become unstable. If the gradient has crossed the anticipated range, the gradient values are driven element-by-element to a specific minimum or maximum value. Gradient clipping improves numerical stability while training a neural network, but it has little effect on the performance of the model.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "11. Explain Forward and Back Propagation in the context of deep learning.",
        "answer": "Forward Propagation: The hidden layer, between the input layer and the output layer of the network, receives inputs with weights. We calculate the output of the activation at each node at each hidden layer, and this propagates to the next layer until we reach the final output layer. We go forward from the inputs to the final output layer, which is known as the forward propagation.\nBack Propagation: It sends error information from the network's last layer to all of the weights within the network. It's a technique for fine-tuning the weights of a neural network based on the previous epoch's (i.e., iteration) error rate. By fine-tuning the weights, you may lower error rates and improve the model's generalization, making it more dependable. The process of backpropagation can be broken down into the following steps: It can generate output by propagating training data through the network. It, then, computes the error derivative for output activations using the target and output values. It can backpropagate to compute the derivative of the error in the previous layer's output activation, and so on for all hidden layers. It calculates the error derivative for weights using the previously obtained derivatives and all hidden layers. The weights are updated based on the error derivatives obtained from the next layer. Forward Propagation: The hidden layer, between the input layer and the output layer of the network, receives inputs with weights. We calculate the output of the activation at each node at each hidden layer, and this propagates to the next layer until we reach the final output layer. We go forward from the inputs to the final output layer, which is known as the forward propagation. Forward Propagation: Back Propagation: It sends error information from the network's last layer to all of the weights within the network. It's a technique for fine-tuning the weights of a neural network based on the previous epoch's (i.e., iteration) error rate. By fine-tuning the weights, you may lower error rates and improve the model's generalization, making it more dependable. The process of backpropagation can be broken down into the following steps: It can generate output by propagating training data through the network. It, then, computes the error derivative for output activations using the target and output values. It can backpropagate to compute the derivative of the error in the previous layer's output activation, and so on for all hidden layers. It calculates the error derivative for weights using the previously obtained derivatives and all hidden layers. The weights are updated based on the error derivatives obtained from the next layer. Back Propagation:",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "12. Explain Data Normalisation. What is the need for it?",
        "answer": "Data Normalisation is a technique in which data is transformed in such a way that they are either dimensionless or have a similar distribution. It is also known as standardization and feature scaling. It's a pre-processing procedure for the input data that removes redundant data from the dataset. Normalization provides each variable equal weights/importance, ensuring that no single variable biases model performance in its favour simply because it is larger. It vastly improves model precision by converting the values of numeric columns in a dataset to a similar scale without distorting the range of values.  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "13. What are the different techniques to achieve data normalization?",
        "answer": "Following are the different techniques employed to achieve data normalization:- Rescaling: Rescaling data is the process of multiplying each member of a data set by a constant term k, or changing each integer x to f(X), where f(x) = kx and k and x are both real values. The simplest of all approaches, rescaling (also known as \"min-max normalization\"), is calculated as:\n\n  x\n'\n=\nx\n-\nm\ni\nn\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n)\n \n\nThis represents the rescaling factor for every data point x. Rescaling: Rescaling data is the process of multiplying each member of a data set by a constant term k, or changing each integer x to f(X), where f(x) = kx and k and x are both real values. The simplest of all approaches, rescaling (also known as \"min-max normalization\"), is calculated as:\n\n  x\n'\n=\nx\n-\nm\ni\nn\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n)\n \n\nThis represents the rescaling factor for every data point x. Rescaling:   x\n'\n=\nx\n-\nm\ni\nn\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n'\n=\nx\n-\nm\ni\nn\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n'\n=\nx\n-\nm\ni\nn\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n' x ' = x\n-\nm\ni\nn\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n-\nm\ni\nn\n(\nx\n) x - m i n ( x ) m\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) m a x ( x ) - m i n ( x )      Mean Normalisation: In the transformation process, this approach employs the mean of the observations:\n\n x\n'\n=\nx\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n)\n\n\nThis represents the mean normalizing factor for every data point x. Mean Normalisation: In the transformation process, this approach employs the mean of the observations:\n\n x\n'\n=\nx\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n)\n\n\nThis represents the mean normalizing factor for every data point x. Mean Normalisation:   x\n'\n=\nx\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n'\n=\nx\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n'\n=\nx\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n' x ' = x\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n)\nm\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) x\n-\na\nv\ne\nr\na\ng\ne\n(\nx\n) x - a v e r a g e ( x ) m\na\nx\n(\nx\n)\n-\nm\ni\nn\n(\nx\n) m a x ( x ) - m i n ( x )      Z-score Normalisation: This technique, also known as standardization, employs the Z-score or \"standard score.\" SVM and logistic regression are two examples of machine learning algorithms that utilise it:\n\n z\n=\nx\n-\nμ\nσ\n\n\nThis represents the Z-score. Z-score Normalisation: This technique, also known as standardization, employs the Z-score or \"standard score.\" SVM and logistic regression are two examples of machine learning algorithms that utilise it:\n\n z\n=\nx\n-\nμ\nσ\n\n\nThis represents the Z-score. Z-score Normalisation:   z\n=\nx\n-\nμ\nσ z\n=\nx\n-\nμ\nσ z\n=\nx\n-\nμ\nσ z = x\n-\nμ\nσ x\n-\nμ x - μ σ     ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "14. What do you mean by hyperparameters in the context of deep learning?",
        "answer": "Hyperparameters are variables that determine the network topology (for example, the number of hidden units) and how the network is trained (Eg: Learning Rate). They are set before training the model, that is, before optimizing the weights and the bias. Following are some of the examples of hyperparameters:- Number of hidden layers: With regularisation techniques, many hidden units inside a layer can boost accuracy. Underfitting may occur if the number of units is reduced. \nLearning Rate: The learning rate is the rate at which a network's parameters are updated. The learning process is slowed by a low learning rate, but it eventually converges. A faster learning rate accelerates the learning process, but it may not converge. A declining Learning rate is usually desired. Number of hidden layers: With regularisation techniques, many hidden units inside a layer can boost accuracy. Underfitting may occur if the number of units is reduced. Number of hidden layers: Learning Rate: The learning rate is the rate at which a network's parameters are updated. The learning process is slowed by a low learning rate, but it eventually converges. A faster learning rate accelerates the learning process, but it may not converge. A declining Learning rate is usually desired. Learning Rate:  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "15. Difference between multi-class and multi-label classification problems.",
        "answer": "  The classification task in a multi-class classification problem has more than two mutually exclusive classes (classes that have no intersection or no attributes in common), whereas in a multi-label classification problem, each label has a different classification task, although the tasks are related in some way. For example, classifying a group of photographs of animals that could be cats, dogs, or bears is a multi-class classification problem that assumes each sample can be of only one type, implying that an image can be categorized as either a cat or a dog, but not both at the same time. Now let us assume you wish to manipulate the image below.   The image above must be categorized as both a cat and a dog because it depicts both creatures. A set of labels is allocated to each sample in a multi-label classification issue, and the classes are not mutually exclusive. In a multi-label classification problem, a pattern can belong to one or more classes.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "16. Explain transfer learning in the context of deep learning.",
        "answer": "Transfer learning is a learning technique that allows data scientists to use what they've learned from a previous machine learning model that was used for a similar task. The ability of humans to transfer their knowledge is used as an example in this learning. You can learn to operate other two-wheeled vehicles more simply if you learn to ride a bicycle. A model trained for autonomous automobile driving can also be used for autonomous truck driving. The features and weights can be used to train the new model, allowing it to be reused. When there is limited data, transfer learning works effectively for quickly training a model. data scientists   In the above image, the first diagram represents training a model from scratch while the second diagram represents using a model already trained on cats and dogs to classify the different class of vehicles, thereby representing transfer learning.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "17. What are the advantages of transfer learning?",
        "answer": "Following are the advantages of transfer learning : Better initial model: In other methods of learning, you must create a model from scratch. Transfer learning is a better starting point because it allows us to perform tasks at a higher level without having to know the details of the starting model.\nHigher learning rate: Because the problem has already been taught for a similar task, transfer learning allows for a faster learning rate during training.\nHigher accuracy after training: Transfer learning allows a deep learning model to converge at a higher performance level, resulting in more accurate output, thanks to a better starting point and higher learning rate. Better initial model: In other methods of learning, you must create a model from scratch. Transfer learning is a better starting point because it allows us to perform tasks at a higher level without having to know the details of the starting model. Better initial model: Higher learning rate: Because the problem has already been taught for a similar task, transfer learning allows for a faster learning rate during training. Higher learning rate: Higher accuracy after training: Transfer learning allows a deep learning model to converge at a higher performance level, resulting in more accurate output, thanks to a better starting point and higher learning rate. Higher accuracy after training:",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "18. Is it possible to train a neural network model by setting all biases to 0? Also, is it possible to train a neural network model by setting all of the weights to 0?",
        "answer": "Yes, even if all of the biases are set to zero, the neural network model has a chance of learning. No, training a model by setting all of the weights to 0 is impossible since the neural network will never learn to complete a task. When all weights are set to zero, the derivatives for each w remain constant, resulting in neurons learning the same features in each iteration. Any constant initialization of weights, not simply zero, is likely to generate a poor result.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "19. What is a tensor in deep learning?",
        "answer": "A tensor is a multidimensional array that represents a generalization of vectors and matrices. It is one of the key data structures used in deep learning. Tensors are represented as n-dimensional arrays of base data types. The data type of each element in the Tensor is the same, and the data type is always known. It's possible that only a portion of the shape (that is, the number of dimensions and the size of each dimension) is known. Most operations yield fully-known tensors if their inputs are likewise fully known, however, in other circumstances, the shape of a tensor can only be determined at graph execution time.  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "20. Explain the difference between a shallow network and a deep network.",
        "answer": "A hidden layer, as well as input and output layers, are present in every neural network. Shallow neural networks are those that have only one hidden layer, whereas deep neural networks include numerous hidden layers. Both shallow and deep networks can fit into any function, however, shallow networks require a large number of input parameters, whereas deep networks, because of their several layers, can fit functions with a small number of input parameters. Deep networks are currently favored over shallow networks because the model learns a new and abstract representation of the input at each layer. In comparison to shallow networks, they are also far more efficient in terms of the number of parameters and computations.  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "21. In a Convolutional Neural Network (CNN), how can you fix the constant validation accuracy?",
        "answer": "When training any neural network, constant validation accuracy is a common issue because the network just remembers the sample, resulting in an over-fitting problem. Over-fitting a model indicates that the neural network model performs admirably on the training sample, but the model's performance deteriorates on the validation set. Following are some ways for improving CNN's constant validation accuracy: It is always a good idea to split the dataset into three sections: training, validation, and testing.\nWhen working with limited data, this difficulty can be handled by experimenting with the neural network's parameters.\nBy increasing the training dataset's size.\nBy using batch normalization.\nBy implementing regularization\nBy reducing the complexity of the network It is always a good idea to split the dataset into three sections: training, validation, and testing. When working with limited data, this difficulty can be handled by experimenting with the neural network's parameters. By increasing the training dataset's size. By using batch normalization. By implementing regularization By reducing the complexity of the network",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "22. Explain Batch Gradient Descent.",
        "answer": "Batch Gradient Descent: Batch Gradient Descent entails computation (involved in each step of gradient descent) over the entire training set at each step and hence it is highly slow on very big training sets. As a result, Batch Gradient Descent becomes extremely computationally expensive. This is ideal for error manifolds that are convex or somewhat smooth. Batch Gradient Descent also scales nicely as the number of features grows. Batch Gradient Descent:  ",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "23. Explain Stochastic Gradient Descent. How is it different from Batch Gradient Descent?",
        "answer": "Stochastic Gradient Descent: Stochastic Gradient Descent seeks to tackle the major difficulty with Batch Gradient Descent, which is the use of the entire training set to calculate gradients at each step. It is stochastic in nature, which means it chooses up a \"random\" instance of training data at each step and then computes the gradient, which is significantly faster than Batch Gradient Descent because there are much fewer data to modify at once. Stochastic Gradient Descent is best suited for unconstrained optimization problems. The stochastic nature of SGD has a drawback in that once it gets close to the minimum value, it doesn't settle down and instead bounces around, giving us a good but not optimal value for model parameters. This can be solved by lowering the learning rate at each step, which will reduce the bouncing and allow SGD to settle down at the global minimum after some time. Stochastic Gradient Descent: Following are the differences between the two:-   Batch Gradient Descent Stochastic Gradient Descent\nThe gradient is calculated using the entire training dataset. A single training sample is used to compute the gradient.\nIt is slow and computationally more expensive than Stochastic Gradient Descent. It is faster and less computationally expensive than Batch Gradient Descent.\nIt is not recommended for large training samples.  It is recommended for large training samples.\nIt is deterministic (not random) in nature. It is stochastic (random) in nature.\nGiven enough time to converge, it returns the best answer. It provides a good solution, but not the best.\nThere is no need to shuffle the data points at random. Because we want the data sample to be in a random order, we'll shuffle the training set for each epoch.\nIn this, it is difficult to get out of shallow local minimas. It has a better chance of escaping shallow local minima.\nIn this, the convergence is slow.  It arrives at the convergence point substantially faster. Batch Gradient Descent Stochastic Gradient Descent\nThe gradient is calculated using the entire training dataset. A single training sample is used to compute the gradient.\nIt is slow and computationally more expensive than Stochastic Gradient Descent. It is faster and less computationally expensive than Batch Gradient Descent.\nIt is not recommended for large training samples.  It is recommended for large training samples.\nIt is deterministic (not random) in nature. It is stochastic (random) in nature.\nGiven enough time to converge, it returns the best answer. It provides a good solution, but not the best.\nThere is no need to shuffle the data points at random. Because we want the data sample to be in a random order, we'll shuffle the training set for each epoch.\nIn this, it is difficult to get out of shallow local minimas. It has a better chance of escaping shallow local minima.\nIn this, the convergence is slow.  It arrives at the convergence point substantially faster. Batch Gradient Descent Stochastic Gradient Descent\nThe gradient is calculated using the entire training dataset. A single training sample is used to compute the gradient.\nIt is slow and computationally more expensive than Stochastic Gradient Descent. It is faster and less computationally expensive than Batch Gradient Descent.\nIt is not recommended for large training samples.  It is recommended for large training samples.\nIt is deterministic (not random) in nature. It is stochastic (random) in nature.\nGiven enough time to converge, it returns the best answer. It provides a good solution, but not the best.\nThere is no need to shuffle the data points at random. Because we want the data sample to be in a random order, we'll shuffle the training set for each epoch.\nIn this, it is difficult to get out of shallow local minimas. It has a better chance of escaping shallow local minima.\nIn this, the convergence is slow.  It arrives at the convergence point substantially faster. Batch Gradient Descent Stochastic Gradient Descent Batch Gradient Descent Batch Gradient Descent Stochastic Gradient Descent Stochastic Gradient Descent The gradient is calculated using the entire training dataset. A single training sample is used to compute the gradient. The gradient is calculated using the entire training dataset. A single training sample is used to compute the gradient. It is slow and computationally more expensive than Stochastic Gradient Descent. It is faster and less computationally expensive than Batch Gradient Descent. It is slow and computationally more expensive than Stochastic Gradient Descent. It is faster and less computationally expensive than Batch Gradient Descent. It is not recommended for large training samples.  It is recommended for large training samples. It is not recommended for large training samples. It is recommended for large training samples. It is deterministic (not random) in nature. It is stochastic (random) in nature. It is deterministic (not random) in nature. It is stochastic (random) in nature. Given enough time to converge, it returns the best answer. It provides a good solution, but not the best. Given enough time to converge, it returns the best answer. It provides a good solution, but not the best. There is no need to shuffle the data points at random. Because we want the data sample to be in a random order, we'll shuffle the training set for each epoch. There is no need to shuffle the data points at random. Because we want the data sample to be in a random order, we'll shuffle the training set for each epoch. In this, it is difficult to get out of shallow local minimas. It has a better chance of escaping shallow local minima. In this, it is difficult to get out of shallow local minimas. It has a better chance of escaping shallow local minima. In this, the convergence is slow.  It arrives at the convergence point substantially faster. In this, the convergence is slow. It arrives at the convergence point substantially faster.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "24. Which deep learning algorithm is the best for face detection?",
        "answer": "  Face identification may be accomplished using a variety of machine learning methods, but the best ones use Convolutional Neural Networks and deep learning. The following are some notable face detection algorithms: FaceNet, Probablisit, Face Embedding, ArcFace, Cosface, and Spherface.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "25. What is an activation function? What is the use of an activation function?",
        "answer": "An artificial neural network's activation function is a function that is introduced to help the network learn complex patterns in the data. When compared to a neuron-based model seen in our brains, the activation function is responsible for determining what is to be fired to the next neuron at the end of the process. In an ANN, an activation function performs the same job. It takes the preceding cell's output signal and turns it into a format that may be used as input to the next cell.   Here, x0 and x1 are the inputs. w1 is the weight and a is the activation function. The activation function introduces non-linearity into the neural network, allowing it to learn more complex functions. The neural network would only be able to learn a function that is a linear combination of its input data if it didn't have the Activation function. The activation function converts inputs to outputs. The activation function is in charge of determining whether or not a neuron should be stimulated. It arrives at a decision by calculating the weighted total and then adds bias. The activation function's main goal is to introduce non-linearity into a neuron's output.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "26. What do you mean by an epochs in the context of deep learning?",
        "answer": "An epoch is a terminology used in deep learning that refers to the number of passes the deep learning algorithm has made across the full training dataset. Batches are commonly used to group data sets (especially when the amount of data is very large). The term \"iteration\" refers to the process of running one batch through the model. The number of epochs equals the number of iterations if the batch size is the entire training dataset. This is frequently not the case for practical reasons. Several epochs are used in the creation of many models. There is a general relation which is given by:- d * e = i * b d * e = i * b d * e = i * b where, d is the dataset size e is the number of epochs i is the number of iterations b is the batch size",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "1. Explain the different types of activation functions.",
        "answer": "Following are the different types of activation functions:   Sigmoid function: The sigmoid function is a non-linear activation function in an ANN that is mostly utilised in feedforward neural networks. It's a differentiable real function with positive derivatives everywhere and a certain degree of smoothness, defined for real input values. The sigmoid function is found in the deep learning models' output layer and is used to anticipate probability-based outputs. The sigmoid function is written as follows: Sigmoid function: f\n(\nx\n)\n=\n(\n1\n(\n1\n+\ne\nx\np\n-\nx\n)\n)\n-\n(\n1\n.\n4\n) f\n(\nx\n)\n=\n(\n1\n(\n1\n+\ne\nx\np\n-\nx\n)\n)\n-\n(\n1\n.\n4\n) f\n(\nx\n)\n=\n(\n1\n(\n1\n+\ne\nx\np\n-\nx\n)\n)\n-\n(\n1\n.\n4\n) f\n(\nx\n)\n=\n(\n1\n(\n1\n+\ne\nx\np\n-\nx\n)\n)\n-\n(\n1\n.\n4\n) f\n(\nx\n)\n=\n(\n1\n(\n1\n+\ne\nx\np\n-\nx\n)\n)\n-\n(\n1\n.\n4\n) f ( x ) = ( 1\n(\n1\n+\ne\nx\np\n-\nx\n) 1 (\n1\n+\ne\nx\np\n-\nx\n) ( 1 + e x p\n-\nx p -\nx - x ) ) - ( 1 . 4 )  Hyperbolic Tangent Function (Tanh): The Tanh function is a smoother and zero-centered function having a range of -1 to 1. The output of the tanh function is represented by: Hyperbolic Tangent Function (Tanh): f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f ( x\ni x i ) = e\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n) e\nx\np\n(\nx\ni\n) e x p ( x\ni x i ) ∑\nj\ne\nx\np\n(\nx\nj\n) ∑\nj ∑\nj ∑ j e x p ( x\nj x j ) - ( 1 . 12 )  Because it provides higher training performance for multilayer neural networks, the tanh function is considerably more widely utilised than the sigmoid function. The tanh function's primary advantage is that it gives a zero-centered output, which helps with backpropagation. Softmax function: The softmax function is another type of activation function used in neural networks to generate probability distribution from a vector of real numbers. This function returns a number between 0 and 1, with the sum of the probabilities equal to 1. The softmax function is written like this: Softmax function: f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n)\n\nThis function is most commonly used in multi-class models, returning probabilities for each class, with the target class having the highest probability. It can be found in practically all of the output layers of the DL architecture. f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f\n(\nx\ni\n)\n=\ne\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n)\n-\n(\n1\n.\n12\n) f ( x\ni x i ) = e\nx\np\n(\nx\ni\n)\n∑\nj\ne\nx\np\n(\nx\nj\n) e\nx\np\n(\nx\ni\n) e x p ( x\ni x i ) ∑\nj\ne\nx\np\n(\nx\nj\n) ∑\nj ∑\nj ∑ j e x p ( x\nj x j ) - ( 1 . 12 )   Softsign function: This is most commonly used in regression computation issues and text-to-speech applications based on deep learning. It's a quadratic polynomial with the following representation: Softsign function: f\n(\nx\n)\n=\n(\nx\nx\n+\n1\n)\n-\n(\n1\n.\n13\n) f\n(\nx\n)\n=\n(\nx\nx\n+\n1\n)\n-\n(\n1\n.\n13\n) f\n(\nx\n)\n=\n(\nx\nx\n+\n1\n)\n-\n(\n1\n.\n13\n) f\n(\nx\n)\n=\n(\nx\nx\n+\n1\n)\n-\n(\n1\n.\n13\n) f\n(\nx\n)\n=\n(\nx\nx\n+\n1\n)\n-\n(\n1\n.\n13\n) f ( x ) = ( x\nx\n+\n1 x x\n+\n1 x x + 1 ) - ( 1 . 13 )  Rectified Linear Unit Function: The rectified linear unit (ReLU) function is a fast-learning artificial intelligence (AI) that promises to give cutting-edge performance and outstanding results. In deep learning, the ReLU function outperforms other AFs like the sigmoid and tanh functions in terms of performance and generalisation. The function is a roughly linear function that preserves the features of linear models, making gradient-descent approaches easier to optimise. Rectified Linear Unit Function: On each input element, the ReLU function performs a threshold operation, setting all values less than zero to zero. As a result, the ReLU is written as: f\n(\nx\n)\n=\nm\na\nx\n(\n0\n,\nx\n)\n=\nx\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) f\n(\nx\n)\n=\nm\na\nx\n(\n0\n,\nx\n)\n=\nx\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) f\n(\nx\n)\n=\nm\na\nx\n(\n0\n,\nx\n)\n=\nx\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) f\n(\nx\n)\n=\nm\na\nx\n(\n0\n,\nx\n)\n=\nx\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) f\n(\nx\n)\n=\nm\na\nx\n(\n0\n,\nx\n)\n=\nx\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) f ( x ) = m a x ( 0 , x ) = x\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) x\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0\n-\n(\n1\n.\n14\n) x\ni\n,\n  i\nf\n x\ni\n≥\n0\n0\n,\n i\nf\n x\ni\n<\n0 x\ni\n,\n  i\nf\n x\ni\n≥\n0 x\ni\n,\n  i\nf\n x\ni\n≥\n0 x\ni x i ,   i f  x\ni x i ≥ 0 0\n,\n i\nf\n x\ni\n<\n0 0\n,\n i\nf\n x\ni\n<\n0 0 ,  i f  x\ni x i < 0 - ( 1 . 14 )  Exponential Linear Unit Function: The exponential linear units (ELUs) function is a type of AF that can be used to speed up neural network training (just like ReLU function). The ELU function's major advantage is that it can solve the vanishing gradient problem by employing identity for positive values and boosting the model's learning properties. The exponential linear unit function has the following representation: Exponential Linear Unit Function: f\n(\nx\n)\n=\nx\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0\n-\n(\n1\n.\n22\n) f\n(\nx\n)\n=\nx\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0\n-\n(\n1\n.\n22\n) f\n(\nx\n)\n=\nx\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0\n-\n(\n1\n.\n22\n) f\n(\nx\n)\n=\nx\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0\n-\n(\n1\n.\n22\n) f\n(\nx\n)\n=\nx\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0\n-\n(\n1\n.\n22\n) f ( x ) = x\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0 x\n,\n               i\nf\n x\n>\n0\nα\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0 x\n,\n               i\nf\n x\n>\n0 x\n,\n               i\nf\n x\n>\n0 x ,                i f  x > 0 α\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0 α\n e\nx\np\n(\nx\n)\n-\n1\n,\n i\nf\n x\n≤\n0 α  e x p ( x ) - 1 ,  i f  x ≤ 0 - ( 1 . 22 )  Interview Resources NLP Interview Questions and Answers\nArtificial Intelligence Interview Questions and Answers\nData Science Interview Questions and Answers\nFree Deep Learning Tutorial\nScaler Data Science & Machine Learning Program\nPopular Deep Learning Projects With Source Code\nHighest Paying Jobs In India (IT Sector) NLP Interview Questions and Answers NLP Interview Questions and Answers Artificial Intelligence Interview Questions and Answers Artificial Intelligence Interview Questions and Answers Data Science Interview Questions and Answers Data Science Interview Questions and Answers Free Deep Learning Tutorial Free Deep Learning Tutorial Scaler Data Science & Machine Learning Program Scaler Data Science & Machine Learning Program Popular Deep Learning Projects With Source Code Popular Deep Learning Projects With Source Code Highest Paying Jobs In India (IT Sector) Highest Paying Jobs In India (IT Sector)",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "2. Differentiate between Deep Learning and Machine Learning.",
        "answer": "Deep Learning: Deep Learning is a subclass of Machine Learning in which a recurrent neural network and an artificial neural network are linked. The algorithms are constructed in the same way as machine learning algorithms are, however, there are many more levels of algorithms. The artificial neural network refers to all of the algorithm's networks put together. In much simpler terms, it mimics the human brain by connecting all of the neural networks in the brain, which is the concept of deep learning. It uses algorithms and a technique to tackle all types of complex problems.\nMachine Learning: Machine learning is a subset of Artificial Intelligence (AI) that allows a system to learn and grow from its experiences without having to be programmed to that level. Data is used by Machine Learning to learn and get accurate outcomes. Machine learning algorithms have the ability to learn and improve their performance by gaining more data. Machine learning is currently employed in self-driving cars, cyber fraud detection, face recognition, and Facebook friend suggestion, among other applications. Learn More. Deep Learning: Deep Learning is a subclass of Machine Learning in which a recurrent neural network and an artificial neural network are linked. The algorithms are constructed in the same way as machine learning algorithms are, however, there are many more levels of algorithms. The artificial neural network refers to all of the algorithm's networks put together. In much simpler terms, it mimics the human brain by connecting all of the neural networks in the brain, which is the concept of deep learning. It uses algorithms and a technique to tackle all types of complex problems. Deep Learning: Machine Learning: Machine learning is a subset of Artificial Intelligence (AI) that allows a system to learn and grow from its experiences without having to be programmed to that level. Data is used by Machine Learning to learn and get accurate outcomes. Machine learning algorithms have the ability to learn and improve their performance by gaining more data. Machine learning is currently employed in self-driving cars, cyber fraud detection, face recognition, and Facebook friend suggestion, among other applications. Learn More. Machine Learning:  Learn More Learn More .   The following table illustrates the difference between them: Deep Learning Machine Learning\nDeep Learning is a subclass of Machine Learning. Machine Learning is a super-class of Deep Learning.\nDeep Learning employs neural networks to represent data, which is a very distinct data representation (ANN). Machine Learning represents data in a different way than Deep Learning since it uses structured data.\nIn this, the output ranges from numerical values to free-form elements such as text or sound. In this, the output consists of numerical values \nIt uses a neural network to evaluate data features and relationships by passing data through processing layers. It uses a variety of automated techniques to convert input into model functions and forecast future actions.\nIt usually deals with millions of data points.  It usually deals with thousands of data points.\nMachine Learning has evolved into Deep Learning. Essentially, it refers to the depth of machine learning. Artificial Intelligence has evolved into Machine Learning. Deep Learning Machine Learning\nDeep Learning is a subclass of Machine Learning. Machine Learning is a super-class of Deep Learning.\nDeep Learning employs neural networks to represent data, which is a very distinct data representation (ANN). Machine Learning represents data in a different way than Deep Learning since it uses structured data.\nIn this, the output ranges from numerical values to free-form elements such as text or sound. In this, the output consists of numerical values \nIt uses a neural network to evaluate data features and relationships by passing data through processing layers. It uses a variety of automated techniques to convert input into model functions and forecast future actions.\nIt usually deals with millions of data points.  It usually deals with thousands of data points.\nMachine Learning has evolved into Deep Learning. Essentially, it refers to the depth of machine learning. Artificial Intelligence has evolved into Machine Learning. Deep Learning Machine Learning Deep Learning Machine Learning Deep Learning Machine Learning Deep Learning is a subclass of Machine Learning. Machine Learning is a super-class of Deep Learning.\nDeep Learning employs neural networks to represent data, which is a very distinct data representation (ANN). Machine Learning represents data in a different way than Deep Learning since it uses structured data.\nIn this, the output ranges from numerical values to free-form elements such as text or sound. In this, the output consists of numerical values \nIt uses a neural network to evaluate data features and relationships by passing data through processing layers. It uses a variety of automated techniques to convert input into model functions and forecast future actions.\nIt usually deals with millions of data points.  It usually deals with thousands of data points.\nMachine Learning has evolved into Deep Learning. Essentially, it refers to the depth of machine learning. Artificial Intelligence has evolved into Machine Learning. Deep Learning is a subclass of Machine Learning. Machine Learning is a super-class of Deep Learning. Deep Learning is a subclass of Machine Learning. Machine Learning is a super-class of Deep Learning. Deep Learning employs neural networks to represent data, which is a very distinct data representation (ANN). Machine Learning represents data in a different way than Deep Learning since it uses structured data. Deep Learning employs neural networks to represent data, which is a very distinct data representation (ANN). Machine Learning represents data in a different way than Deep Learning since it uses structured data. In this, the output ranges from numerical values to free-form elements such as text or sound. In this, the output consists of numerical values In this, the output ranges from numerical values to free-form elements such as text or sound. In this, the output consists of numerical values It uses a neural network to evaluate data features and relationships by passing data through processing layers. It uses a variety of automated techniques to convert input into model functions and forecast future actions. It uses a neural network to evaluate data features and relationships by passing data through processing layers. It uses a variety of automated techniques to convert input into model functions and forecast future actions. It usually deals with millions of data points.  It usually deals with thousands of data points. It usually deals with millions of data points. It usually deals with thousands of data points. Machine Learning has evolved into Deep Learning. Essentially, it refers to the depth of machine learning. Artificial Intelligence has evolved into Machine Learning. Machine Learning has evolved into Deep Learning. Essentially, it refers to the depth of machine learning. Artificial Intelligence has evolved into Machine Learning.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "3. What do you know about Dropout?",
        "answer": "Dropout is a regularization approach that helps to avoid overfitting and hence improves generalizability (that is, the model predicts correct output for most of the inputs in general, rather than only being limited to the training data set). In general, we should utilize a low dropout value of 20 percent to 50 percent of neurons, with 20% being a decent starting point. A probability that is too low has no effect, whereas a number that is too high causes the network to under-learn.   When you employ dropout on a larger network, you're more likely to achieve better results because the model has more opportunities to learn independent representations.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "4. Mention the applications of autoencoders.",
        "answer": "Following are the applications of autoencoders:- Image Denoising: Denoising images is a skill that autoencoders excel at. A noisy image is one that has been corrupted or has a little amount of noise (that is, random variation of brightness or color information in images) in it. Image denoising is used to gain accurate information about the image's content.\nDimensionality Reduction: The input is converted into a reduced representation by the autoencoders, which is stored in the middle layer called code. This is where the information from the input has been compressed, and each node may now be treated as a variable by extracting this layer from the model. As a result, we can deduce that by removing the decoder, an autoencoder can be utilised for dimensionality reduction, with the coding layer as the output.\nFeature Extraction: The encoding section of Autoencoders aids in the learning of crucial hidden features present in the input data, lowering the reconstruction error. During encoding, a new collection of original feature combinations is created.\nImage Colorization: Converting a black-and-white image to a coloured one is one of the applications of autoencoders. We can also convert a colourful image to grayscale.\nData Compression: Autoencoders can be used for data compression. Yet they are rarely used for data compression because of the following reasons:\nLossy compression: The autoencoder's output is not identical to the input, but it is a near but degraded representation. They are not the best option for lossless compression.\nData-specific: Autoencoders can only compress data that is identical to the data on which they were trained. They differ from traditional data compression algorithms like jpeg or gzip in that they learn features relevant to the provided training data. As a result, we can't anticipate a landscape photo to be compressed by an autoencoder trained on handwritten digits. Image Denoising: Denoising images is a skill that autoencoders excel at. A noisy image is one that has been corrupted or has a little amount of noise (that is, random variation of brightness or color information in images) in it. Image denoising is used to gain accurate information about the image's content. Image Denoising: Dimensionality Reduction: The input is converted into a reduced representation by the autoencoders, which is stored in the middle layer called code. This is where the information from the input has been compressed, and each node may now be treated as a variable by extracting this layer from the model. As a result, we can deduce that by removing the decoder, an autoencoder can be utilised for dimensionality reduction, with the coding layer as the output. Dimensionality Reduction: Feature Extraction: The encoding section of Autoencoders aids in the learning of crucial hidden features present in the input data, lowering the reconstruction error. During encoding, a new collection of original feature combinations is created. Feature Extraction: Image Colorization: Converting a black-and-white image to a coloured one is one of the applications of autoencoders. We can also convert a colourful image to grayscale. Image Colorization: Data Compression: Autoencoders can be used for data compression. Yet they are rarely used for data compression because of the following reasons:\nLossy compression: The autoencoder's output is not identical to the input, but it is a near but degraded representation. They are not the best option for lossless compression.\nData-specific: Autoencoders can only compress data that is identical to the data on which they were trained. They differ from traditional data compression algorithms like jpeg or gzip in that they learn features relevant to the provided training data. As a result, we can't anticipate a landscape photo to be compressed by an autoencoder trained on handwritten digits. Data Compression: Lossy compression: The autoencoder's output is not identical to the input, but it is a near but degraded representation. They are not the best option for lossless compression.\nData-specific: Autoencoders can only compress data that is identical to the data on which they were trained. They differ from traditional data compression algorithms like jpeg or gzip in that they learn features relevant to the provided training data. As a result, we can't anticipate a landscape photo to be compressed by an autoencoder trained on handwritten digits. Lossy compression: The autoencoder's output is not identical to the input, but it is a near but degraded representation. They are not the best option for lossless compression. Lossy compression: Data-specific: Autoencoders can only compress data that is identical to the data on which they were trained. They differ from traditional data compression algorithms like jpeg or gzip in that they learn features relevant to the provided training data. As a result, we can't anticipate a landscape photo to be compressed by an autoencoder trained on handwritten digits. Data-specific:",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "5. What are autoencoders? Explain the different layers of autoencoders.",
        "answer": "An autoencoder is a type of neural network with the condition that the output layer has the same dimension as that of the input layer. In other words, the number of output units in the output layer is equal to the number of input units in the input layer. An autoencoder is also known as a replicator neural network since it duplicates data from the input to the output in an unsupervised way. By sending the input through the network, the autoencoders rebuild each dimension of the input. It may appear simple to use a neural network to replicate an input, however, the size of the input is reduced during the replication process, resulting in a smaller representation. In comparison to the input and output layers, the middle layers of the neural network have fewer units. As a result, the reduced representation of the input is stored in the middle layers. This reduced representation of the input is used to recreate the output. Following are the different layers in the architecture of autoencoders : Encoder: An encoder is a fully connected, feedforward neural network that compresses the input image into a latent space representation and encodes it as a compressed representation in a lower dimension. The deformed representation of the original image is the compressed image.\nCode: The reduced representation of the input that is supplied into the decoder is stored in this section of the network.\nDecoder: Like the encoder, the decoder is a feedforward network with a structure identical to the encoder. This network is in charge of reassembling the input from the code to its original dimensions. Encoder: An encoder is a fully connected, feedforward neural network that compresses the input image into a latent space representation and encodes it as a compressed representation in a lower dimension. The deformed representation of the original image is the compressed image. Encoder: Code: The reduced representation of the input that is supplied into the decoder is stored in this section of the network. Code: Decoder: Like the encoder, the decoder is a feedforward network with a structure identical to the encoder. This network is in charge of reassembling the input from the code to its original dimensions. Decoder:   As we can see in the above image, the input is compressed in the encoder, then stored in the Code, and then the original input is decompressed from the code by the decoder. The autoencoder's principal goal is to provide an output that is identical to the input.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "6. What exactly do you mean by exploding and vanishing gradients?",
        "answer": "By taking incremental steps towards the minimal value, the gradient descent algorithm aims to minimize the error. The weights and biases in a neural network are updated using these processes. However, at times, the steps grow excessively large, resulting in increased updates to weights and bias terms — to the point where the weights overflow (or become NaN, that is, Not a Number). An exploding gradient is the result of this, and it is an unstable method. On the other hand, if the steps are excessively small, it results in minor – even negligible – changes in the weights and bias terms. As a result, we may end up training a deep learning model with nearly identical weights and biases every time, never reaching the least error function. The vanishing gradient is what it's called.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "7. How does Recurrent Neural Network backpropagation vary from Artificial Neural Network backpropagation?",
        "answer": "Backpropagation in Recurrent Neural Networks differ from that of Artificial Neural Networks in the sense that each node in Recurrent Neural Networks has an additional loop as shown in the following image:   This loop, in essence, incorporates a temporal component into the network. This allows for the capture of sequential information from data, which is impossible with a generic artificial neural network.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "8. Differentiate between bias and variance in the context of deep learning models. How can you achieve balance between the two?",
        "answer": "Comprehending prediction errors is crucial when it comes to understanding predictions. Reducible (errors that arise due to squared bias or squared variance) and irreducible (errors that arise due to the randomness or natural variability in a system and cannot be reduced by varying the model) mistakes are the two primary types of errors. There are two types of reducible errors: bias and variance. Gaining a thorough grasp of these flaws aids in the construction of an accurate model by preventing overfitting and underfitting. Bias: Bias: The bias is defined as the difference between the ML model's predicted values and the actual value. Biasing results in a substantial inaccuracy in both training and testing data. To avoid the problem of underfitting, it is advised that an algorithm be low biassed at all times. The data predicted is in a straight line format due to significant bias, and hence does not fit accurately in the data set. Underfitting of data is the term for this type of fitting. This occurs when the theory is too straightforward or linear. Consider the graph below as an illustration of a situation like this.   Variance: Variance: The variance of the model is the variability of model prediction for a given data point, which tells us about the dispersion of our data. It is the difference between the validation error and the training error. The model with high variance has a very complex fit to the training data and so is unable to fit accurately on new data. As a result, while such models perform well on training data, they have high error rates when testing data. When a model's variance is excessive, it's referred to as Overfitting of Data. Overfitting, which involves accurately fitting the training set using a complicated curve and a high order hypothesis, is not a viable option because the error with unknown data is considerable. Variance should be kept to a minimum when training a data model.   The model must always aim for a low bias and a low variance in order to achieve the best balance between the two mistakes.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "9. According to you, which one is more powerful - a two layer neural network without any activation function or a two layer decision tree?",
        "answer": "A two-layer neural network is made up of three layers: one input layer, one hidden layer, and one output layer. When dealing with neural networks, an activation function is essential since it is required when dealing with complex and nonlinear functional mappings between inputs and response variables. When there is no activation function in a two-layer neural network, it is simply a linear network. A Neural Network without an Activation function is just a Linear Regression Model, which has limited capability and frequently fails to perform well. A decision tree with a depth of two layers is known as a two-layer decision tree. Decision Trees are a type of supervised machine learning (that is, the machine is fed with what the input is and what the related output is in the training data) in which the data is continually split according to a parameter. Two entities, decision nodes, and leaves can be used to explain the tree. The decisions or final outcomes are represented by the leaves. And the data is separated at the decision nodes. When comparing these two models, the two-layer neural network (without activation function) is more powerful than the two-layer decision tree, because the two-layer neural network will consider more attributes while building a model, whereas the two-layer decision tree will only consider 2 or 3 attributes.   The figure on the left depicts a 2 layer decision tree and the figure on the right depicts a 2 layer neural network.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "10. Can a deep learning model be solely built on linear regression?",
        "answer": "Yes, if the problem is represented by a linear equation, deep networks can be built using a linear function as the activation function for each layer. A problem that is a composition of linear functions, on the other hand, is a linear function, and there is nothing spectacular that can be accomplished by implementing a deep network because adding more nodes to the network will not boost the machine learning model's predictive capacity.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "11. While building a neural network architecture, how will you decide how many neurons and the hidden layers should the neural network have?",
        "answer": "There is no clear and fast rule for determining the exact number of neurons and hidden layers required to design a neural network architecture given a business problem. The size of the hidden layer in a neural network should be somewhere between the size of the output layers and that of the input layers. However, there are a few basic ways that might help you get a head start on constructing a neural network architecture: The best method to approach any unique real-world predictive modelling problem is to start with some basic systematic experimentation to see what would perform best for any given dataset based on previous experience working with neural networks in similar real-world situations. The network configuration can be chosen based on one's understanding of the problem domain and previous expertise with neural networks. The number of layers and neurons employed on similar issues is always a good place to start when evaluating a neural network's configuration.\nIt is best to start with simple neural network architecture and gradually increase the complexity of the neural network based on predicted output and accuracy. The best method to approach any unique real-world predictive modelling problem is to start with some basic systematic experimentation to see what would perform best for any given dataset based on previous experience working with neural networks in similar real-world situations. The network configuration can be chosen based on one's understanding of the problem domain and previous expertise with neural networks. The number of layers and neurons employed on similar issues is always a good place to start when evaluating a neural network's configuration. It is best to start with simple neural network architecture and gradually increase the complexity of the neural network based on predicted output and accuracy.",
        "reference": "interviewbit.com",
        "role": "deep-learning"
    },
    {
        "question": "1) What is deep learning?",
        "answer": "Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network. In the mid-1960s, Alexey Grigorevich Ivakhnenko published the first general, while working on deep learning network. Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "2) What are the main differences between AI, Machine Learning, and Deep Learning?",
        "answer": "ADVERTISEMENT\nAI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.\nMachine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.\n\nDeep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.\nUnsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "4) What are the applications of deep learning?",
        "answer": "There are various applications of deep learning:\nComputer vision\nNatural language processing and pattern recognition\nImage recognition and processing\nMachine translation\nSentiment analysis\nQuestion Answering system\nObject Classification and Detection\nAutomatic Handwriting Generation\nAutomatic Text Generation.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "5) Do you think that deep network is better than a shallow one?",
        "answer": "Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "6) What do you mean by \"overfitting\"?",
        "answer": "Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "7) What is Backpropagation?",
        "answer": "Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.\nBackpropagation can be divided into the following steps:\nIt can forward propagation of training data through the network to generate output.\nIt uses target value and output value to compute error derivative concerning output activations.\nIt can backpropagate to compute the derivative of the error concerning output activations in the previous layer and continue for all hidden layers.\nIt uses the previously calculated derivatives for output and all hidden layers to calculate the error derivative concerning weights.\nIt updates the weights.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "8) What is the function of the Fourier Transform in Deep Learning?",
        "answer": "Fourier transform package is highly efficient for analyzing, maintaining, and managing a large databases. The software is created with a high-quality feature known as the special portrayal. One can effectively utilize it to generate real-time array data, which is extremely helpful for processing all categories of signals.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "There are several forms and categories available for the particular subject, but the autonomous pattern represents independent or unspecified mathematical bases which are free from any specific categorizer or formula.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "10) What is the use of Deep learning in today's age, and how is it adding data scientists?",
        "answer": "Deep learning has brought significant changes or revolution in the field of machine learning and data science. The concept of a complex neural network (CNN) is the main center of attention for data scientists. It is widely taken because of its advantages in performing next-level machine learning operations. The advantages of deep learning also include the process of clarifying and simplifying issues based on an algorithm due to its utmost flexible and adaptable nature. It is one of the rare procedures which allow the movement of data in independent pathways. Most of the data scientists are viewing this particular medium as an advanced additive and extended way to the existing process of machine learning and utilizing the same for solving complex day to day issues.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "11) What are the deep learning frameworks or tools?",
        "answer": "Deep learning frameworks or tools are:\nTensorflow, Keras, Chainer, Pytorch, Theano & Ecosystem, Caffe2, CNTK, DyNetGensim, DSSTNE, Gluon, Paddle, Mxnet, BigDL",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "12) What are the disadvantages of deep learning?",
        "answer": "There are some disadvantages of deep learning, which are:\nDeep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity.\nThe deep learning model is not good for small data sets, and it fails here.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "13) What is the meaning of term weight initialization in neural networks?",
        "answer": "In neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error. Biases can be initialized to zero. The standard rule for setting the weights is to be close to zero without being too small.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation. In general, data normalization boils down to subtracting the mean of each data point and dividing by its standard deviation.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "15) Why is zero initialization not a good weight initialization process?",
        "answer": "If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.\nAs a result, the network cannot learn at all because there is no source of asymmetry between neurons. That is the reason why we need to add randomness to the weight initialization process.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "16) What are the prerequisites for starting in Deep Learning?",
        "answer": "There are some basic requirements for starting in Deep Learning, which are:\nMachine Learning\nMathematics\nPython Programming",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "17) What are the supervised learning algorithms in Deep learning?",
        "answer": "Artificial neural network\nConvolution neural network\nRecurrent neural network",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "18) What are the unsupervised learning algorithms in Deep learning?",
        "answer": "Self Organizing Maps\nDeep belief networks (Boltzmann Machine)\nAuto Encoders",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "19) How many layers in the neural network?",
        "answer": "Input Layer\nThe input layer contains input neurons which send information to the hidden layer.\nHidden Layer\nThe hidden layer is used to send data to the output layer.\nOutput Layer\nThe data is made available at the output layer.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "20) What is the use of the Activation function?",
        "answer": "The activation function is used to introduce nonlinearity into the neural network so that it can learn more complex function. Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.\nActivation function translates the inputs into outputs. The activation function is responsible for deciding whether a neuron should be activated or not. It makes the decision by calculating the weighted sum and further adding bias with it. The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "21) How many types of activation function are available?",
        "answer": "Binary Step\nSigmoid\nTanh\nReLU\nLeaky ReLU\nSoftmax\nSwish",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "22) What is a binary step function?",
        "answer": "The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "23) What is the sigmoid function?",
        "answer": "The sigmoid activation function is also called the logistic function. It is traditionally a trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0. It was the default activation used on neural networks, in the early 1990s.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "24) What is Tanh function?",
        "answer": "The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0. Later in the 1990s and through the 2000s, this function was preferred over the sigmoid activation function as models. It was easier to train and often had better predictive performance.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "25) What is ReLU function?",
        "answer": "A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.\nAdoption of ReLU may easily be considered one of the few milestones in the deep learning revolution.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "26) What is the use of leaky ReLU function?",
        "answer": "The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "27) What is the softmax function?",
        "answer": "The softmax function is used to calculate the probability distribution of the event over 'n' different events. One of the main advantages of using softmax is the output probabilities range. The range will be between 0 to 1, and the sum of all the probabilities will be equal to one. When the softmax function is used for multi-classification model, it returns the probabilities of each class, and the target class will have a high probability.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "28) What is a Swish function?",
        "answer": "Swish is a new, self-gated activation function. Researchers at Google discovered the Swish function. According to their paper, it performs better than ReLU with a similar level of computational efficiency.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "29) What is the most used activation function?",
        "answer": "Relu function is the most used activation function. It helps us to solve vanishing gradient problems.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "30) Can Relu function be used in output layer?",
        "answer": "No, Relu function has to be used in hidden layers.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "31) In which layer softmax activation function used?",
        "answer": "Softmax activation function has to be used in the output layer.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "32) What do you understand by Autoencoder?",
        "answer": "Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output; typically,internet representation consists of smaller dimensions than the input vector. As a result, they can learn efficient ways of representing the data. Autoencoder consists of two parts; an encoder tries to fit the inputs to the internal representation, and a decoder converts the internal state to the outputs.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "33) What do you mean by Dropout?",
        "answer": "Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "34) What do you understand by Tensors?",
        "answer": "Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "35) What do you understand by Boltzmann Machine?",
        "answer": "A Boltzmann machine (also known as stochastic Hopfield network with hidden units) is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.\nSome important points about Boltzmann Machine-\nIt uses a recurrent structure.\nIt consists of stochastic neurons, which include one of the two possible states, either 1 or 0.\nThe neurons present in this are either in an adaptive state (free state) or clamped state (frozen state).\nIf we apply simulated annealing or discrete Hopfield network, then it would become a Boltzmann Machine.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "36) What is Model Capacity?",
        "answer": "The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "37) What is the cost function?",
        "answer": "A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "38) Explain gradient descent?",
        "answer": "An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function via the following formula:\n\nWhere,\nΘ - is the parameter vector,\nα - learning rate,\nJ(Θ) - is a cost function\nIn machine learning, it is used to update the parameters of our model. Parameters represent the coefficients in linear regression and weights in neural networks.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "39) Explain the following variant of Gradient Descent: Stochastic, Batch, and Mini-batch?",
        "answer": "Stochastic Gradient Descent\nStochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.\nBatch Gradient Descent\nBatch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.\nMini-batch Gradient Descent\nMini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "40) What are the main benefits of Mini-batch Gradient Descent?",
        "answer": "It is computationally efficient compared to stochastic gradient descent.\nIt improves generalization by finding flat minima.\nIt improves convergence by using mini-batches. We can approximate the gradient of the entire training set, which might help to avoid local minima.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "42) What do you understand by a convolutional neural network?",
        "answer": "A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "There are four layered concepts that we should understand in CNN (Convolutional Neural Network):\nConvolution\nThis layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.\nReLU\nThe ReLu layer is used with the convolutional layer.\nPooling\nIt reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.\nFull Collectedness\nNeurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "44) What is an RNN?",
        "answer": "RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data. RNN use backpropagation algorithm for training because of their internal memory. RNN can remember important things about the input they received, which enables them to be very precise in predicting what's coming next.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "45) What are the issues faced while training in Recurrent Networks?",
        "answer": "Recurrent Neural Network uses backpropagation algorithm for training, but it is applied on every timestamp. It is usually known as Back-propagation Through Time (BTT).\nThere are two significant issues with Back-propagation, such as:\nVanishing Gradient\nWhen we perform Back-propagation, the gradients tend to get smaller and smaller because we keep on moving backward in the Network. As a result, the neurons in the earlier layer learn very slowly if we compare it with the neurons in the later layers.Earlier layers are more valuable because they are responsible for learning and detecting simple patterns. They are the building blocks of the network.\nIf they provide improper or inaccurate results, then how can we expect the next layers and complete network to perform nicely and provide accurate results. The training procedure tales long, and the prediction accuracy of the model decreases.\nExploding Gradient\nExploding gradients are the main problem when large error gradients accumulate. They provide result in very large updates to neural network model weights during training.\nGradient Descent process works best when updates are small and controlled. When the magnitudes of the gradient accumulate, an unstable network is likely to occur. It can cause poor prediction of results or even a model that reports nothing useful.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "LSTM stands for Long short-term memory. It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a \"general purpose computer.\" It can process not only a single data point but also entire sequences of data.\nThey are a special kind of RNN which are capable of learning long-term dependencies.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "",
        "answer": "An autoencoder contains three layers:\nEncoder\nThe encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.\nCode\nThe code layer is used to represent the compressed input which is fed to the decoder.\nDecoder\nThe decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "48) What do you understand by Deep Autoencoders?",
        "answer": "Deep Autoencoder is the extension of the simple Autoencoder. The first layer present in DeepAutoencoder is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions. Deeper layers which are available in the Deep Autoencoder tend to learn even high-order features.\nA deep autoencoder is the combination of two, symmetrical deep-belief networks:\nFirst four or five shallow layers represent the encoding half.\nThe other combination of four or five layers makes up the decoding half.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    },
    {
        "question": "49) What are the three steps to developing the necessary assumption structure in Deep learning?",
        "answer": "The procedure of developing an assumption structure involves three specific actions.\nThe first step contains algorithm development. This particular process is lengthy.\nThe second step contains algorithm analyzing, which represents the in-process methodology.\nThe third step is about implementing the general algorithm in the final procedure. The entire framework is interlinked and required for throughout the process.",
        "reference": "javatpoint.com",
        "role": "deep-learning"
    }
]