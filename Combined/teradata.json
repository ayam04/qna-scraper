[
    {
        "question": "1. Explain channel driver.",
        "answer": "As the name implies, a channel driver acts as a means of communication between PEs and the applications that run on channels connected to clients. The Teradata Gateway acts in much the same way as a channel driver, acting as a conduit between the Parse Engine and applications connected to network clients.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "2. What is the importance of using Teradata?",
        "answer": "The following are reasons why Teradata is important: The system has the capability of handling (storing and processing) large volumes of data, more than 50 petabytes.  \nYou can integrate it with various business intelligence (BI) tools.  \nThis software supports OLAP (online analytical processing), enabling users to perform complex analytics on data.  \nTeradata offers a comprehensive set of services (full) concerning data warehousing like cloud-based and hardware-based data warehousing, business analytics, etc.  \nSQL (Structured Query Language) is supported by Teradata as a means of interacting with data stored in tables. The application consists of diverse queries that offer flexibility to users. \nUsing the Teradata platform, companies can consolidate their core business objectives by organizing their analytical capabilities. \nTeradata is based on Massive Parallel Processing (MPP), which makes it possible to run multiple tasks simultaneously and efficiently, resulting in fast processing speeds. The system has the capability of handling (storing and processing) large volumes of data, more than 50 petabytes. You can integrate it with various business intelligence (BI) tools. This software supports OLAP (online analytical processing), enabling users to perform complex analytics on data. Teradata offers a comprehensive set of services (full) concerning data warehousing like cloud-based and hardware-based data warehousing, business analytics, etc. SQL (Structured Query Language) is supported by Teradata as a means of interacting with data stored in tables. The application consists of diverse queries that offer flexibility to users. Using the Teradata platform, companies can consolidate their core business objectives by organizing their analytical capabilities. Teradata is based on Massive Parallel Processing (MPP), which makes it possible to run multiple tasks simultaneously and efficiently, resulting in fast processing speeds.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "3. What do you mean by caching in Teradata?",
        "answer": "In simplest terms, caching is a benefit of using Teradata that involves storing frequently used data and information in cache memory so that, when the next time the data is needed, it can be retrieved directly from memory instead of requiring the application to generate it again. In Teradata, caching remains in the same order, which means that it does not change very often. In fact, caches are typically shared among several applications.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "4. What are the benefits of using ETL tools over Teradata?",
        "answer": "Extract, Transform, Load (ETL) means three distinct tasks for managing databases.  ETL tools offer some advantages over Teradata, including: Support for multiple heterogeneous destinations and sources of data.  \nThe ETL tools provide a full-featured GUI that simplifies the debugging process for managing databases. \nETL tools offer the advantage of being able to reuse components. Thus, if the main server is updated, all corresponding applications connected to the server are automatically updated.  \nETL tools can be used to pivot (transform rows into columns) and de-pivot (transform columns into rows). Support for multiple heterogeneous destinations and sources of data. The ETL tools provide a full-featured GUI that simplifies the debugging process for managing databases. ETL tools offer the advantage of being able to reuse components. Thus, if the main server is updated, all corresponding applications connected to the server are automatically updated. ETL tools can be used to pivot (transform rows into columns) and de-pivot (transform columns into rows).",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "5. Is Teradata an ETL tool or a database?",
        "answer": "Teradata is not an ETL (Extract, Transform and Load) tool. Teradata is an open-source RDBMS (relational database management system) that runs on different operating systems, including Windows, Unix, and Linux. Teradata is a relational database management system capable of handling data loads in terabytes. The system is capable of handling large-scale data warehouse applications.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "6. Mention a few ETL (Extract, Transform and Load) Tools that come under Teradata.",
        "answer": "There are several ETL (Extract, Transform, and Load) tools that are commonly used in Teradata as follows: DataStage \nInformatica\nSSIS (SQL Server Integration Services) DataStage Informatica SSIS (SQL Server Integration Services)",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "7. Explain nodes in Teradata.",
        "answer": "The Teradata System consists of nodes, which are the basic units. Nodes are individual servers in a Teradata system. Each node comprises a separate operating system, CPU, memory, Teradata RDBMS software, and disk space.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "8. What do you mean by Spool space in Teradata? Write its usage.",
        "answer": "Spool space refers to the unused space in the system in which intermediate results from a SQL query are stored. Query execution is not possible for users without spool space. Amount of spool space is divided based on the number of AMPs, but each AMP has only a fraction of the space available. In the event that the per AMP limit is exceeded, the user will receive a warning that they have run out of spool space. Example: Let's say the user was assigned a spool space of 200000000 bytes. This is the maximum space the user is allowed to use and it is distributed evenly across all AMPs as shown below. Example:  ",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "9. What is Skewness in Teradata?",
        "answer": "As a statistical concept, \"skewness\" refers to the row distribution on AMPs (Access Module Processors). In data distribution, the Skew Factor refers to the distribution of table data among AMPs. Skewed factor of 0 indicate that the data is evenly distributed among the AMP's. In the case of highly skewed data, it means that some AMPs have more rows and some have very few, i.e., the distribution is not even. The Skew Factor is high in this case (unequal distribution of data), affecting performance and Teradata's parallelism.   Choosing the right index can control the skewness of the data distribution. Ideally, you should choose a Primary Index that contains as many unique values as possible so as to avoid skewness.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "10. What is performance tuning and why is it important?",
        "answer": "Specifically, Teradata Performance tuning involves identifying all bottlenecks in the database and resolving them. The bottleneck does not cause errors, but it certainly causes delays in data retrieval from the database. A company without performance tuning for its database could suffer from imperfect responses to queries, causing unnecessary difficulties in accessing its data and other issues. The reasons for consistent performance tuning are as follows:   Increasing the speed of data retrieval: A database that isn't optimized can cause retrieval of data to be slower if you have a lot of data. Performance tuning allows you to build indexes and fix problems that could delay the retrieval of your data.\nAvoiding coding loops: Coding loops (repeating a certain block of code repeatedly until a certain condition is met) can increase the load on your database. SQL queries are executed multiple times if present in a loop, however if you move them out of the loop, performance can be improved since they are executed once instead of many times.\nOptimize SQL query performance: In order to enhance query performance, it is best to avoid correlated subqueries, to avoid overusing select (and instead declare each column individually), and to avoid temporary tables if possible. The purpose of performance tuning is generally to reduce the response time for the end user or the latency. Increasing the speed of data retrieval: A database that isn't optimized can cause retrieval of data to be slower if you have a lot of data. Performance tuning allows you to build indexes and fix problems that could delay the retrieval of your data. Increasing the speed of data retrieval Avoiding coding loops: Coding loops (repeating a certain block of code repeatedly until a certain condition is met) can increase the load on your database. SQL queries are executed multiple times if present in a loop, however if you move them out of the loop, performance can be improved since they are executed once instead of many times. Avoiding coding loops: Optimize SQL query performance: In order to enhance query performance, it is best to avoid correlated subqueries, to avoid overusing select (and instead declare each column individually), and to avoid temporary tables if possible. The purpose of performance tuning is generally to reduce the response time for the end user or the latency. Optimize SQL query performance:",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "11. What is the process of restarting MLOAD Teradata Server after execution?",
        "answer": "In general, the process begins from the last known checkpoint, and after the MLOAD script is executed, the server is restarted.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "12. What is the process of restarting MLOAD Client System after its failure?",
        "answer": "Teradata MultiLoad jobs that failed or were aborted because of client system failure can be restarted depending on whether they stopped during the application phase (apply all DML (Data Manipulation Language) operations). When the Teradata MultiLoad job was stopped prior to or after the application phase, you should restart the job as it is, without making any changes to the script. Terradata MultiLoad uses the entries from the restart log table to determine its stopping point and begins processing at that point. '\nWhen a Teradata MultiLoad job is aborted or the client system fails during the application stage, resolve the issue associated with failure and then restart the job again. When the Teradata MultiLoad job was stopped prior to or after the application phase, you should restart the job as it is, without making any changes to the script. Terradata MultiLoad uses the entries from the restart log table to determine its stopping point and begins processing at that point. ' When a Teradata MultiLoad job is aborted or the client system fails during the application stage, resolve the issue associated with failure and then restart the job again.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "13. Why Multi-load doesn't support USI (Unique Secondary Index) instead of NUSI (Non-Unique Secondary Index)?",
        "answer": "Teradata allows all AMP (Access Module Processors) to operate independently. With USI, the index subtable would have to be present on multiple AMPs, which would require communication between AMPs. But with NUSI, the index subtable would be present on the same AMP as the data row, which would allow that AMP to be handled independently. This is why NUSI is supported by multi-load.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "14. Explain different string manipulation operators and functions associated with Teradata.",
        "answer": "The Teradata String functions are used to manipulate strings and are also compatible with the ANSI standard. Additionally, it supports some standard string functions as well as the Teradata extensions to those functions. SUBSTRING: It extracts a selective portion of the long string (ANSI standard). SUBSTRING: It extracts a selective portion of the long string (ANSI standard). SUBSTRING: Example:  Consider a string “InterviewBit” from a table. Example: SELECT SUBSTRING('Interviewbit' FROM 1 FOR 5); SELECT SUBSTRING('Interviewbit' FROM 1 FOR 5); Output: Inter Inter POSITION: An individual character in a string (ANSI standard) can be located. POSITION: An individual character in a string (ANSI standard) can be located. POSITION: Example: Example: SELECT POSITION(\"r\" IN \"InterviewBit\"); SELECT POSITION(\"r\" IN \"InterviewBit\"); Output: 5 5 TRIM: Removes (trims) blank space from a specified string. TRIM: Removes (trims) blank space from a specified string. TRIM: Example: Example: SELECT TRIM(\"  InterviewBit  \"); SELECT TRIM(\"  InterviewBit  \"); Output: InterviewBit InterviewBit UPPER: The string is converted to uppercase. UPPER: The string is converted to uppercase. UPPER: Example: Example: SELECT UPPER(\"InterviewBit\"); SELECT UPPER(\"InterviewBit\"); Output: INTERVIEWBIT INTERVIEWBIT LOWER: The string is converted to lowercase. LOWER: The string is converted to lowercase. LOWER: Example: Example: SELECT LOWER(\"INTERVIEWBIT\"); SELECT LOWER(\"INTERVIEWBIT\"); Output: interviewbit interviewbit",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "15. What do you mean by Teradata utilities and write different types of Teradata utilities?",
        "answer": "Data can be loaded into Teradata databases as well as exported from Teradata databases to client applications using Teradata utilities. There are many Teradata utilities available, including: Basic Teradata Query (BTEQ): Teradata provides the BTEQ utility, which can be used in batch (executing a collection of statements as a script) or interactive mode (executing statements one by one). You can also use it to execute any DDL (Data Definition Language) or DML statement, macro, or stored procedure. With BTEQ, you can import data into Teradata tables as well as export data to files and reports.\nFastload: The FastLoad utility loads data into tables quickly. There will be no duplicate rows even if the target table is a Multiset table (stores duplicate records).\nMultiload: MultiLoad is able to load data into multiple tables simultaneously and can perform different types of tasks such as INSERT, UPDATE, DELETE, and UPSERT. It is best suitable for operations such as bulk update, delete,  upsert and as well as complex interface manipulations.\nFastexport: This utility exports Teradata data into flat files. Alternatively, the utility can export the data as reports. Using joins, the utility can extract data from several tables at one time\nTeradata Parallel Data Pump(TPump): It helps maintain Teradata Databases by updating, deleting, inserting, and upserting data in databases. Multiple changes can be made at the same time.\nTeradata Parallel Transport (TPT): This is an all-in-one tool to load and export data into/from Teradata databases. Among existing utilities like fastload, fastexport, multiload, and TPUMP, Teradata recommends TPT. Basic Teradata Query (BTEQ): Teradata provides the BTEQ utility, which can be used in batch (executing a collection of statements as a script) or interactive mode (executing statements one by one). You can also use it to execute any DDL (Data Definition Language) or DML statement, macro, or stored procedure. With BTEQ, you can import data into Teradata tables as well as export data to files and reports. Basic Teradata Query (BTEQ): Fastload: The FastLoad utility loads data into tables quickly. There will be no duplicate rows even if the target table is a Multiset table (stores duplicate records). Fastload: Multiload: MultiLoad is able to load data into multiple tables simultaneously and can perform different types of tasks such as INSERT, UPDATE, DELETE, and UPSERT. It is best suitable for operations such as bulk update, delete,  upsert and as well as complex interface manipulations. Multiload: Fastexport: This utility exports Teradata data into flat files. Alternatively, the utility can export the data as reports. Using joins, the utility can extract data from several tables at one time Fastexport: Teradata Parallel Data Pump(TPump): It helps maintain Teradata Databases by updating, deleting, inserting, and upserting data in databases. Multiple changes can be made at the same time. Teradata Parallel Data Pump(TPump): Teradata Parallel Transport (TPT): This is an all-in-one tool to load and export data into/from Teradata databases. Among existing utilities like fastload, fastexport, multiload, and TPUMP, Teradata recommends TPT. Teradata Parallel Transport (TPT):",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "16. Explain Teradata Architecture.",
        "answer": "The following diagram illustrates Teradata's architecture:   Teradata's architecture is based on MPP (massively parallel processing). In general, it can be divided into two parts i.e., storage architectures and retrieval architectures. In total, the architecture consists of four components, namely, a parsing engine, BYNET, AMPs, and disks. The first two components make up the storage architecture, and the last two are retrieval architecture components. Parsing Engine (PE): The Parsing Engine receives client queries and prepares an efficient execution plan to execute/run SQL queries. As soon as a user executes a SQL query, it is first connected to the PE (Parsing Engine). The PE performs the following functions: \nVerifies whether the queries have syntax errors. \nDetermines whether or not the objects utilized by the SQL query exist. \nPrepares execution plans for these queries and then sends them to BYNET. \nGet the results of the SQL query from the AMPs and send it to the client.\nAccess Module Processors (AMPs): It is a virtual processor that is connected to PE via BYNET. Each AMP contains its own disk allowing it to read and write data from disks.  As such, it is referred to as shared nothing architecture. After receiving the data and execution plan from Parsing Engine, AMPs perform any data type conversion, aggregation, filtering, and sorting, and further write (store) data to the corresponding disks. When the query is fired, all AMPs work together to give back the data. \nBYNETs: BYNET functions as a communication channel between PEs and AMPs. This component receives the execution plan from the parsing engine and passes it on to the AMPs. Teradata has two BYNETs, named BYNET 0 and BYNET 1, but we refer to them as a single system. Reason for having 2 BYNETs:   \nThe second BYNET can take over if the first BYNET fails.   \nBoth BYNETs can be made functional when data volume is large, which will enhance communication between PEs and AMPs, and therefore speed up the process. \nDisks: These are Virtual Disks offered by Teradata for each AMP. Vdisk, or Virtual Disk, is the storage area of each AMP. Parsing Engine (PE): The Parsing Engine receives client queries and prepares an efficient execution plan to execute/run SQL queries. As soon as a user executes a SQL query, it is first connected to the PE (Parsing Engine). The PE performs the following functions: \nVerifies whether the queries have syntax errors. \nDetermines whether or not the objects utilized by the SQL query exist. \nPrepares execution plans for these queries and then sends them to BYNET. \nGet the results of the SQL query from the AMPs and send it to the client. Parsing Engine (PE): Verifies whether the queries have syntax errors. \nDetermines whether or not the objects utilized by the SQL query exist. \nPrepares execution plans for these queries and then sends them to BYNET. \nGet the results of the SQL query from the AMPs and send it to the client. Verifies whether the queries have syntax errors. Determines whether or not the objects utilized by the SQL query exist. Prepares execution plans for these queries and then sends them to BYNET. Get the results of the SQL query from the AMPs and send it to the client. Access Module Processors (AMPs): It is a virtual processor that is connected to PE via BYNET. Each AMP contains its own disk allowing it to read and write data from disks.  As such, it is referred to as shared nothing architecture. After receiving the data and execution plan from Parsing Engine, AMPs perform any data type conversion, aggregation, filtering, and sorting, and further write (store) data to the corresponding disks. When the query is fired, all AMPs work together to give back the data. Access Module Processors (AMPs): BYNETs: BYNET functions as a communication channel between PEs and AMPs. This component receives the execution plan from the parsing engine and passes it on to the AMPs. Teradata has two BYNETs, named BYNET 0 and BYNET 1, but we refer to them as a single system. Reason for having 2 BYNETs:   \nThe second BYNET can take over if the first BYNET fails.   \nBoth BYNETs can be made functional when data volume is large, which will enhance communication between PEs and AMPs, and therefore speed up the process. BYNETs The second BYNET can take over if the first BYNET fails.   \nBoth BYNETs can be made functional when data volume is large, which will enhance communication between PEs and AMPs, and therefore speed up the process. The second BYNET can take over if the first BYNET fails. Both BYNETs can be made functional when data volume is large, which will enhance communication between PEs and AMPs, and therefore speed up the process. Disks: These are Virtual Disks offered by Teradata for each AMP. Vdisk, or Virtual Disk, is the storage area of each AMP. Disks:",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "17. What are the newly developed features of Teradata?",
        "answer": "Teradata offers the following features:   Unlimited Parallelism: Teradata is based on Massive Parallel Processing (MPP), which allows it to divide large tasks (related to data processing) into smaller tasks and run them in parallel.   \nShared Nothing Architecture: As this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others, resulting in an optimized performance for the given task. \nLinear Scalability: Teradata Systems are linearly scalable and can handle large volumes of data in the most efficient manner.   \nConnectivity: Teradata is best in terms of connectivity as it can connect with channel-attached systems, such as mainframes or networks. \nMature Optimizer: Teradata offers a mature optimizer (which provides the most efficient method for retrieving the data required by a SQL query) that can handle up to 64 joins (combining data from different tables in a database) per SQL query.  \nSQL (Structured Query Language): This standard language is supported by Teradata as a means of interacting with data stored in tables. It also offers its own extensions.  \nRobust Utilities: As part of Teradata's robust utility suite, Teradata provides utilities for importing and exporting data from/to Teradata systems such as Fastload, Fastexport, Multiload, and TPT (Teradata Parallel Transporter), and many more.    \nLoad & Unload utilities: Teradata features load & unload utilities, which allow users to move data into and out of the Teradata system. \nAutomatic Distribution: Teradata automatically distributes data evenly among the disks, requiring no manual intervention.  \nLow TCO (Total cost of ownership): Due to its ease of setup, administration, and maintenance, it has a low TCO. Unlimited Parallelism: Teradata is based on Massive Parallel Processing (MPP), which allows it to divide large tasks (related to data processing) into smaller tasks and run them in parallel. Unlimited Parallelism: Shared Nothing Architecture: As this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others, resulting in an optimized performance for the given task. Shared Nothing Architecture: Linear Scalability: Teradata Systems are linearly scalable and can handle large volumes of data in the most efficient manner. Linear Scalability: Connectivity: Teradata is best in terms of connectivity as it can connect with channel-attached systems, such as mainframes or networks. Connectivity: Mature Optimizer: Teradata offers a mature optimizer (which provides the most efficient method for retrieving the data required by a SQL query) that can handle up to 64 joins (combining data from different tables in a database) per SQL query. Mature Optimizer: SQL (Structured Query Language): This standard language is supported by Teradata as a means of interacting with data stored in tables. It also offers its own extensions. SQL (Structured Query Language): Robust Utilities: As part of Teradata's robust utility suite, Teradata provides utilities for importing and exporting data from/to Teradata systems such as Fastload, Fastexport, Multiload, and TPT (Teradata Parallel Transporter), and many more. Robust Utilities: Load & Unload utilities: Teradata features load & unload utilities, which allow users to move data into and out of the Teradata system. Load & Unload utilities: Automatic Distribution: Teradata automatically distributes data evenly among the disks, requiring no manual intervention. Automatic Distribution: Low TCO (Total cost of ownership): Due to its ease of setup, administration, and maintenance, it has a low TCO. Low TCO (Total cost of ownership):",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "1. What's the purpose of this below query?",
        "answer": "SELECT HASHMAP (HASHBUCKET(HASHROW(emp_id))), COUNT(*) FROM Employee GROUP BY 1; SELECT HASHMAP (HASHBUCKET(HASHROW(emp_id))), COUNT(*) FROM Employee GROUP BY 1; With the above query, you can determine the number of rows in each AMP for a given database table. HASHAMP, HASHBUCKET, and HASHROW indicate the number of rows in the AMPs when used together. Conclusion Among the most popular database management systems are Teradata. Employers are seeking candidates with extensive knowledge of its architecture and ability to use it efficiently. It is important to prepare for Teradata Interview Questions if you are seeking employment related to Teradata. database management systems database management systems It is true that every interview is different depending on the position. In this article, we have provided the important Teradata Interview Questions and Answers for freshers and experienced, which will help you excel in your interview. There are questions on architectural basics, utilities related to Fastload, Multiload, BTEQ, SQL, and Stored Procedures. Ready to ace your Teradata interview now?",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "2. What is the importance of UPSERT command in Teradata?",
        "answer": "Teradata enables update and insert operations to be performed simultaneously on a table from another table using UPSERT Command. Updates are made if the update condition matches in another table and unmatched rows are inserted into the table if the update condition does not match. UPDATE-ELSE-INSERT syntax: UPDATE-ELSE-INSERT syntax: UPDATE department SET budget_amount = 60000 WHERE department_number = 600 ELSE INSERT INTO department(department_number, department_name, budget_amount, manager_employee_number) VALUES(600, 'Test Dept', 60000, NULL); UPDATE department SET budget_amount = 60000 WHERE department_number = 600 ELSE INSERT INTO department(department_number, department_name, budget_amount, manager_employee_number) VALUES(600, 'Test Dept', 60000, NULL); This statement updates the row where department_number matches 600 to set budget_amount to 60000. In the event that no match is found, a new row will be inserted.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "3. In Teradata, what is the purpose of using CASE Expression?",
        "answer": "When a CASE expression is used, each row is compared with a condition or WHEN clause, and the result of the first match is returned. Else, the result from the ELSE clause will be returned if there are no matches. Syntax: Syntax: CASE <expression>  \nWHEN <expression> THEN result-1  \nWHEN <expression> THEN result-2  \nELSE  \n  Result-n  \nEND CASE <expression>  \nWHEN <expression> THEN result-1  \nWHEN <expression> THEN result-2  \nELSE  \n  Result-n  \nEND",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "4. Explain the set operators in Teradata.",
        "answer": "Operators such as SET combine the results from multiple SELECT statements. It may seem similar to Joins, but Joins combine columns from different tables, whereas SET operators combine rows from different tables. The following set operators are supported by Teradata SQL: UNION: It combines results from several SELECT statements. Duplicate values are ignored.\nUNION ALL: It combines results from several SELECT statements, including duplicate rows.\nINTERSECT: It combines results from several SELECT statements. The function can be used to return those rows in the first SELECT statement that match those in the second SELECT statement. Basically, it returns the rows which exist in both SELECT statements.\nMINUS/EXCEPT: It combines results from several SELECT statements. The function can be used to return those rows in the first SELECT statement that are not matched with those in the second SELECT statement. UNION: It combines results from several SELECT statements. Duplicate values are ignored. UNION: UNION ALL: It combines results from several SELECT statements, including duplicate rows. UNION ALL: INTERSECT: It combines results from several SELECT statements. The function can be used to return those rows in the first SELECT statement that match those in the second SELECT statement. Basically, it returns the rows which exist in both SELECT statements. INTERSECT: MINUS/EXCEPT: It combines results from several SELECT statements. The function can be used to return those rows in the first SELECT statement that are not matched with those in the second SELECT statement. MINUS/EXCEPT: Example: Assume the student table below is Table1 and the attendance table is Table2. Example: Roll_No First_Name Last_Name DateofBirth\n101 Asha Bisht 18/1/1996\n102 Rahul Patidar 1/1/1997\n103 Vishal Bairagi 25/9/1997\n104 Girja Shankar 14/6/1994\n105 Sonal Dange 20/8/1997 Roll_No First_Name Last_Name DateofBirth\n101 Asha Bisht 18/1/1996\n102 Rahul Patidar 1/1/1997\n103 Vishal Bairagi 25/9/1997\n104 Girja Shankar 14/6/1994\n105 Sonal Dange 20/8/1997 Roll_No First_Name Last_Name DateofBirth Roll_No First_Name Last_Name DateofBirth Roll_No First_Name Last_Name DateofBirth 101 Asha Bisht 18/1/1996\n102 Rahul Patidar 1/1/1997\n103 Vishal Bairagi 25/9/1997\n104 Girja Shankar 14/6/1994\n105 Sonal Dange 20/8/1997 101 Asha Bisht 18/1/1996 101 Asha Bisht 18/1/1996 102 Rahul Patidar 1/1/1997 102 Rahul Patidar 1/1/1997 103 Vishal Bairagi 25/9/1997 103 Vishal Bairagi 25/9/1997 104 Girja Shankar 14/6/1994 104 Girja Shankar 14/6/1994 105 Sonal Dange 20/8/1997 105 Sonal Dange 20/8/1997                             1. UNION 1. UNION Following is a UNION query that combines the Roll_No values from both Table1 and Table2. SELECT Roll_No FROM Table1  \nUNION  \nSELECT Roll_No FROM Table2; SELECT Roll_No FROM Table1  \nUNION  \nSELECT Roll_No FROM Table2; Output: Following is the output of the above query when executed. It does not includes duplicate values. Output: Roll_No\n101\n102\n103\n104\n105 Roll_No\n101\n102\n103\n104\n105 Roll_No Roll_No Roll_No 101\n102\n103\n104\n105 101 101 102 102 103 103 104 104 105 105 2. UNION ALL 2. UNION ALL Here is an example of a UNION ALL statement. SELECT Roll_No FROM Table1  \nUNION ALL   \nSELECT Roll_No FROM Table2; SELECT Roll_No FROM Table1  \nUNION ALL   \nSELECT Roll_No FROM Table2; Output: Following is the output of the above query when executed. It includes duplicate values as well. Roll_No\n101\n102\n103\n104\n105\n101\n102\n103\n104 Roll_No\n101\n102\n103\n104\n105\n101\n102\n103\n104 Roll_No Roll_No Roll_No 101\n102\n103\n104\n105\n101\n102\n103\n104 101 101 102 102 103 103 104 104 105 105 101 101 102 102 103 103 104 104 3. INTERSECT 3. INTERSECT Here is an example of an INTERSECT statement. This command returns the Roll_No value that exists or present in both tables i.e., Table1 and Table2. SELECT Roll_No FROM Table1  \nINTERSECT   \nSELECT Roll_No FROM Table2; SELECT Roll_No FROM Table1  \nINTERSECT   \nSELECT Roll_No FROM Table2; Output: Following is the output of the above query when executed. The Roll_No105 is excluded because there is no such record in Table2. Output: Roll_No\n101\n102\n103\n104 Roll_No\n101\n102\n103\n104 Roll_No Roll_No Roll_No 101\n102\n103\n104 101 101 102 102 103 103 104 104 4. MINUS/EXCEPT 4. MINUS/EXCEPT Here is an example of a MINUS/EXCEPT statement. SELECT Roll_No FROM Table1  \nMINUS\nSELECT Roll_No FROM Table2; SELECT Roll_No FROM Table1  \nMINUS\nSELECT Roll_No FROM Table2; Output: Following is the output of the above query when executed. Only Roll_No105 is included because it is present in Table1 but there is no such record in Table2. Output: Roll_No\n105 Roll_No\n105 Roll_No Roll_No Roll_No 105 105 105",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "5. How to find duplicate records in a table?",
        "answer": "The DISTINCT statement or GROUP BY statement can be used to identify duplicate records in a table. SELECT DISTINCT column 1, column 2... FROM tablename; SELECT DISTINCT column 1, column 2... FROM tablename; OR SELECT column 1, column 2,... FROM tablename GROUP BY column 1, column 2....; SELECT column 1, column 2,... FROM tablename GROUP BY column 1, column 2....; Example: Consider the following student table. Roll_No First_Name Last_Name\n101 Asha Bisht\n102 Rahul Patidar\n103 Vishal Bairagi\n104 Girja Shankar\n105 Asha Dange Roll_No First_Name Last_Name\n101 Asha Bisht\n102 Rahul Patidar\n103 Vishal Bairagi\n104 Girja Shankar\n105 Asha Dange Roll_No First_Name Last_Name Roll_No First_Name Last_Name Roll_No First_Name Last_Name 101 Asha Bisht\n102 Rahul Patidar\n103 Vishal Bairagi\n104 Girja Shankar\n105 Asha Dange 101 Asha Bisht 101 Asha Bisht 102 Rahul Patidar 102 Rahul Patidar 103 Vishal Bairagi 103 Vishal Bairagi 104 Girja Shankar 104 Girja Shankar 105 Asha Dange 105 Asha Dange DISTINCT DISTINCT Here is an example of a DISTINCT statement. SELECT DISTINCT First_Name FROM tablename; SELECT DISTINCT First_Name FROM tablename; Output: Following is the output of the above query when executed. With a distinct statement, duplicate values can be eliminated. Output: First_Name\nAsha\nRahul\nVishal\nGirja First_Name\nAsha\nRahul\nVishal\nGirja First_Name First_Name First_Name Asha\nRahul\nVishal\nGirja Asha Asha Rahul Rahul Vishal Vishal Girja Girja",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "6. Explain fallback in Teradata.",
        "answer": "As the name implies, the fallback feature stores the second copy of rows from a table on a different AMP, which is called the Fallback AMP. In the event that one of the AMPs fails, the fallback rows are accessed. As a result, even if one of the AMPs fails, data can still be accessed since a fallback AMP is available. In the below diagram, you can see how a duplicate (fallback) copy of each row is stored in another AMPs. In AMP 0, a duplicate copy of the primary row of AMP1 (3) and AMP2 (6) is stored in fallback rows. Similarly, in AMP 1, a duplicate copy of the primary row of AMP0 (1) and AMP2 (5) is stored in the fallback row. All the AMPs stored fallback values in the same way.  ",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "7. List out the different forms of locks available in Teradata.",
        "answer": "Every object in the database is shared between multiple users who access the data simultaneously. If, for example, a user was updating a table and another user tried to view it simultaneously, the second user would receive inaccurate and inconsistent information. Locking mechanisms have been invented to avoid this kind of data inconsistency or data corruption. Having a lock prevents multiple users from changing the same data at the same time, reducing the possibility of data corruption/data inconsistency. In general, Teradata comprises four types of locks as follows: Exclusive: Teradata applies an exclusive lock whenever anyone attempts to modify the structure of any objects ( like a table or view). In other words, Teradata holds the lock on that object and no other user is permitted to access or manipulate that object until the lock is released from the object. \nWrite: Table that is secured with a write lock can only be modified by the lock owner. If other users try to insert, delete, or update a table, a write lock will be applied. With a write lock, other users cannot modify the same table.  \nRead: When a user submits a SELECT query, a read lock is applied.  Multiple users can hold READ locks on an object, during which the system does not permit changes to that object. Hence, data integrity is thus maintained since the data in the tables cannot be altered when read locks are applied.  \nAccess: It only prevents exclusive access. ACCESS locks do not restrict access to another user except for when an EXCLUSIVE lock is required to prevent others from accessing. Exclusive: Teradata applies an exclusive lock whenever anyone attempts to modify the structure of any objects ( like a table or view). In other words, Teradata holds the lock on that object and no other user is permitted to access or manipulate that object until the lock is released from the object. Exclusive: Write: Table that is secured with a write lock can only be modified by the lock owner. If other users try to insert, delete, or update a table, a write lock will be applied. With a write lock, other users cannot modify the same table. Write: Read: When a user submits a SELECT query, a read lock is applied.  Multiple users can hold READ locks on an object, during which the system does not permit changes to that object. Hence, data integrity is thus maintained since the data in the tables cannot be altered when read locks are applied. Read: Access: It only prevents exclusive access. ACCESS locks do not restrict access to another user except for when an EXCLUSIVE lock is required to prevent others from accessing. Access:",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "8. What is PPI (Partitioned Primary Index)?",
        "answer": "As its name suggests, Partitioned Primary Indexes (PPI) are one of Teradata's powerful features that allow users to access a specific portion of a table instead of the whole table. Essentially, PPI is an indexing mechanism that will help improve query performance. When used for data distribution, PPI works the same way as Primary Index, and partitions are created based on range or case as specified in the table. In partitioned primary indexes (PPIs), rows are sorted according to the partition number. By using PPI, you can avoid a full table scan and only access required partitions. \nUsing PPI prevents the use of secondary indexes, as well as additional I/O maintenance. \nIt enables quick access to a subset of a large table. \nPPI enables removing old data and adding new data to a table with ease. By using PPI, you can avoid a full table scan and only access required partitions. Using PPI prevents the use of secondary indexes, as well as additional I/O maintenance. It enables quick access to a subset of a large table. PPI enables removing old data and adding new data to a table with ease.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "9. What is PDE (Parallel Data Extension)?",
        "answer": "Between the operating system and Teradata Database lies a software layer called Parallel Database Extensions (PDE). This enhances the speed and scalability of Teradata Database by supporting parallelism across system nodes. Through PDE, Teradata Database is capable of: Parallel processing \nPrioritize and manage Teradata Database workloads. \nManage memory, I/O (Input/Output), and messaging system interfaces consistently across multiple OS platforms, etc. Parallel processing Prioritize and manage Teradata Database workloads. Manage memory, I/O (Input/Output), and messaging system interfaces consistently across multiple OS platforms, etc.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "10. List some of the most commonly used BTEQ scripts.",
        "answer": "The following are some common BTEQ scripts: LOGON: This allows you to log in to the Teradata system.   \nACTIVITYCOUNT: It specifies how many rows were affected by the last query performed.   \nERRORCODE: This returns the status code of the last query performed.  \nDATABASE: This sets the default database.   \nLABEL: It specifies a label for a set of SQL commands.   \nRUN FILE: This command executes the query contained in a file.   \nGOTO: Turns the control over to a label.   \nLOGOFF: This terminates all sessions and logs you off from the database.   \nIMPORT: It specifies the path to the input file and initiates import to the input file.   \nEXPORT: It specifies a path to the output file and initiates export to the output file. LOGON: This allows you to log in to the Teradata system. ACTIVITYCOUNT: It specifies how many rows were affected by the last query performed. ERRORCODE: This returns the status code of the last query performed. DATABASE: This sets the default database. LABEL: It specifies a label for a set of SQL commands. RUN FILE: This command executes the query contained in a file. GOTO: Turns the control over to a label. LOGOFF: This terminates all sessions and logs you off from the database. IMPORT: It specifies the path to the input file and initiates import to the input file. EXPORT: It specifies a path to the output file and initiates export to the output file.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "11. Explain various table types supported by Teradata.",
        "answer": "The following types of tables are supported by Teradata: Permanent Table: This table contains all the data inserted by the user and stores the data permanently after it has been entered in the table. The content of permanent tables can be shared between different sessions and users. It is the default table. \nVolatile Table: When data is added to a volatile table, it is only retained during the current session, and the table is automatically dropped after the user session ends. They are generally used to store data that is intermediate during data transformation. \nGlobal Temporary Table: Other types of permanent tables include global temporary tables. This type of table stores the globally used values for the entire application, and its lifetime is dependent on the session of the user. Upon the end of the session, the table is deleted/dropped. \nDerived Table: Among all the tables, derived tables have the shortest lifetime. During query execution, intermediate results of queries are stored in these tables. Tables are created, used, and then dropped in the course of a query. Permanent Table: This table contains all the data inserted by the user and stores the data permanently after it has been entered in the table. The content of permanent tables can be shared between different sessions and users. It is the default table. Permanent Table: Volatile Table: When data is added to a volatile table, it is only retained during the current session, and the table is automatically dropped after the user session ends. They are generally used to store data that is intermediate during data transformation. Volatile Table: Global Temporary Table: Other types of permanent tables include global temporary tables. This type of table stores the globally used values for the entire application, and its lifetime is dependent on the session of the user. Upon the end of the session, the table is deleted/dropped. Global Temporary Table: Derived Table: Among all the tables, derived tables have the shortest lifetime. During query execution, intermediate results of queries are stored in these tables. Tables are created, used, and then dropped in the course of a query. Derived Table:",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "12. What's the best way to check the current version of Teradata?",
        "answer": "For determining the current version and release of software, there are several methods. You can view the current Teradata Database version and release level via any console or client session by running the following query: SELECT * FROM DBC.DBCInfoV; SELECT * FROM DBC.DBCInfoV; In Teradata, the DBC.DBCINFO table contains information relevant to the Teradata release and version. Here, DBC is a Database computer.\nDBCInfoV is the table where database information is saved. DBC is a Database computer. DBCInfoV is the table where database information is saved.  ",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "13. What steps will you take if the Fast Load Script does not run in a reliable manner?",
        "answer": "In the event the Fast Load Script does not work for you, and only the error tables are available to you, then there are two ways to restart: Getting the old file to run again: Be sure not to completely remove the error tables. Instead, fix the errors in the script or file, and then execute it again. \nRunning a new file: Alternatively, you can restart by using the ending loading and beginning statements. As a consequence, the lock that was put on the target table can be removed and the record can also be removed from the fast-log table. If that works, you can run the whole script again. Or, you might drop the table and recreate it. Getting the old file to run again: Be sure not to completely remove the error tables. Instead, fix the errors in the script or file, and then execute it again. Getting the old file to run again: Running a new file: Alternatively, you can restart by using the ending loading and beginning statements. As a consequence, the lock that was put on the target table can be removed and the record can also be removed from the fast-log table. If that works, you can run the whole script again. Or, you might drop the table and recreate it. Running a new file:",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "14. State difference between Teradata and Oracle.",
        "answer": "Among the most popular RDBMS systems are Teradata and Oracle: Teradata: Teradata is an open-source RDBMS (relational database management system) that runs on different operating systems, including Windows, Unix, and Linux. The Teradata architecture is based on Massive Parallel Processing (MPP), and is therefore widely used for large-scale data warehouse applications.   \nOracle: Oracle is a well-known Relational Database Management System (RDBMS), also referred to as Oracle database or OracleDB. OracleDB runs seamlessly on various platforms such as Windows, Unix, Mac, etc. Oracle was the first database designed exclusively for business and enterprise grid computing. As a result of Real Application Clustering and Portability features, Oracle databases are scalable to meet the demands of workloads. Enterprises choose it as a cost-effective solution to their application and data management problems. Teradata: Teradata is an open-source RDBMS (relational database management system) that runs on different operating systems, including Windows, Unix, and Linux. The Teradata architecture is based on Massive Parallel Processing (MPP), and is therefore widely used for large-scale data warehouse applications. Teradata: Oracle: Oracle is a well-known Relational Database Management System (RDBMS), also referred to as Oracle database or OracleDB. OracleDB runs seamlessly on various platforms such as Windows, Unix, Mac, etc. Oracle was the first database designed exclusively for business and enterprise grid computing. As a result of Real Application Clustering and Portability features, Oracle databases are scalable to meet the demands of workloads. Enterprises choose it as a cost-effective solution to their application and data management problems. Oracle: Teradata  Oracle \nAs this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others. Oracle architecture is based on Shared Everything architecture.  \nIn most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database.\nThe architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing).  The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing). \nIt is complex to set up, execute, and maintain.  It is complex to set up, execute, and maintain. Teradata  Oracle \nAs this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others. Oracle architecture is based on Shared Everything architecture.  \nIn most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database.\nThe architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing).  The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing). \nIt is complex to set up, execute, and maintain.  It is complex to set up, execute, and maintain. Teradata  Oracle Teradata  Oracle Teradata Oracle As this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others. Oracle architecture is based on Shared Everything architecture.  \nIn most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database.\nThe architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing).  The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing). \nIt is complex to set up, execute, and maintain.  It is complex to set up, execute, and maintain. As this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others. Oracle architecture is based on Shared Everything architecture. As this database is built on a shared-nothing architecture, the disks, Teradata nodes, and AMPs (Access Module Processors) are all independent and do not share resources with others. Oracle architecture is based on Shared Everything architecture. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. In most cases, Oracle is used as an online backend application. It handles inserts, updates, and deletions in transactions in the database. The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing).  The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing). The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing). The architecture of Oracle allows any machine to access any data. Oracle is therefore a good fit for OLTP (Online Transaction Processing). It is complex to set up, execute, and maintain.  It is complex to set up, execute, and maintain. It is complex to set up, execute, and maintain. It is complex to set up, execute, and maintain.",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "15. Mention the procedure via which we can run Teradata jobs in a UNIX environment.",
        "answer": "In order to run Teradata utilities under UNIX, you simply need to execute them in the following manner: BTEQ -    $Sh> BTEQ< [ Script path]/TEE< LOGFILE PATH > (OR) BTEQ -    $Sh> BTEQ< [ Script path > [LOG FILE PATH]\nFLOAD -    Sh> FASTLOAD< [ Script path]/TEE< LOGFILE PATH > (OR) FLOAD -    $Sh> FASTLOAD < [ Script path > [LOG FILE PATH]\nMLOAD -    $Sh> Mload < [ Script path]/TEE< LOGFILE PATH > (OR) MLOAD -    $Sh> Mload < [ Script path > [LOG FILE PATH]\nTPUMP -   $Sh> TPUMP < [ Script path]/TEE< LOGFILE PATH > (OR) TPUMP -    $Sh> TPUMP < [ Script path > [LOG FILE PATH]\nFEXP -    $Sh> FEXP < [ Script path]/TEE< LOGFILE PATH > (OR) FEXP -    $Sh> FEXP < [ Script path > [LOG FILE PATH] BTEQ -    $Sh> BTEQ< [ Script path]/TEE< LOGFILE PATH > (OR) BTEQ -    $Sh> BTEQ< [ Script path > [LOG FILE PATH] FLOAD -    Sh> FASTLOAD< [ Script path]/TEE< LOGFILE PATH > (OR) FLOAD -    $Sh> FASTLOAD < [ Script path > [LOG FILE PATH] MLOAD -    $Sh> Mload < [ Script path]/TEE< LOGFILE PATH > (OR) MLOAD -    $Sh> Mload < [ Script path > [LOG FILE PATH] TPUMP -   $Sh> TPUMP < [ Script path]/TEE< LOGFILE PATH > (OR) TPUMP -    $Sh> TPUMP < [ Script path > [LOG FILE PATH] FEXP -    $Sh> FEXP < [ Script path]/TEE< LOGFILE PATH > (OR) FEXP -    $Sh> FEXP < [ Script path > [LOG FILE PATH]",
        "reference": "interviewbit.com",
        "role": "teradata"
    },
    {
        "question": "1) What is Teradata? What are some primary characteristics of Teradata?",
        "answer": "Teradata is an RDBMS (Relational database management system) which is perfect to use with large-scale data warehousing application. It works on the parallelism concept. It is an open system. It can run on Windows/ UNIX/ Linux server platform. Teradata provides support to multiple data warehouse operations at the same time to different clients.\nIt is developed by an American IT firm called Teradata corporation. It is a dealer of analytic data platforms, applications, and other related services.\nCharacteristics of Teradata\nADVERTISEMENT\nIt is compatible with the American National Standards Institute (ANSI).\nIt acts in a way as a server does.\nIt is an open system.\nIt is single.\nIt has multi-node running capabilities.\nIt is built on parallelism.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "2) What are the different table types supported by Teradata?",
        "answer": "There are four types of tables as per data storage in Teradata:\nPermanent table\nGlobal Temporary Table (GTT)\nVolatile table\nDerived table\nPermanent Table\nThese are the Default table types in Teradata. Some of its characteristics are as follows.\nAs its name suggests these tables remains in the system until it is dropped.\nData is stored in a stable space.\nThe permanent table definition is stored in the data dictionary.\nGlobal Temporary Tables\nGlobal Temporary tables are also another kind of permanent tables. These tables are used to store the globally used values throughout the application, and the lifetime is limited to the user session. Once the user session is over, the table will be dropped.\nThe global temporary table definition is stored in the data dictionary\nData is stored in temporary space\nCollect statistics supported.\nVolatile Tables\nVolatile tables are used to store the user session data only. At the end of a particular user session, the table will drop. Volatile tables are essential to store in-between data during data transmission or in complex calculations.\nDerived Tables\nDerived tables have the smallest lifetime among all the tables. These tables hold the intermediate results during the query execution. These tables are created, used and dropped within a query.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "3) What is the difference between Teradata and Oracle?",
        "answer": "The Teradata and Oracle both are the Relational database management systems. However, Oracle supports an Object-Relational Database Management System (ORDBMS).\nLet's check out some differences between Teradata and Oracle based on the following parameters.\nArchitecture\nOracle is Shared Everything Architecture whereas Teradata is Shared Nothing (SN) Architecture.\nHere the term Shared architecture is referred to a multiprocessor database management system where memory and disk storage is shared between the processors.\nParallelism\nOracle has conditional parallelism whereas Teradata has unconditional parallelism. It gives Teradata advantage over OLAP, which results in the exceptional performance than a non-parallel system. Parallelism needs a multi-processor system.\nScalability\nScalability contains several aspects of an IT infrastructure such as data handling ( Increases in Data and transactional volume) as well as the increase in multidimensional data, number of users, query complexity, etc.\n\nTeradata is Linearly Scalable. Linearly scalable means the database capacity can be increased by adding more nodes to the infrastructure, and when the data volume increases, performance is not affected.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "4) What are the Updated features of Teradata?",
        "answer": "Some of its newly developed features are as follows.\nAutomated temporal analytics.\nJavaScript object Notation\nTeradata QueryGrid\nXML Data Type\nPerformance\nData Compression\nCustomer associated innovation like Teradata viewpoint.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "5) What is the Multi-insert?",
        "answer": "Inserting data records into the table using more than one insert statements are referred to as Multi-insert. We can achieve it by putting a semicolon in front of the keyword INSERT in the next statement rather than terminating the first statement with a semicolon.\nInsert into Cname \"select * from customer\";\nInsert into amount \"select * from customer\";",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "6) What is BTEQ utility in Teradata?",
        "answer": "BTEQ utility is the most powerful utility in Teradata. It is useful for both batch and interactive mode. It can also be used to run any DDL statement, DML statement, Create macros, and stored procedures. One another important use of BTEQ Is to import data into Teradata tables from a flat-file. It is also useful for extracting data from tables into files or reports.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "7) What are some commonly used BTEQ scripts?",
        "answer": "Some commonly used BTEQ scripts are as follows.\nLOGON: It is used to log into the Teradata system.\nACTIVITYCOUNT: It returns the number of rows affected by the most recently used query.\nERRORCODE: It returns the status code of the most recently used query.\nDATABASE: It sets the default database.\nLABEL: It assigns a label to a set of SQL commands.\nRUN FILE: It executes the query contained in a file.\nGOTO: It transfers control to a label.\nLOGOFF: It logs off from the database and terminates all sessions.\nIMPORT: it specifies the input file path.\nEXPORT: It specifies the output file path and initiates the export.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "8) What is the difference between fastload and multiload? Which one is faster?",
        "answer": "Fastload uses multiple sessions to rapidly load a large amount of data on an empty table, while Multiload is used for high-volume maintenance on tables and views. Multiload works with non-empty tables also. Multiload can use a maximum of five tables.\nIf we talk about the faster one, then Fastload is faster than multi-load.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "9) What is the difference between Teradata and basic RDBMS?",
        "answer": "Teradata Basic RDBMS\nIt has a large number of different destinations Basic RDBMS has a lack of various destinations.\nSource operation is allowed in Teradata. It is not necessary that source operation is always allowed in basic RDBMS.\nComponents can be reused for any number of times. Reusability of components is limited.\nDebugging is easy in Teradata. Debugging is complicated.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "10) Explain AMP in Teradata?",
        "answer": "AMP is an integral part of Teradata Architecture. The term AMP stands for Access module Processor. It stores the data on the disks. AMP is a part of the following activities.\nIt manages a portion of the database\nIt maintains a part of each table.\nIt accomplishes all the tasks associated with generating result set such as sort, join, and aggregation.\nIt performs space and lock management.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "11) What is SMP and MPP platforms?",
        "answer": "SMP technology is related to hardware. The hardware that supports Teradata database software is based on SMP (Symmetric multiprocessing) technology. The hardware can be combined with a communications network that connects the SMP systems to form MSP (Massively Parallel Processing) systems.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "12) Explain some differences between MPP and SMP?",
        "answer": "MPP\nMPP (Massively Parallel Processing) is a Computer system which is attached to many independent arithmetic units or entire microprocessors that run in parallel.\nDatabases can be expanded by adding additional CPUs.\nAn MPP environment does not share resources among physical computers, so the performance in MPP environment is improved.\nPerformance of an MPP system is linear, so it increases in proportion to the number of nodes.\nSMP\nIn an SMP (Symmetric Multi-Processing) processing system, the CPU shares the same memory. So the result code running in one system may affect the memory used by another.\nSMP databases usually use one CPU to perform database searches.\nThe workload for a parallel task is allocated across the processors in the system.\nSMP databases can run on several servers. However, they will share another resource.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "13) Did You Write Stored Procedures In Teradata?",
        "answer": "No, because the stored procedures become a particular AMP operation and no company will encourage that.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "14) What Is the Use of having Index on Table?",
        "answer": "Index table facilitates with the faster and efficient search of the record.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "15) How to find duplicates in a Table?",
        "answer": "To find the duplicates in a table, Group by those fields and select id, count(*) from table group by id having count (*) > 1.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "16) Why managing the data is important?",
        "answer": "Data is the ultimate source of deriving useful information. With data, many important tasks such as business management, problem formulation, decision making, and many other valuable tasks can be accomplished easily. When the data is not managed, then there are substantial chances that the user will get the errors. A well-managed data always allows users to save time, and to analyze things easily. There are a lot of other reasons as well due to which data management is important.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "17) What exactly do you know about Catching in Teradata?",
        "answer": "It is an add-on feature in Teradata which let the users to share the cache easily with all the applications because it works closely with the source and even let the users mound the outcomes in the manner they are comfortable with. This approach saves time when the data is complex and contain so many errors associated with them.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "18) How you will check the version of Teradata?",
        "answer": "It can be checked with the following command\n\".SHOW VERSION\".",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "19) Explain the Parallel Data Extension in Teradata?",
        "answer": "PDE is a software interface layer that lies between the Teradata Database and operating system. PDE supports the parallelism through system nodes. It contributes to Teradata Database speed and linear scalability. Many utilities like diagnostic and troubleshooting work at the PDE level.\nPDE tools are a collection of PDE utilities that come with Teradata Database. They are not listed in Utilities because PDE tools have online documentation accessible from a system console using the \"pdehelp\" and \"man\" commands.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "20) What is the use of FALLBACK?",
        "answer": "FALLBACK is a unique feature used by Teradata to handle AMP failures. It protects data in case of AMP vproc failure. Fallback is very useful for the application that requires high availability.\nFall back is automatic; it is enabled by default when you deploy a Teradata database. The fallback setting can't be overridden during or after table creation. Fallback is transparent; it protects data by storing a second copy of each row of a table on any other AMP in the same cluster. Fallback facilitates with AMP fault tolerance at the table level.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "21) What is Database exceptions in Teradata?",
        "answer": "Teradata Database deals with the same features that come with an on-premises Teradata Database system with the following exceptions:\nTeradata database data block read-ahead count is only 15 data blocks.\nTeradata database has a default PERM DB size for permanent tables is 254 sectors.\nTeradata database has a default WORK DB size for temporary tables is 254 sectors, sometimes referred to as SPOOL DB size.\nIn Teradata, one single transaction can consume 100% of FSG cache.\nTeradata Database 16.10 does not support Multiple Hash Maps feature in the public cloud.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "22) List out Teradata data types?",
        "answer": "The list of some basic datatypes in Teradata is as follows.\nData Types Length (Bytes) Range of values\nBYTEINT 1 -128 to +127\nSMALLINT 2 -32768 to +32767\nINTEGER 4 -2,147,483,648 to +2147,483,647\nBIGINT 8 -9,233,372,036,854,775,80 8 to +9,233,372,036,854,775,8 07\nDECIMAL 1-16\nNUMERIC 1-16\nFLOAT 8 IEEE format\nCHAR Fixed Format 1-64,000\nVARCHAR Variable 1-64,000\nDATE 4 YYYYYMMDD\nTIME 6 or 8 HHMMSS.nnnnnn+HHMM or HHMMSS.nnnnnn\nCHAR Fixed Format 1-64,000\nTIMESTAMP 10 or 12 YYMMDDHHMMSS.nnnnnn +HHMM or YYMMDDHHMMSS.nnnnnn",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "And what are the available primary index types?",
        "answer": "The technique to specify where the data exist in the Teradata is called primary index. Each table should contain a primary index specified, if not, Teradata will assign a primary index for the table. The main index provides faster data access and search.\nThere are two types of primary indexes in Teradata:\nUnique Primary Index(UPI)\nNon-Unique Primary Index(NUPI)",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "24) Why is the CASE Expression used in Teradata?",
        "answer": "CASE Expression is used to evaluate each case against a specific condition and returns the result based on the first match. When there is no case that will match condition, then else part will return.\nThe basic syntax of a CASE expression is as follows:\nCASE <expression>  \nWHEN <expression> THEN result-1   \nWHEN <expression> THEN result-2  \nELSE   \nResult-n   \nEND",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "25) What are the Joins in Teradata and How many types of Joins are there in Teradata?",
        "answer": "Joins combine the record from more than one table using common columns or value.\nThere are seven types of joins associated with Teradata.\nInner Join\nInner joins combine the records from multiple tables and returns the value set that is common in both tables.\nLeft Outer Join\nLeft outer join returns all the records in the left table and only common records from the right table.\nRight Outer Join\nRight outer join returns all the records in the right table and only common records from the left table.\nFull Outer Join\nIt is a combination of Left Outer Join and Right Outer Join. It returns both common and distinct records from both the tables.\nSelf-Join\nSelf-join compares the value in a column with the other values in the same column of the table.\nCross Join\nCross join joins every row from the left table to every row in the right table.\nCartesian Production Join\nIt works the same as cross join.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "26) What is called Partitioned Primary Index (PPI) and discuss the advantages of using it in a query?",
        "answer": "Partitioned Primary Index (PPI) is an indexing technique that allows for improving the performance of specific queries. Partitioned Primary Index (PPI) is defined within a table, and rows are sorted according to their partition number. Their row hash arranges records.\nAdvantages of Partitioned Primary Index (PPI):\nPPI helps to avoid a full table scan and only required partitions are accessed.\nPPI avoids using the secondary index, and it helps to prevent additional I/O maintenance.\nPPI allows Quick access to the subset of a large table.\nPPI facilitates with easy to drop old data and add new data.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "",
        "answer": "Database objects that are built using queries on tables are termed as views. The definition of view is stored permanently in the data definition. Data for the view is a dynamic process at the execution time.\n\nSyntax\nCREATE/REPLACE VIEW <viewname>  \nAS   \n<select query>;",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "",
        "answer": "Set operators are used to batch the result from multiple SELECT statements. Set operator is different from joins because joins batch the columns in multiple tables, but set operators batch multiple rows.\nGiven below are the four Set operators in Teradata:\nUNION\nUNION ALL\nINTERSECT\nMINUS/EXCEPT",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "29) What is Upsert statement in Teradata?",
        "answer": "In Teradata, we can combine the update and insert statement into a single statement. It is called an Upsert statement.",
        "reference": "javatpoint.com",
        "role": "teradata"
    },
    {
        "question": "30) What are the String Manipulation operators and functions associated with Teradata?",
        "answer": "Teradata String functions are used for string manipulation. It concatenates strings and creates a single string. It also supports some standard string functions along with the Teradata extension to those functions.\nSUBSTR: It is used to extract only a portion of the long string depends on Teradata extension.\nSUBSTRING: It is used to extract only a portion of the long string depends on the ANSI extension.\nINDEX: It is used to locate a specific position of a character string depends on the Teradata extension.\nPOSITION: It is used to locate a specific position of a character string depends on the ANSI extension.\nTRIM: It trims blank from the specified string.\nUPPER: It converts the string to uppercase.\nLOWER: It converts the string to lowercase.",
        "reference": "javatpoint.com",
        "role": "teradata"
    }
]