[
    {
        "question": "1. How is the statistical significance of an insight assessed?",
        "answer": "Hypothesis testing is used to find out the statistical significance of the insight. To elaborate, the null hypothesis and the alternate hypothesis are stated, and the p-value is calculated.\nAfter calculating the p-value, the null hypothesis is assumed true, and the values are determined. To fine-tune the result, the alpha value, which denotes the significance, is tweaked. If the p-value turns out to be less than the alpha, then the null hypothesis is rejected. This ensures that the result obtained is statistically significant.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "2. Where are long-tailed distributions used?",
        "answer": "A long-tailed distribution is a type of distribution where the tail drops off gradually toward the end of the curve.\nThe Pareto principle and the product sales distribution are good examples to denote the use of long-tailed distributions. Also, it is widely used in classification and regression problems.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "3. What is the central limit theorem?",
        "answer": "The central limit theorem states that the normal distribution is arrived at when the sample size varies without having an effect on the shape of the population distribution.\nThis central limit theorem is the key because it is widely used in performing hypothesis testing and also to calculate the confidence intervals accurately.\nLearn more about Quantitative Methods with our blog!",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "4. What is observational and experimental data in Statistics?",
        "answer": "Observational data correlates to the data that is obtained from observational studies, where variables are observed to see if there is any correlation between them.\nExperimental data is derived from experimental studies, where certain variables are held constant to see if any discrepancy is raised in the working.\nCheck out our blog on Statistics for Data Science!",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "5. What is meant by mean imputation for missing data? Why is it bad?",
        "answer": "Mean imputation is a rarely used practice where null values in a dataset are replaced directly with the corresponding mean of the data.\nIt is considered a bad practice as it completely removes the accountability for feature correlation. This also means that the data will have low variance and increased bias, adding to the dip in the accuracy of the model, alongside narrower confidence intervals.\nBecome a Data Scientist\nM.Tech in\nArtificial Intelligence and Machine Learning\nTwo years online learning\nExecutive M.Tech in AI and ML\nIIT Jammu Alumni Status\nJob Assistance by Intellipaat and IIT Jammu\nEnroll Now",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "6. What is an outlier? How can outliers be determined in a dataset?",
        "answer": "Outliers are data points that vary in a large way when compared to other observations in the dataset. Depending on the learning process, an outlier can worsen the accuracy of a model and decrease its efficiency sharply.\nOutliers are determined by using two methods:\nStandard deviation/z-score\nInterquartile range (IQR)\nGet 100% Hike!\nMaster Most in Demand Skills Now !\nBy providing your contact details, you agree to our Terms of Use & Privacy Policy",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "7. How is missing data handled in statistics?",
        "answer": "There are many ways to handle missing data in Statistics:\nPrediction of the missing values\nAssignment of individual (unique) values\nDeletion of rows, which have the missing data\nMean imputation or median imputation\nUsing random forests, which support the missing values",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "8. What is exploratory data analysis?",
        "answer": "Exploratory data analysis is the process of performing investigations on data to understand the data better.\nIn this, initial investigations are done to determine patterns, spot abnormalities, test hypotheses, and also check if the assumptions are right.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "9. What is the meaning of selection bias?",
        "answer": "Selection bias is a phenomenon that involves the selection of individual or grouped data in a way that is not considered to be random. Randomization plays a key role in performing analysis and understanding model functionality better.\nIf correct randomization is not achieved, then the resulting sample will not accurately represent the population.\nLearn how to calculate and interpret the Median in Statistics!",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "10. What are the types of selection bias in statistics?",
        "answer": "There are many types of selection bias as shown below:\nObserver selection\nAttrition\nProtopathic bias\nTime intervals\nSampling bias\nCheck out our video on Statistics Interview Questions on YouTube designed especially for beginners:",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "11. What is the meaning of an inlier?",
        "answer": "An inlier is a data point that lies at the same level as the rest of the dataset. Finding an inlier in the dataset is difficult when compared to an outlier as it requires external data to do so. Inliers, similar to outliers reduce model accuracy. Hence, even they are removed when they’re found in the data. This is done mainly to maintain model accuracy at all times.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "12. What is the probability of getting a sum of 5 or 8 when 2 dice are rolled once?",
        "answer": "When 2 dice are rolled,\nTotal outcomes = 36 (i.e. 6*6)\nPossible outcomes of getting 5 = 4\nPossible outcomes of getting a sum 8 = 5\nTotal = 9\nProbability =9/36 = 1/4 = 0.25",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "13. State the case where the median is a better measure when compared to the mean.",
        "answer": "In the case where there are a lot of outliers that can positively or negatively skew data, the median is preferred as it provides an accurate measure in this case of determination.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "14. Can you give an example of root cause analysis?",
        "answer": "Root cause analysis, as the name suggests, is a method used to solve problems by first identifying the root cause of the problem.\nExample: If the higher crime rate in a city is directly associated with the higher sales in a red-colored shirt, it means that they are having a positive correlation. However, this does not mean that one causes the other.\nCausation can always be tested using A/B testing or hypothesis testing.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "15. What is the meaning of six sigma in statistics?",
        "answer": "Six sigma is a quality assurance methodology used widely in statistics to provide ways to improve processes and functionality when working with data.\nA process is considered as six sigma when 99.99966% of the outcomes of the model are considered to be defect-free.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "16. What is DOE?",
        "answer": "DOE is an acronym for the Design of Experiments in statistics. It is considered as the design of a task that describes the information and the change of the same based on the changes to the independent input variables.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "17. What is the meaning of KPI in statistics?",
        "answer": "KPI stands for Key Performance Analysis in statistics. It is used as a reliable metric to measure the success of a company with respect to its achieving the required business objectives.\nThere are many good examples of KPIs:\nProfit margin percentage\nOperating profit margin\nExpense ratio",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "18. What type of data does not have a log-normal distribution or a Gaussian distribution?",
        "answer": "Exponential distributions do not have a log-normal distribution or a Gaussian distribution. In fact, any type of data that is categorical will not have these distributions as well.\nExample: Duration of a phone car, time until the next earthquake, etc.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "19. What is the Pareto principle?",
        "answer": "The Pareto principle is also called the 80/20 rule, which means that 80 percent of the results are obtained from 20 percent of the causes in an experiment.\nA simple example of the Pareto principle is the observation that 80 percent of peas come from 20 percent of pea plants on a farm.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "20. What is the meaning of the five-number summary in Statistics?",
        "answer": "The five-number summary is a measure of five entities that cover the entire range of data as shown below:\nLow extreme (Min)\nFirst quartile (Q1)\nMedian\nUpper quartile (Q3)\nHigh extreme (Max)",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "21. What are population and sample in Inferential Statistics, and how are they different?",
        "answer": "A population is a large volume of observations (data). The sample is a small portion of that population. Because of the large volume of data in the population, it raises the computational cost. The availability of all data points in the population is also an issue.\nIn short:\nWe calculate the statistics using the sample.\nUsing these sample statistics, we make conclusions about the population.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "22. What are quantitative data and qualitative data?",
        "answer": "Quantitative data is also known as numeric data.\nQualitative data is also known as categorical data.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "23. What is Mean?",
        "answer": "Mean is the average of a collection of values. We can calculate the mean by dividing the sum of all observations by the number of observations.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "24. What is the meaning of standard deviation?",
        "answer": "Standard deviation represents the magnitude of how far the data points are from the mean. A low value of standard deviation is an indication of the data being close to the mean, and a high value indicates that the data is spread to extreme ends, far away from the mean.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "25. What is a bell-curve distribution?",
        "answer": "A normal distribution can be called a bell-curve distribution. It gets its name from the bell curve shape that we get when we visualize the distribution.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "26. What is skewness?",
        "answer": "Skewness measures the lack of symmetry in a data distribution. It indicates that there are significant differences between the mean, the mode, and the median of data. Skewed data cannot be used to create a normal distribution.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "27. What is kurtosis?",
        "answer": "Kurtosis is used to describe the extreme values present in one tail of distribution versus the other. It is actually the measure of outliers present in the distribution. A high value of kurtosis represents large amounts of outliers being present in data. To overcome this, we have to either add more data into the dataset or remove the outliers.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "28. What is correlation?",
        "answer": "Correlation is used to test relationships between quantitative variables and categorical variables. Unlike covariance, correlation tells us how strong the relationship is between two variables. The value of correlation between two variables ranges from -1 to +1.\nThe -1 value represents a high negative correlation, i.e., if the value in one variable increases, then the value in the other variable will drastically decrease. Similarly, +1 means a positive correlation, and here, an increase in one variable will lead to an increase in the other. Whereas, 0 means there is no correlation.\nIf two variables are strongly correlated, then they may have a negative impact on the statistical model, and one of them must be dropped.\nNext up on this top Statistics Interview Questions and Answers blog, let us take a look at the intermediate set of questions.\n\nIntermediate Interview Questions",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "29. What are left-skewed and right-skewed distributions?",
        "answer": "A left-skewed distribution is one where the left tail is longer than that of the right tail. Here, it is important to note that the mean < median < mode.\nSimilarly, a right-skewed distribution is one where the right tail is longer than the left one. But, here mean > median > mode.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "30. What is the difference between Descriptive and Inferential Statistics?",
        "answer": "Descriptive Statistics: Descriptive statistics is used to summarize a sample set of data like the standard deviation or the mean.\nInferential statistics: Inferential statistics is used to draw conclusions from the test data that are subjected to random variations.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "31. What are the types of sampling in Statistics?",
        "answer": "There are four main types of data sampling as shown below:\nSimple random: Pure random division\nCluster: Population divided into clusters\nStratified: Data divided into unique groups\nSystematical: Picks up every ‘n’ member in the data",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "32. What is the meaning of covariance?",
        "answer": "Covariance is the measure of indication when two items vary together in a cycle. The systematic relation is determined between a pair of random variables to see if the change in one will affect the other variable in the pair or not.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "33. Imagine that Jeremy took part in an examination. The test is having a mean score of 160, and it has a standard deviation of 15. If Jeremy’s z-score is 1.20, what would be his score on the test?",
        "answer": "To determine the solution to the problem, the following formula is used:\nX = μ + Zσ\n\nHere:\nμ: Mean\nσ: Standard deviation\nX: Value to be calculated\n\nTherefore, X = 160 + (15*1.2) = 173.8 (Approximated to 174)\nIf you are looking forward to becoming an expert in Statistics and Data Analytics, make sure to check out Intellipaat’s Data Analyst Certification program.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "34. If a distribution is skewed to the right and has a median of 20, will the mean be greater than or less than 20?",
        "answer": "If the given distribution is a right-skewed distribution, then the mean should be greater than 20, while the mode remains to be less than 20.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "35. What is Bessel's correction?",
        "answer": "Bessel’s correction is a factor that is used to estimate a populations’ standard deviation from its sample. It causes the standard deviation to be less biased, thereby, providing more accurate results.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "36. The standard normal curve has a total area to be under one, and it is symmetric around zero. True or False?",
        "answer": "True, a normal curve will have the area under unity and the symmetry around zero in any distribution. Here, all of the measures of central tendencies are equal to zero due to the symmetric nature of the standard normal curve.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "37. In an observation, there is a high correlation between the time a person sleeps and the amount of productive work he does. What can be inferred from this?",
        "answer": "First, correlation does not imply causation here. Correlation is only used to measure the relationship, which is linear between rest and productive work. If both vary rapidly, then it means that there is a high amount of correlation between them.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "38. What is the relationship between the confidence level and the significance level in statistics?",
        "answer": "The significance level is the probability of obtaining a result that is extremely different from the condition where the null hypothesis is true. While the confidence level is used as a range of similar values in a population.\nBoth significance and confidence level are related by the following formula:\nSignificance level = 1 − Confidence level",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "39. A regression analysis between apples (y) and oranges (x) resulted in the following least-squares line: y = 100 + 2x. What is the implication if oranges are increased by 1?",
        "answer": "If the oranges are increased by one, there will be an increase of 2 apples since the equation is:\ny = 100 + 2x.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "40. What types of variables are used for Pearson’s correlation coefficient?",
        "answer": "Variables to be used for the Pearson’s correlation coefficient must be either in a ratio or in an interval.\nNote that there can exist a condition when one variable is a ratio, while the other is an interval score.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "41. In a scatter diagram, what is the line that is drawn above or below the regression line called?",
        "answer": "The line that is drawn above or below the regression line in a scatter diagram is called the residual or also the prediction error.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "42. What are the examples of symmetric distribution?",
        "answer": "Symmetric distribution means that the data on the left side of the median is the same as the one present on the right side of the median.\nThere are many examples of symmetric distribution, but the following three are the most widely used ones:\nUniform distribution\nBinomial distribution\nNormal distribution",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "43. Where is inferential statistics used?",
        "answer": "Inferential statistics is used for several purposes, such as research, in which we wish to draw conclusions about a population using some sample data. This is performed in a variety of fields, ranging from government operations to quality control and quality assurance teams in multinational corporations.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "44. What is the relationship between mean and median in a normal distribution?",
        "answer": "In a normal distribution, the mean is equal to the median. To know if the distribution of a dataset is normal, we can just check the dataset’s mean and median.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "45. What is the difference between the Ist quartile, the IInd quartile, and the IIIrd quartile?",
        "answer": "Quartiles are used to describe the distribution of data by splitting data into three equal portions, and the boundary or edge of these portions are called quartiles.\nThat is,\nThe lower quartile (Q1) is the 25th percentile.\nThe middle quartile (Q2), also called the median, is the 50th percentile.\nThe upper quartile (Q3) is the 75th percentile.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "46. How do the standard error and the margin of error relate?",
        "answer": "The standard error and the margin of error are quite closely related to each other. In fact, the margin of error is calculated using the standard error. As the standard error increases, the margin of error also increases.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "47. What is one sample t-test?",
        "answer": "This T-test is a statistical hypothesis test in which we check if the mean of the sample data is statistically or significantly different from the population’s mean.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "48. What is an alternative hypothesis?",
        "answer": "The alternative hypothesis (denoted by H1) is the statement that must be true if the null hypothesis is false. That is, it is a statement used to contradict the null hypothesis. It is the opposing point of view that gets proven right when the null hypothesis is proven wrong.\nCheck out this Data Science Certification course to become a certified Data Scientist.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "49. Given a left-skewed distribution that has a median of 60, what conclusions can we draw about the mean and the mode of the data?",
        "answer": "Given that it is a left-skewed distribution, the mean will be less than the median, i.e., less than 60, and the mode will be greater than 60.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "50. What are the types of biases that we encounter while sampling?",
        "answer": "Sampling biases are errors that occur when taking a small sample of data from a large population as the representation in statistical analysis. There are three types of biases:\nThe selection bias\nThe survivorship bias\nThe undercoverage bias\nNext up on this top Statistics Interview Questions and answers blog, let us take a look at the advanced set of questions.\n\n\nAdvanced Interview Questions",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "51. What are the scenarios where outliers are kept in the data?",
        "answer": "There are not many scenarios where outliers are kept in the data, but there are some important situations when they are kept. They are kept in the data for analysis if:\nResults are critical\nOutliers add meaning to the data\nThe data is highly skewed",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "52. Briefly explain the procedure to measure the length of all sharks in the world.",
        "answer": "Following steps can be used to determine the length of sharks:\nDefine the confidence level (usually around 95%)\nUse sample sharks to measure\nCalculate the mean and standard deviation of the lengths\nDetermine t-statistics values\nDetermine the confidence interval in which the mean length lies",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "53. How does the width of the confidence interval change with length?",
        "answer": "The width of the confidence interval is used to determine the decision-making steps. As the confidence level increases, the width also increases.\nThe following also apply:\nWide confidence interval: Useless information\nNarrow confidence interval: High-risk factor",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "54. What is the meaning of degrees of freedom (DF) in statistics?",
        "answer": "Degrees of freedom or DF is used to define the number of options at hand when performing an analysis. It is mostly used with t-distribution and not with the z-distribution.\nIf there is an increase in DF, the t-distribution will reach closer to the normal distribution. If DF > 30, this means that the t-distribution at hand is having all of the characteristics of a normal distribution.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "55. How can you calculate the p-value using MS Excel?",
        "answer": "Following steps are performed to calculate the p-value easily:\nFind the Data tab above\nClick on Data Analysis\nSelect Descriptive Statistics\nSelect the corresponding column\nInput the confidence level",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "56. What is the law of large numbers in statistics?",
        "answer": "The law of large numbers in statistics is a theory that states that the increase in the number of trials performed will cause a positive proportional increase in the average of the results becoming the expected value.\nExample: The probability of flipping a fair coin and landing heads is closer to 0.5 when it is flipped 100,000 times when compared to 100 flips.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "57. What are some of the properties of a normal distribution?",
        "answer": "A normal distribution, regardless of its size, will have a bell-shaped curve that is symmetric along the axes.\nFollowing are some of the important properties:\nUnimodal: It has only one mode.\nSymmetrical: Left and right halves of the curve are mirrored.\nCentral tendency: The mean, median, and mode are at the midpoint.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "58. If there is a 30 percent probability that you will see a supercar in any 20-minute time interval, what is the proba­bility that you see at least one supercar in the period of an hour (60 minutes)?",
        "answer": "The probability of not seeing a supercar in 20 minutes is:\n= 1 − P(Seeing one supercar)\n= 1 − 0.3\n= 0.7\nProbability of not seeing any supercar in the period of 60 minutes is:\n= (0.7) ^ 3 = 0.343\nHence, the probability of seeing at least one supercar in 60 minutes is:\n= 1 − P(Not seeing any supercar)\n= 1 − 0.343 = 0.657",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "59. What is the meaning of sensitivity in statistics?",
        "answer": "Sensitivity, as the name suggests, is used to determine the accuracy of a classifier (logistic, random forest, etc.):\nThe simple formula to calculate sensitivity is:\nSensitivity = Predicted True Events/Total number of Events",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "60. What are the types of biases that you can encounter while sampling?",
        "answer": "There are three types of biases:\nSelection bias\nSurvivorship bias\nUnder coverage bias",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "61. What is the meaning of TF/IDF vectorization?",
        "answer": "TF-IDF is an acronym for Term Frequency – Inverse Document Frequency. It is used as a numerical measure to denote the importance of a word in a document. This document is usually called the collection or the corpus.\nThe TF-IDF value is directly proportional to the number of times a word is repeated in a document. TF-IDF is vital in the field of Natural Language Processing (NLP) as it is mostly used in the domain of text mining and information retrieval.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "62. What are some of the low and high-bias Machine Learning algorithms?",
        "answer": "There are many low and high-bias Machine Learning algorithms, and the following are some of the widely used ones:\nLow bias: SVM, decision trees, KNN algorithm, etc.\nHigh bias: Linear and logistic regression\nCheck out this Machine Learning Training in Noida and master ML Skills.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "63. What is the use of Hash tables in statistics?",
        "answer": "Hash tables are the data structures that are used to denote the representation of key-value pairs in a structured way. The hashing function is used by a hash table to compute an index that contains all of the details regarding the keys that are mapped to their associated values.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "64. What are some of the techniques to reduce underfitting and overfitting during model training?",
        "answer": "Underfitting refers to a situation where data has high bias and low variance, while overfitting is the situation where there are high variance and low bias.\nFollowing are some of the techniques to reduce underfitting and overfitting:\nFor reducing underfitting:\nIncrease model complexity\nIncrease the number of features\nRemove noise from the data\nIncrease the number of training epochs\nFor reducing overfitting:\nIncrease training data\nStop early while training\nLasso regularization\nUse random dropouts",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "65. Can you give an example to denote the working of the central limit theorem?",
        "answer": "Let’s consider the population of men who have normally distributed weights, with a mean of 60 kg and a standard deviation of 10 kg, and the probability needs to be found out.\nIf one single man is selected, the weight is greater than 65 kg, but if 40 men are selected, then the mean weight is far more than 65 kg.\nThe solution to this can be as shown below:\nZ = (x − µ) / ? = (65 − 60) / 10 = 0.5\n\nFor a normal distribution P(Z > 0.5) = 0.409\nZ = (65 − 60) / 5 = 1\nP(Z > 1) = 0.090",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "66. How do you stay up-to-date with the new and upcoming concepts in statistics?",
        "answer": "This is a commonly asked question in a statistics interview. Here, the interviewer is trying to assess your interest and ability to find out and learn new things efficiently. Do talk about how you plan to learn new concepts and make sure to elaborate on how you practically implemented them while learning.\nIf you are looking forward to learning and mastering all of the Data Analytics and Data Science concepts and earn a certification in the same, do take a look at Intellipaat’s latest Data Science with R Certification offerings.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "67. What is the benefit of using box plots?",
        "answer": "Box plots allow us to provide a graphical representation of the 5-number summary and can also be used to compare groups of histograms.\nCheck out this Python Data Science Course to get an in-depth understanding of Data Science and Python.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "68. Does a symmetric distribution need to be unimodal?",
        "answer": "A symmetric distribution does not need to be unimodal (having only one mode or one value that occurs most frequently). It can be bi-modal (having two values that have the highest frequencies) or multi-modal (having multiple or more than two values that have the highest frequencies).",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "69. What is the impact of outliers in statistics?",
        "answer": "Outliers in statistics have a very negative impact as they skew the result of any statistical query. For example, if we want to calculate the mean of a dataset that contains outliers, then the mean calculated will be different from the actual mean (i.e., the mean we will get once we remove the outliers).",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "70. When creating a statistical model, how do we detect overfitting?",
        "answer": "Overfitting can be detected by cross-validation. In cross-validation, we divide the available data into multiple parts and iterate on the entire dataset. In each iteration, one part is used for testing, and others are used for training. This way, the entire dataset will be used for training and testing purposes, and we can detect if the data is being overfitted.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "71. What is a survivorship bias?",
        "answer": "The survivorship bias is the flaw of the sample selection that occurs when a dataset only considers the ‘surviving’ or existing observations and fails to consider those observations that have already ceased to exist.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "72. What is an undercoverage bias?",
        "answer": "The undercoverage bias is a bias that occurs when some members of the population are inadequately represented in the sample.",
        "reference": "intellipaat.com",
        "role": "statistics"
    },
    {
        "question": "1. What do you think of the phrase ‘p-value’?",
        "answer": "It is a number that helps determine the probability of a random occurrence when evaluating a hypothesis. In statistics, the p-value indicates how likely it is that a particular dataset occurred by chance. If the p-value is less than alpha, we can conclude that there is a probability of 5% that the experiment results occurred by chance or 5% of the time, we would see these results.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "2. What is Statistics?",
        "answer": "Statistics is the discipline that studies and develops techniques for gathering, processing, analyzing, interpreting, and communicating statistical information (using information gathered from research).",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "3. What is the central limit theorem?",
        "answer": "The central limit theorem is the foundation of statistics. It states that if a sample is drawn from a population with large sample size, the distribution of the sample's mean will be distributed normally. In other words, the original population distribution will not be affected. The central limit theorem is extremely useful in estimating confidence intervals and testing hypotheses. For instance, let's say I want to estimate the worldwide average height. I would take a sample of people from the general population and calculate the mean. Because it is difficult or impossible to collect data on every person's height, the mean of my sample will serve as my estimate. To create a normal curve, we can plot the mean value and the frequency on a graph and then multiply them several times. The resulting curve will be similar to the original data set, but it will be slightly shifted to the left.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "4. What is a hypothesis test? How is the statistical significance of an insight determined?",
        "answer": "The statistical significance of an experiment's insights can be assessed using hypothesis testing. Hypothesis testing examines the probability of a given experiment's results occurring by chance. The null hypothesis is defined first, and then p-values are computed. If the null hypothesis is true, other values are determined as well. As its name suggests, the alpha value indicates the degree of significance. In a two-tailed test, the p-value is less than alpha if the null hypothesis is rejected but is greater than alpha if the null hypothesis is accepted. In a one-tailed test, the p-value is less than alpha if the null hypothesis is accepted but is greater than alpha if the null hypothesis is rejected. The rejection of the null hypothesis indicates that the results obtained are statistically significant.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "5. Why are statistical data referred to as observational and experimental?",
        "answer": "Correlations between variables can be discovered through the collection of observational data. To determine the cause or effect of a particular variable, experimental data is collected from those experiments where it is kept constant.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "6. What is the definition of an inlier?",
        "answer": "An error instance is usually identified as an Inliner within a data set. It is usually a lower-level data point and should therefore be removed. Finding inliers is usually difficult and requires outside data to identify.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "7. What is the Six sigma in statistic?",
        "answer": "In quality control, an error-free data set is generated using six sigma statistics. σ is known as standard deviation. The lower the standard deviation, the less likely that a process performs accurately and commits errors. If a process delivers 99.99966% error-free results, it is said to be six sigma. A six sigma model is one that outperforms 1σ, 2σ, 3σ, 4σ, and 5σ processes and is sufficiently reliable to deliver defect-free work.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "8. What does KPI stand for in statistics?",
        "answer": "A KPI is a quantifiable measure to evaluate whether the objectives are being met or not. \nIt is a reliable metric to measure the performance level of an organisation or individual. \nAn example of a KPI in an organisation such as the expense ratio. \nIn terms of performance, KPIs are an effective way of measuring whether an organisation or individual is meeting expectations. A KPI is a quantifiable measure to evaluate whether the objectives are being met or not. It is a reliable metric to measure the performance level of an organisation or individual. An example of a KPI in an organisation such as the expense ratio. In terms of performance, KPIs are an effective way of measuring whether an organisation or individual is meeting expectations.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "9. Why is the Pareto principle famous?",
        "answer": "The Pareto principle states that 80% of the effects or results in an experiment come from 20% of the causes. The Pareto principle is often applied to business to explain that 80% of the profits or results come from 20% of the efforts. To illustrate, 80% of customers buy 20% of the items.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "10. What are the characteristics of large numbers in statistics?",
        "answer": "When the number of trials in an experiment increases, the results will approach the expected value in a desirable proportion because of the law of large numbers. To determine the probability of rolling a six-sided die three times, we can use this example. The outcome is far from the expected value, and if we roll the die a large number of times, we will more likely obtain our desired result closer to the expected value (3.5 in this instance).",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "11. What are the differences between Data Science and Statistics?",
        "answer": "Data Science, which is a scientific discipline that employs data, includes interdisciplinary methods, algorithms, and even the procedure for extracting data knowledge. The data can be either coded or uncoerced. Data mining and data science are similar because both provide abstract data from a large amount of data. Data science now includes computer science, mathematical statistics, and computer science and behavioural applications. Data science, which integrates data analysis, understanding, organization, and communication together, produces insights and knowledge from a large amount of data by combining statistical analysis, visualization, and applied mathematical economics. The collection, analysis, interpretation, organization, and presentation of data are the main components of data science. The points listed below provide information on the differences between data science and statistics: On Comparison Data Science Statistics\nDefinition\nA branch of scientific techniques that is related to disciplines other than science.\nData mining involves processes, algorithms, and systems, too.\nTo obtain information from data, use structured or unstructured data.\nA set of operations for dealing with data is provided.\nPart of the mathematics branch.\nDesign experiments can be accomplished by providing methods.\nThe plan collects data, analyzes it, and forms an image to represent it for additional assessments.\nBasic principle\nScientific computing techniques are based on scientific principles.\nThe field of machine learning and other analytics processes, as well as business models, are all part of the industry.\nAffordable big data tools allow for the development of new data-based knowledge.\nA subject that combines technology with business functions, trends, and so on.\nThe branch of studying data that utilise statistics is known as statistics.\nThe application of statistical procedures or algorithms to determine values in order to solve a problem is permissible.\nBasis of Development\nTo tackle data issues.\nDevelop models that can help us understand how people and products behave in real life so that we can improve our business performance.\nDecision making is supported by the decision making process.\nTo interpret data to create interesting and real-world questions.\nFormulate questions and solutions using data tables, graphs, and charts\nYou must be able to grasp how data analysis is done in order to master it.\nDecisions should be supported by information.\nApplications\nMedical management\nFund management\nData security and fraud prevention.\nProduction, Technology, Market research, etc.\nBusiness involving commerce and trade.\nPopulation studies and economics are employed to determine the effects of a law on a community and how it may be affected.\nScience, technology, engineering and other applied fields\nTechnique\nScientific techniques can be used to solve problems using random data\nA data specification defines the quantity of data to be collected for a given problem.\nYou must come up with strategies to get your job done.\nData can be used to improve the performance of organizations.\nMathematical expressions, models, and ideas are used.\nData must be analyzed in order to understand it.\nI want to estimate the values of different data attributes.\nData can be used to determine human activities. On Comparison Data Science Statistics\nDefinition\nA branch of scientific techniques that is related to disciplines other than science.\nData mining involves processes, algorithms, and systems, too.\nTo obtain information from data, use structured or unstructured data.\nA set of operations for dealing with data is provided.\nPart of the mathematics branch.\nDesign experiments can be accomplished by providing methods.\nThe plan collects data, analyzes it, and forms an image to represent it for additional assessments.\nBasic principle\nScientific computing techniques are based on scientific principles.\nThe field of machine learning and other analytics processes, as well as business models, are all part of the industry.\nAffordable big data tools allow for the development of new data-based knowledge.\nA subject that combines technology with business functions, trends, and so on.\nThe branch of studying data that utilise statistics is known as statistics.\nThe application of statistical procedures or algorithms to determine values in order to solve a problem is permissible.\nBasis of Development\nTo tackle data issues.\nDevelop models that can help us understand how people and products behave in real life so that we can improve our business performance.\nDecision making is supported by the decision making process.\nTo interpret data to create interesting and real-world questions.\nFormulate questions and solutions using data tables, graphs, and charts\nYou must be able to grasp how data analysis is done in order to master it.\nDecisions should be supported by information.\nApplications\nMedical management\nFund management\nData security and fraud prevention.\nProduction, Technology, Market research, etc.\nBusiness involving commerce and trade.\nPopulation studies and economics are employed to determine the effects of a law on a community and how it may be affected.\nScience, technology, engineering and other applied fields\nTechnique\nScientific techniques can be used to solve problems using random data\nA data specification defines the quantity of data to be collected for a given problem.\nYou must come up with strategies to get your job done.\nData can be used to improve the performance of organizations.\nMathematical expressions, models, and ideas are used.\nData must be analyzed in order to understand it.\nI want to estimate the values of different data attributes.\nData can be used to determine human activities. On Comparison Data Science Statistics On Comparison Data Science Statistics On Comparison Data Science Statistics Definition\nA branch of scientific techniques that is related to disciplines other than science.\nData mining involves processes, algorithms, and systems, too.\nTo obtain information from data, use structured or unstructured data.\nA set of operations for dealing with data is provided.\nPart of the mathematics branch.\nDesign experiments can be accomplished by providing methods.\nThe plan collects data, analyzes it, and forms an image to represent it for additional assessments.\nBasic principle\nScientific computing techniques are based on scientific principles.\nThe field of machine learning and other analytics processes, as well as business models, are all part of the industry.\nAffordable big data tools allow for the development of new data-based knowledge.\nA subject that combines technology with business functions, trends, and so on.\nThe branch of studying data that utilise statistics is known as statistics.\nThe application of statistical procedures or algorithms to determine values in order to solve a problem is permissible.\nBasis of Development\nTo tackle data issues.\nDevelop models that can help us understand how people and products behave in real life so that we can improve our business performance.\nDecision making is supported by the decision making process.\nTo interpret data to create interesting and real-world questions.\nFormulate questions and solutions using data tables, graphs, and charts\nYou must be able to grasp how data analysis is done in order to master it.\nDecisions should be supported by information.\nApplications\nMedical management\nFund management\nData security and fraud prevention.\nProduction, Technology, Market research, etc.\nBusiness involving commerce and trade.\nPopulation studies and economics are employed to determine the effects of a law on a community and how it may be affected.\nScience, technology, engineering and other applied fields\nTechnique\nScientific techniques can be used to solve problems using random data\nA data specification defines the quantity of data to be collected for a given problem.\nYou must come up with strategies to get your job done.\nData can be used to improve the performance of organizations.\nMathematical expressions, models, and ideas are used.\nData must be analyzed in order to understand it.\nI want to estimate the values of different data attributes.\nData can be used to determine human activities. Definition\nA branch of scientific techniques that is related to disciplines other than science.\nData mining involves processes, algorithms, and systems, too.\nTo obtain information from data, use structured or unstructured data.\nA set of operations for dealing with data is provided.\nPart of the mathematics branch.\nDesign experiments can be accomplished by providing methods.\nThe plan collects data, analyzes it, and forms an image to represent it for additional assessments. Definition A branch of scientific techniques that is related to disciplines other than science.\nData mining involves processes, algorithms, and systems, too.\nTo obtain information from data, use structured or unstructured data. A branch of scientific techniques that is related to disciplines other than science.\nData mining involves processes, algorithms, and systems, too.\nTo obtain information from data, use structured or unstructured data. A branch of scientific techniques that is related to disciplines other than science. Data mining involves processes, algorithms, and systems, too. To obtain information from data, use structured or unstructured data. A set of operations for dealing with data is provided.\nPart of the mathematics branch.\nDesign experiments can be accomplished by providing methods.\nThe plan collects data, analyzes it, and forms an image to represent it for additional assessments. A set of operations for dealing with data is provided.\nPart of the mathematics branch.\nDesign experiments can be accomplished by providing methods.\nThe plan collects data, analyzes it, and forms an image to represent it for additional assessments. A set of operations for dealing with data is provided. Part of the mathematics branch. Design experiments can be accomplished by providing methods. The plan collects data, analyzes it, and forms an image to represent it for additional assessments. Basic principle\nScientific computing techniques are based on scientific principles.\nThe field of machine learning and other analytics processes, as well as business models, are all part of the industry.\nAffordable big data tools allow for the development of new data-based knowledge.\nA subject that combines technology with business functions, trends, and so on.\nThe branch of studying data that utilise statistics is known as statistics.\nThe application of statistical procedures or algorithms to determine values in order to solve a problem is permissible. Basic principle Scientific computing techniques are based on scientific principles.\nThe field of machine learning and other analytics processes, as well as business models, are all part of the industry.\nAffordable big data tools allow for the development of new data-based knowledge.\nA subject that combines technology with business functions, trends, and so on. Scientific computing techniques are based on scientific principles.\nThe field of machine learning and other analytics processes, as well as business models, are all part of the industry.\nAffordable big data tools allow for the development of new data-based knowledge.\nA subject that combines technology with business functions, trends, and so on. Scientific computing techniques are based on scientific principles. The field of machine learning and other analytics processes, as well as business models, are all part of the industry. Affordable big data tools allow for the development of new data-based knowledge. A subject that combines technology with business functions, trends, and so on. The branch of studying data that utilise statistics is known as statistics.\nThe application of statistical procedures or algorithms to determine values in order to solve a problem is permissible. The branch of studying data that utilise statistics is known as statistics.\nThe application of statistical procedures or algorithms to determine values in order to solve a problem is permissible. The branch of studying data that utilise statistics is known as statistics. The application of statistical procedures or algorithms to determine values in order to solve a problem is permissible. Basis of Development\nTo tackle data issues.\nDevelop models that can help us understand how people and products behave in real life so that we can improve our business performance.\nDecision making is supported by the decision making process.\nTo interpret data to create interesting and real-world questions.\nFormulate questions and solutions using data tables, graphs, and charts\nYou must be able to grasp how data analysis is done in order to master it.\nDecisions should be supported by information. Basis of Development To tackle data issues.\nDevelop models that can help us understand how people and products behave in real life so that we can improve our business performance.\nDecision making is supported by the decision making process. To tackle data issues.\nDevelop models that can help us understand how people and products behave in real life so that we can improve our business performance.\nDecision making is supported by the decision making process. To tackle data issues. Develop models that can help us understand how people and products behave in real life so that we can improve our business performance. Decision making is supported by the decision making process. To interpret data to create interesting and real-world questions.\nFormulate questions and solutions using data tables, graphs, and charts\nYou must be able to grasp how data analysis is done in order to master it.\nDecisions should be supported by information. To interpret data to create interesting and real-world questions.\nFormulate questions and solutions using data tables, graphs, and charts\nYou must be able to grasp how data analysis is done in order to master it.\nDecisions should be supported by information. To interpret data to create interesting and real-world questions. Formulate questions and solutions using data tables, graphs, and charts You must be able to grasp how data analysis is done in order to master it. Decisions should be supported by information. Applications\nMedical management\nFund management\nData security and fraud prevention.\nProduction, Technology, Market research, etc.\nBusiness involving commerce and trade.\nPopulation studies and economics are employed to determine the effects of a law on a community and how it may be affected.\nScience, technology, engineering and other applied fields Applications Medical management\nFund management\nData security and fraud prevention.\nProduction, Technology, Market research, etc. Medical management\nFund management\nData security and fraud prevention.\nProduction, Technology, Market research, etc. Medical management Fund management Data security and fraud prevention. Production, Technology, Market research, etc. Business involving commerce and trade.\nPopulation studies and economics are employed to determine the effects of a law on a community and how it may be affected.\nScience, technology, engineering and other applied fields Business involving commerce and trade.\nPopulation studies and economics are employed to determine the effects of a law on a community and how it may be affected.\nScience, technology, engineering and other applied fields Business involving commerce and trade. Population studies and economics are employed to determine the effects of a law on a community and how it may be affected. Science, technology, engineering and other applied fields Technique\nScientific techniques can be used to solve problems using random data\nA data specification defines the quantity of data to be collected for a given problem.\nYou must come up with strategies to get your job done.\nData can be used to improve the performance of organizations.\nMathematical expressions, models, and ideas are used.\nData must be analyzed in order to understand it.\nI want to estimate the values of different data attributes.\nData can be used to determine human activities. Technique Scientific techniques can be used to solve problems using random data\nA data specification defines the quantity of data to be collected for a given problem.\nYou must come up with strategies to get your job done.\nData can be used to improve the performance of organizations. Scientific techniques can be used to solve problems using random data\nA data specification defines the quantity of data to be collected for a given problem.\nYou must come up with strategies to get your job done.\nData can be used to improve the performance of organizations. Scientific techniques can be used to solve problems using random data A data specification defines the quantity of data to be collected for a given problem. You must come up with strategies to get your job done. Data can be used to improve the performance of organizations. Mathematical expressions, models, and ideas are used.\nData must be analyzed in order to understand it.\nI want to estimate the values of different data attributes.\nData can be used to determine human activities. Mathematical expressions, models, and ideas are used.\nData must be analyzed in order to understand it.\nI want to estimate the values of different data attributes.\nData can be used to determine human activities. Mathematical expressions, models, and ideas are used. Data must be analyzed in order to understand it. I want to estimate the values of different data attributes. Data can be used to determine human activities.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "12. What are cherry-picking, P-hacking, and significance chasing?",
        "answer": "Cherry-picking is the act of exclusively taking the bits of information that support a particular conclusion and ignoring all the bits of information that contradict it.\nP-hacking, also known as data collection or analysis manipulation, is a technique that produces significant patterns even though they have no underlying effect.\nReporting insignificant results as if they are almost significant, is known as Significance Chasing. Data Dredging, Data Fishing, and Data Snooping are all names for this behaviour. Cherry-picking is the act of exclusively taking the bits of information that support a particular conclusion and ignoring all the bits of information that contradict it. P-hacking, also known as data collection or analysis manipulation, is a technique that produces significant patterns even though they have no underlying effect. Reporting insignificant results as if they are almost significant, is known as Significance Chasing. Data Dredging, Data Fishing, and Data Snooping are all names for this behaviour.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "13. What is the difference between an error of type I and an error of type II?",
        "answer": "When the null hypothesis is rejected even though it is correct, a type 1 error occurs. False positives are also known as type 1 errors.\nWhen the null hypothesis is not rejected despite being incorrect, a type 2 error occurs. This is also known as a false negative. When the null hypothesis is rejected even though it is correct, a type 1 error occurs. False positives are also known as type 1 errors. When the null hypothesis is not rejected despite being incorrect, a type 2 error occurs. This is also known as a false negative.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "14. How does one define statistical interaction?",
        "answer": "When an input variable influences an output variable, a statistical interaction occurs. \nIn real life, for example, the interaction of adding sugar to the stirring of tea is an example of statistical interaction. Neither of the variables has an impact on sweetness, but the two variables combine to produce sweetness. When an input variable influences an output variable, a statistical interaction occurs. In real life, for example, the interaction of adding sugar to the stirring of tea is an example of statistical interaction. Neither of the variables has an impact on sweetness, but the two variables combine to produce sweetness.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "15. What are some examples of data sets with non-Gaussian distributions?",
        "answer": "When data follows a non-normal distribution, it is frequently non-Gaussian. A non-Gaussian distribution is often seen in many statistics processes. This occurs when data is naturally clustered on one side or the other on a graph. For instance, bacterial growth follows an exponential or non-Gaussian distribution, which is non-normal.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "16. How does linear regression work?",
        "answer": "When utilised in statistics, linear regression is a technique that models the relationship between one or more predictor variables and one outcome variable. For example, linear regression may be used to study the connection between various predictors, such as age, gender, heredity, diet, and height.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "17. What are the necessary conditions for a Binomial Distribution?",
        "answer": "The three most important characteristics of a Binomial Distribution are listed below. The number of observations must be prearranged. In other words, one can only determine the probability of an event happening a specific number of times if a fixed number of trials are performed.\nIt is important that each trial is independent of the others. This means that the probability of each subsequent trial should not be affected by previous trials.\nThe chance of getting the job remains the same no matter how many times you try. The number of observations must be prearranged. In other words, one can only determine the probability of an event happening a specific number of times if a fixed number of trials are performed. It is important that each trial is independent of the others. This means that the probability of each subsequent trial should not be affected by previous trials. The chance of getting the job remains the same no matter how many times you try.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "18. What is the difference between a sample and a population?",
        "answer": "The subset of the population from which numbers are obtained is known as the sample. The numbers obtained from the population are known as parameters, while the numbers obtained from the sample are known as statistics. It is through sample data that conclusions may be made about the population. Population Sample\nA parameter is an observable quality that can be measured. Statistics is an observable quality that can be measured.\nEvery element of the population is a unique individual. A subset of the population is used to explore some aspects of the population.\nAn opinion report is a true representation of what happened. The reported values have a confidence level and an error margin.\nAll members of a group are included in the list. A particular portion of the population is represented by that subset. Population Sample\nA parameter is an observable quality that can be measured. Statistics is an observable quality that can be measured.\nEvery element of the population is a unique individual. A subset of the population is used to explore some aspects of the population.\nAn opinion report is a true representation of what happened. The reported values have a confidence level and an error margin.\nAll members of a group are included in the list. A particular portion of the population is represented by that subset. Population Sample Population Sample Population Sample A parameter is an observable quality that can be measured. Statistics is an observable quality that can be measured.\nEvery element of the population is a unique individual. A subset of the population is used to explore some aspects of the population.\nAn opinion report is a true representation of what happened. The reported values have a confidence level and an error margin.\nAll members of a group are included in the list. A particular portion of the population is represented by that subset. A parameter is an observable quality that can be measured. Statistics is an observable quality that can be measured. A parameter is an observable quality that can be measured. Statistics is an observable quality that can be measured. Every element of the population is a unique individual. A subset of the population is used to explore some aspects of the population. Every element of the population is a unique individual. A subset of the population is used to explore some aspects of the population. An opinion report is a true representation of what happened. The reported values have a confidence level and an error margin. An opinion report is a true representation of what happened. The reported values have a confidence level and an error margin. All members of a group are included in the list. A particular portion of the population is represented by that subset. All members of a group are included in the list. A particular portion of the population is represented by that subset.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "19. What are the different kinds of variables or levels of measurement?",
        "answer": "A variable can be categorized as one of four types: Ordinal, Interval, Ratio, or Nominal. Scale and Continuous are sometimes used to describe Interval and Ratio levels of measurement, respectively.  ",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "20. What is the difference between Descriptive and Inferential Statistics?",
        "answer": "Descriptive Inferential\nDescribe the data in terms of its key characteristics. To conclude the population, it is used.\nData can be organised, analysed, and presented in a meaningful way thanks to charts. The purpose of data analysis is to compare data and make predictions through hypotheses.\nUsing charts, tables, and graphs to present information. Probability was responsible for achieving this goal. Descriptive Inferential\nDescribe the data in terms of its key characteristics. To conclude the population, it is used.\nData can be organised, analysed, and presented in a meaningful way thanks to charts. The purpose of data analysis is to compare data and make predictions through hypotheses.\nUsing charts, tables, and graphs to present information. Probability was responsible for achieving this goal. Descriptive Inferential Descriptive Inferential Descriptive Inferential Describe the data in terms of its key characteristics. To conclude the population, it is used.\nData can be organised, analysed, and presented in a meaningful way thanks to charts. The purpose of data analysis is to compare data and make predictions through hypotheses.\nUsing charts, tables, and graphs to present information. Probability was responsible for achieving this goal. Describe the data in terms of its key characteristics. To conclude the population, it is used. Describe the data in terms of its key characteristics. To conclude the population, it is used. Data can be organised, analysed, and presented in a meaningful way thanks to charts. The purpose of data analysis is to compare data and make predictions through hypotheses. Data can be organised, analysed, and presented in a meaningful way thanks to charts. The purpose of data analysis is to compare data and make predictions through hypotheses. Using charts, tables, and graphs to present information. Probability was responsible for achieving this goal. Using charts, tables, and graphs to present information. Probability was responsible for achieving this goal.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "1. What is sampling?",
        "answer": "Selecting an unbiased or random subset of individual observations in a population is regarded as part of the statistical practice of sampling. In order to obtain some understanding of the population, sampling is used.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "2. How do you determine the statistical significance of an insight?",
        "answer": "The p-value is used to determine whether the null hypothesis is true or false. To put it another way, the null hypothesis states that there is no difference between the conditions, and the alternate hypothesis states that there is a difference. The p-value is then calculated.\nOnce the p-value has been calculated, the null hypothesis is accepted and the sample values are determined. The alpha value, which indicates the significance of the result, is adjusted to fine-tune the result. If the p-value is lower than the alpha, the null hypothesis is rejected and the result is statistically significant. The p-value is used to determine whether the null hypothesis is true or false. To put it another way, the null hypothesis states that there is no difference between the conditions, and the alternate hypothesis states that there is a difference. The p-value is then calculated. Once the p-value has been calculated, the null hypothesis is accepted and the sample values are determined. The alpha value, which indicates the significance of the result, is adjusted to fine-tune the result. If the p-value is lower than the alpha, the null hypothesis is rejected and the result is statistically significant.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "3. How does the central limit theorem work?",
        "answer": "A stable distribution is one whose parameters change only slightly when the sample size changes. The central limit theorem says that a normal distribution is a result when the sample size is unchanged and the population shape doesn't change. The central limit theorem is crucial because it provides us with the correct formula for calculating confidence intervals. It is also used to test hypotheses correctly.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "4. How do you define exploratory data analysis?",
        "answer": "The goal of an exploratory data analysis is to better understand data by conducting investigations on it. During this stage, patterns are detected, hypotheses are tested, anomalies are spotted, and the foundation for the research is established.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "5. What is the definition of selection bias?",
        "answer": "The process of selecting individual or group data in a way that is not random is known as selection bias. Randomization is crucial in evaluating model functionality and performing analysis. Therefore, if incorrect randomization is not avoided, the obtained sample will not accurately represent the population.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "6. What does it mean by inlier?",
        "answer": "Finding an inlier in a dataset is more challenging than finding an outlier. Because finding an inlier requires external data, model accuracy is often maintained. The reduction in model accuracy caused by the presence of inliers is the same as that caused by outliers. Even when inliers are detected in the data, they are usually removed to maintain model accuracy.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "7. What are the applications of long-tailed distributions?",
        "answer": "The part of the curve that extends to the end is known as a long tail. It gradually gets smaller towards the end of the curve. The long-tailed distribution is used to demonstrate the Pareto principle and the product sales distribution in these examples. It is also utilised in classification and regression problems.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "8. In what situation would the median be a more suitable measure compared to the mean?",
        "answer": "In situations where outliers can affect data in either a positive or negative manner, the median is preferable due to its ability to accurately gauge this.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "9. How might root cause analysis be applied to a real-life situation?",
        "answer": "The technique of identifying the source of a problem by identifying the root cause is known as root cause analysis.\nExamples: A positive correlation between the higher crime rate in a city and the higher sales of red shirts can be inferred from the above sentence. However, this does not mean that one causes the other.\nCorrelational and experimental approaches can always be used to test causation. The technique of identifying the source of a problem by identifying the root cause is known as root cause analysis. Examples: A positive correlation between the higher crime rate in a city and the higher sales of red shirts can be inferred from the above sentence. However, this does not mean that one causes the other. Examples: Correlational and experimental approaches can always be used to test causation.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "10. How does the Design of Experiments in statistics work?",
        "answer": "The Design of Experiments in Statistics is an experimental design that defines an inquiry task that specifies how variable changes when another variable change. It is also known as the Design of Experiments. Design of Experiments",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "11. What does standard deviation mean?",
        "answer": "When a set of data points is near the mean, a low value of standard deviation indicates that the points are close to the mean, and a high value indicates that the points are far away from the mean. On the other hand, when the data points are far apart from each other, a high standard deviation indicates that the points are far away from the mean, and a low standard deviation indicates that the points are close to the mean.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "12. What are the characteristics of a bell-curve distribution?",
        "answer": "The characteristic bell curve shape of a normal distribution is what gives it its name. We can perceive the bell curve as we look at the distribution.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "13. What is your definition of skewness?",
        "answer": "Skewed data distribution has a non-symmetrical pattern relative to the mean, the mode, and the median. The skewness of data indicates that there are significant differences between the mean, the mode, and the median. Data that is skewed cannot be used to create a normal distribution.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "14. How do you define kurtosis?",
        "answer": "Outliers are detected in a data distribution using kurtosis. It measures the extent to which the tail values diverge from the central portion of the distribution. The higher the kurtosis, the higher the number of outliers in the data. To reduce their effect, we may either include more data or eliminate the outliers.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "15. What is the definition of correlation?",
        "answer": "The degree to which variables correlate is tested by covariance and correlation. In contrast to covariance, correlation indicates how closely linked two variables are. Values for correlation range from -1 to +1, with -1 indicating a strong negative correlation and +1 indicating a strong positive correlation.\nA high negative correlation, where if one variable increases, the other variable will decrease drastically, is represented by the -1 value. A positive correlation, where an increase in one variable will cause an increase in the other, is represented by the +1 value. There is no correlation between 0 and +1 variables, whereas 0 and -1 variables have a negative correlation.\nIf the statistical model is affected negatively by two variables that are strongly correlated, then one of them must be removed. The degree to which variables correlate is tested by covariance and correlation. In contrast to covariance, correlation indicates how closely linked two variables are. Values for correlation range from -1 to +1, with -1 indicating a strong negative correlation and +1 indicating a strong positive correlation. A high negative correlation, where if one variable increases, the other variable will decrease drastically, is represented by the -1 value. A positive correlation, where an increase in one variable will cause an increase in the other, is represented by the +1 value. There is no correlation between 0 and +1 variables, whereas 0 and -1 variables have a negative correlation. If the statistical model is affected negatively by two variables that are strongly correlated, then one of them must be removed.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "16. Left-skewed and right-skewed distributions exist, what are they?",
        "answer": "The left tail is longer than the right tail in a left-skewed distribution. It is critical to note here that mean, median, and mode are inverses of one another.\nIn contrast to a left-skewed distribution, in which the left tail is longer than the right one, a right-skewed distribution is one where the right tail is longer than the left one. Here, the mean > the median > the mode. The left tail is longer than the right tail in a left-skewed distribution. It is critical to note here that mean, median, and mode are inverses of one another. In contrast to a left-skewed distribution, in which the left tail is longer than the right one, a right-skewed distribution is one where the right tail is longer than the left one. Here, the mean > the median > the mode.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "17. How does the term covariance relate to understanding?",
        "answer": "When two items are associated in a random process, covariance is the measure of how closely they fluctuate together. Is there a connection between one of the variables in a random pair and the other variable? If there is, then the systematic connection is determined.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "18. How do you define Bessel's correction?",
        "answer": "Bessel’s correction corrects the flaw in using a sample to estimate a population standard deviation. It lowers the bias in the estimated standard deviation, resulting in more accurate measurements.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "19. What are inferential statistics used for?",
        "answer": "In inferential statistics, we use some sample data to draw conclusions about a population. From government operations to quality control and quality assurance teams in multinational corporations, inferential statistics are used in a variety of fields.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "20. How are mean and median related in a normal distribution?",
        "answer": "The mean and the median of a dataset are in agreement if the dataset’s distribution is normal. We can immediately tell if a dataset’s distribution is normal if we simply check its mean and median.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "21. What is the relationship between standard error and the margin of error?",
        "answer": "The margin of error is proportionally influenced by the standard error. In other words, the margin of error is computed using standard error. As standard error increases, the margin of error also rises.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "22. What does a degree of freedom (DF) represent in statistics?",
        "answer": "The t-distribution is used to calculate degrees of freedom and not the z-distribution. When speaking about degrees of freedom, we are referring to the number of options at our disposal when conducting an analysis. The t-distribution will shift closer to a normal distribution as DF increases. If DF is greater than 30, this means that the t-distribution at hand has all of the characteristics of a normal distribution.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "23. How do you explain the law of large numbers in statistics?",
        "answer": "Inference from statistical data can be said to follow the law of large numbers, which purports that, as the number of trials increases, the average result will increase in proportion to it. The percentage of heads obtained by repeatedly flipping a fair coin is lower the more times it is flipped, 100,000 times in this example.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "24. How does TF/IDF vectorization relate to meaning?",
        "answer": "A numerical value representing the importance of a word in a document is referred to as TF-IDF. It is measured using the Term Frequency – Inverse Document Frequency formula. A collection of a corpus is usually called upon to perform this calculation. The phrase frequency-inverse document frequency value is directly proportional to the number of times a word appears in a document. Text mining and information retrieval are mainly dependent on phrase frequency-inverse document frequency values.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "25. What is the purpose of Hash tables in statistics?",
        "answer": "When key-value pairs are stored in a hash table, the information regarding keys and associated values are stored in a hierarchical fashion using hash tables. The hashing function is used to provide an index that contains all of the information regarding keys and their associated values.",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "26. Symmetric distributions need to be unimodal, does it?",
        "answer": "Bi- or multi-modal symmetric distributions do not have to have only one mode or value that occurs most frequently, nor do they have to be unimodal (having only one mode or value that occurs most frequently).",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "27. Is there any significance to outliers in statistics?",
        "answer": "Outliers have a significant detrimental impact on the calculation of any statistical query result. For example, if we seek to compute the mean of a dataset that contains outliers, we will get a different result than the actual mean (i.e., the mean we would get after removing the outliers).",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "28. What is the meaning of Central Tendency?",
        "answer": "The central tendency measures (signifies) the central position within the dataset by referencing a single value. The three most common central tendency measures are the mean, the median, and the mode. 1. Mean: The Arithmetic Mean is the sum of all values divided by the number of values. In cases where n values are provided (x1, x2, x3, …, xn), the following formula can be used. 1. Mean:   2. Median: The median is the value located in the middle when the data is ordered (e.g. ordered in ascending or descending order). If n values are provided (such as x1, x2, x3,……xn), then the median is x ƪ = { x1, x2, x3,……xn } .  2. Median: If n is odd, the case is I. If n is odd, the case is I.   If n is even, the case is II. If n is even, the case is II.   3. Mode: In the dataset, there may be more than one value that is the mode. Therefore, the mode is the most frequent value. 3. Mode:",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "29. How do you define Normal Distribution?",
        "answer": "The mean of a Normal Distribution is located symmetrically about the distribution's centre. It is also known as a Gaussian Distribution. A symmetric curve resembles a bell, with the most frequent data occurring at the centre (see the figure).  ",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "30. How do you define empirical rule?",
        "answer": "The 68 – 95 – 99.7 rule or the Three Sigma Rule refers to the proposition that on a Normal Distribution, There will be 68% within one Standard Error of the Mean of the data.\nThere will be 95% of the data within two Standard deviations of the mean.\nThere is around a 97% chance that the data will be within three standard deviations of the mean. There will be 68% within one Standard Error of the Mean of the data. There will be 95% of the data within two Standard deviations of the mean. There is around a 97% chance that the data will be within three standard deviations of the mean.   There's a lot of work involved in preparing for a data science interview, no matter how much experience you've gained or how impressive your statistics degree is. An interview may surprise you no matter how much work you've done or how many statistics courses you've taken, so be sure to keep those questions in mind when you discuss. The Statistics Interview Questions and Answers listed here provide a fundamental understanding of Statistics from the ground up to the most advanced concepts. They enable students and professionals to get a comprehensive view of the field. That concludes our interview questions on statistics! Hopefully, this has refreshed your knowledge on the subject. Useful Resources https://www.interviewbit.com/technical-interview-questions/\nhttps://www.interviewbit.com/coding-interview-questions/\nhttps://www.interviewbit.com/mock-interview/\nhttps://www.interviewbit.com/blog/ https://www.interviewbit.com/technical-interview-questions/ https://www.interviewbit.com/technical-interview-questions/ https://www.interviewbit.com/coding-interview-questions/ https://www.interviewbit.com/coding-interview-questions/ https://www.interviewbit.com/mock-interview/ https://www.interviewbit.com/mock-interview/ https://www.interviewbit.com/blog/ https://www.interviewbit.com/blog/",
        "reference": "interviewbit.com",
        "role": "statistics"
    },
    {
        "question": "1) What is Statistics?",
        "answer": "Statistics is a discipline that concerns the study of collection, organization, analysis, interpretation, and presentation of data. Statistics study is generally used in scientific, industrial, and social problems to understand the statistical population or a statistical model of the related data. For example, to get the population statistics, we can use diverse it into the groups of people or objects such as \"all people living in a country\".\nStatistics is the study of every aspect of data, including the planning of data collection in terms of the design of surveys and experiments.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "2) What are the different types of Statistics?",
        "answer": "There are mainly two types of Statistics:\nADVERTISEMENT\nDescriptive statistics\nInferential statistics\nDescriptive Statistics\nDescriptive statistics is a type of statistics where data is summarized through the given observations. The summarization is done from a population sample using parameters such as the mean or standard deviation. Descriptive statistics provides a way to organize, represent and describe a collection of data using tables, graphs, and summary measures. For example, a collection of people in a city using specific services such as the internet or television channels.\nThe descriptive statistics can be categorized into the following four different categories:\nMeasure of frequency\nMeasure of position\nMeasure of dispersion\nA measure of central tendency\nInferential Statistics\nInferential statistics is a type of statistics used to interpret the meaning of descriptive statistics. These statistics are used to conclude the data that depends on random variations such as observational errors, sampling variation, etc. Once we have collected, analyzed, and summarized the data, we use these statistics to describe the meaning of the collected data.\nIn this method, we use the information collected from a sample to make decisions, predictions, or inferences from a population. It also facilitates us to give statements that go beyond the available data or information.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "3) What is the key difference between data and statistics?",
        "answer": "In general, people often use the terms \"data\" and \"statistics\" interchangeably, but there is a key difference between them. Data can be specified as the individual pieces of factual information recorded and used for analysis. In other terms, data is raw information from which statistics are created. On the other hand, statistics are the results of data analysis, its interpretation, and presentation.\nIn other words, we can say that statistics is a process of some computation to provide some understanding of what the data means. Statistics are generally presented in the form of a table, chart, or graph. For research purposes, we require both statistics and data frequently. Statistics are often reported and used by government agencies. For example, unemployment statistics, educational literacy statistics, etc. These types of statistics are called \"statistical data\".",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "4) What are the main things you should know before studying data analysis?",
        "answer": "Following are the four main things you should know before studying data analysis. These things are:\nDescriptive statistics\nInferential statistics\nDistributions (normal distribution / sampling distribution)\nHypothesis testing",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "5) What are the four different types of data statistics?",
        "answer": "Data statistics can be divided into mainly two categories:\nQualitative data\nQuantitative data\nLater, these can be subdivided into 4 types of data where nominal data and ordinal data come under qualitative data, and interval and ratio data come under quantitative data.\nQualitative data: Qualitative data is a set of information that cannot be measured in the form of numbers. It is also called categorical data. It normally contains words, narratives, etc., that we label with names. It mainly focuses on the qualities of things in data, and after the qualitative data analysis, the outcome comes in featuring keywords, extracting data, and ideas elaboration.\nFor example, a person's hair color such as black, brown, red, blonde, etc. The qualitative data can be divided into two subcategories: nominal and ordinal.\nNominal Data: The nominal data are used to label variables with no quantitative value and no order. It doesn't change the meaning if you change the order of the value, and after that meaning will remain the same. So, you can only observe the nominal data and can't measure.\nOrdinal Data: The ordinal data is very much similar to the nominal data but not in the case of an order. The ordinal data is ordered, and their categories can be ordered like 1st, 2nd, etc.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "6) What is the Central Limit Theorem? Why is it used?",
        "answer": "Central Limit Theorem is the most important part of statistics. It specifies that the distribution of a sample from a population that consists of large sample size will have its mean normally distributed. In other words, we can say that it will not affect the original population distribution even if the sample size gets larger, regardless of the population's distribution. Generally, it is considered sufficient for the CLT to hold if the sample sizes are equal to or more than 30.\nCentral Limit Theorem or CTL is mainly used to calculate confidence intervals and hypothesis testing. It also facilitates us to calculate the confidence intervals accurately. For example, if you want to calculate the average height of the people in the world, you have to take some samples from the general population, which serves as the data set. Here, it is very difficult or nearly impossible to get data regarding the height of every person in the world, so you have to calculate the mean of your sample data.\nBy multiplying the get data set several times, you will get the mean and their frequencies which you can plot on the graph and create a normal distribution curve. Here, you will get a bell-shaped curve that closely resembles the original data set.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "7) What do you understand by observational and experimental data in Statistics?",
        "answer": "Observational data is a type of data obtained from observational studies. In observational data, we observe the variables to see if there is any correlation between them. On the other hand, experimental data is a type of data that is collected from experimental studies. Here, we hold certain variables as constant to see if there is any discrepancy raised in the working.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "8) How can you assess the statistical significance of an insight?",
        "answer": "We can use hypothesis testing to determine the statistical significance of an insight. Here, we state the null and alternate hypotheses and then calculate the p-value. Once the p-value is calculated, the null hypothesis is assumed true, and the values are determined. To ensure the value's correctness, we compare it with the alpha value, which denotes the significance, which is tweaked. If the p-value is less than the alpha value, the null hypothesis is rejected, otherwise considered. This is used to ensure that the result obtained is statistically significant.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "9) What is the difference between data analysis and machine learning?",
        "answer": "Following is a list of key differences between data analysis and machine learning:\nData Analysis Machine Learning\nData analysis is a process where we inspect, clean, transform, and model data to find useful information, informing conclusions, and support decision-making, which can enhance the decision-making process. Machine learning is mainly used to automate the entire data analysis workflow to provide deeper, faster, and more comprehensive insights.\nData analysis requires a deep knowledge of coding and basic knowledge of statistics. On the other hand, machine learning requires a basic knowledge of coding and deep knowledge of statistics and business.\nWe mainly focus on generating valuable insights from the available data in data analysis. Companies use the data analysis process to make better decisions regarding several matters such as marketing, production, etc. We mainly focus on studying algorithms that improve the overall user experience in machine learning. It is a subset of artificial intelligence that leverages algorithms to analyze huge amounts of data.\nData analysis may require human intervention to inspect, clean, transform, and model data to find useful and trustworthy information. In machine learning, we use algorithms that learn from data automatically and apply the learning without human intervention.\nThe average salary of a data analysis professional in India is less than the salary of a machine learning professional. The average salary of a machine learning professional in India is more than the salary of a data analysis professional.\nA data analysis professional has to deal with data, so they should have deep knowledge of coding and basic knowledge of statistics. A machine learning professional must know about Deep Learning, Natural Language Processing (NLP), Computer Vision, Data Analytics Skills, Statistical Analysis, SQL, and knowledge of R and Python programming language.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "10) What is the difference between inferential statistics and descriptive statistics?",
        "answer": "Inferential statistics provide information about a sample. It is required to conclude the population. On the other hand, descriptive statistics provide exact and accurate information.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "11) What is Normality in Statistics?",
        "answer": "In Statistics, Normality is behaviour consistent with the usual way of behaving of a person. It is an accepted way of social standards and thinking and behaving similarly to the majority, and generally seen as a good way in this context. According to the situation, it can also be specified as expected and appropriate behaviour.\nIn the case of psychological statistics, it can also be just being average. It specifies how you adjust to the surroundings, manage or control emotions, work satisfactorily, and build satisfactory, fulfilling, or at least acceptable relationships.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "12) What are the criteria for Normality?",
        "answer": "For any specified behaviour or trait, the criteria for Normality are being average or close to the average. It means the scores falling within one standard deviation above or below the mean is normal. The most average 68.3% of the population is considered normal.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "13) What is the assumption of NormalityNormality?",
        "answer": "In technical terms, the assumption of NormalityNormality states that the sampling distribution of the mean is normal or that the distribution of means across samples is normal. In other words, the assumption of NormalityNormality specifies that the mean distribution across samples is normal. This is true across independent samples as well.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "14) What is the main usage of long-tailed distributions? Where are they mainly used?",
        "answer": "The long-tailed distributions are the type of distribution where the tail gradually drops off toward the curve's end. They are most widely used in classification and regression problems. The Pareto principle and the product sales distribution are good examples of using long-tailed distributions.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "15) What do you understand by Hypothesis Testing?",
        "answer": "In Statistics, Hypothesis Testing is mainly used to see if a certain experiment generates meaningful results. It helps assess the statistical significance of insight by finding the odds of the results occurring by chance. In Hypothesis Testing, the first thing is to know the null hypothesis and then specify it. After that, the p-value is calculated, and if the null hypothesis is true, the other values are also determined. The alpha value specifies the significance, and you can adjust it accordingly.\nIf the p-value is less than the alpha value, the null hypothesis is rejected, but the null hypothesis is accepted if the p-value is greater than the alpha value. If the null hypothesis is rejected, it indicates that the results obtained are statistically significant.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "16) How can you handle the missing data in Statistics?",
        "answer": "There are several ways to handle the missing data in Statistics:\nBy predicting the missing values.\nBy assigning the individual or unique values.\nBy deleting the rows which have the missing data.\nBy mean imputation or median imputation.\nBy using the random forests, which support the missing values.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "17) What do you understand by mean imputation for missing data? Why is considered bad?",
        "answer": "Mean imputation is a way where null values in a dataset are replaced directly with the corresponding mean of the data. It is a rarely used practice nowadays. Mean imputation is considered bad practice because it completely removes the accountability for feature correlation. It also means that the data will have low variance and increased bias that may cause a dip in the model's accuracy, along with the narrower confidence intervals.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "18) What do you understand by six Sigma in Statistics?",
        "answer": "In Statistics, six Sigma is a quality control method used to produce an error or defect-free data set. In this method, the standard deviation is known as Sigma or σ. The more the standard deviation is, the less likely that process would perform with accuracy and causes a defect. A six sigma model works better than 1σ, 2σ, 3σ, 4σ, 5σ processes and is reliable enough to provide a defect-free work. If you get the outcome of the process 99.99966% error-free, it is considered six Sigma.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "19) What is an exploratory data analysis in Statistics?",
        "answer": "In Statistics, an exploratory data analysis is the process of performing investigations on data to understand the data better. In this process, the initial investigations are done to determine patterns, spot abnormalities, test hypotheses, and check if the assumptions are correct.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "20) What do you understand by selection bias?",
        "answer": "In Statistics, the selection bias is a phenomenon that involves the selection of individual or grouped data in a way that is not considered to be random. Randomization plays a vital role in performing analysis and understanding the model functionality better. If we don't achieve the correct randomization, the resulting sample will not accurately represent the population.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "21) What is an outlier in Statistics? How can you determine an outlier in a data set?",
        "answer": "In Statistics, outliers are data points that usually vary largely as compared to other observations in the dataset. Based on the learning process, an outlier can decrease a model's accuracy and decrease its efficiency sharply.\nWe can determine an outlier by using two methods:\nStandard deviation/z-score\nInterquartile range (IQR)",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "22) What do you understand by an inlier in Statistics?",
        "answer": "An inlier is a data point within a data set that lies at the same level as the rest of the data set. It isn't easy to find an inlier in the dataset compared to an outlier as it requires external data.\nSimilar to outliers, inliers also reduce the model accuracy. Unlike outliers, inlier is hard to find and often requires external data for accurate identification. So, it is usually an error, and we have to remove it to improve the model accuracy. This is mainly done to maintain the model accuracy at all times.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "23) What do you understand by KPI in Statistics?",
        "answer": "KPI is an acronym that stands for Key Performance Indicator. A KPI is a quantifiable measure to understand if we can achieve the goal or not. KPI is a reliable metric that is generally used to measure the performance level of an organization or individual for the objectives. An example of KPI in an organization is the expense ratio.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "24) What are the different types of selection bias in Statistics?",
        "answer": "There are several types of selection bias in Statistics:\nAttrition selection bias\nObserver selection bias\nProtopathic selection bias\nTime intervals selection bias\nSampling selection bias",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "25) What is the law of large numbers in Statistics?",
        "answer": "In Statistics, the law of large numbers is used to specify that if we increase the number of trials in an experiment, we will get a positive and proportional increase in the results coming closer to the expected value. For example, if you roll a six-sided dice three times and check the probability, you will see that the expected value obtained is far from the average value. On the other hand, if you roll a dice a large number of times, you will obtain the average result closer to the expected value, which is 3.5 in this case. This is a good example of the law of large numbers in Statistics.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "26) What is root cause analysis in Statistics? Can you give an example to explain it?",
        "answer": "As the name suggests, root cause analysis is a method used in Statistics to solve problems by first identifying the root cause of the problem.\nFor example, If you see that the higher crime rate in a city is directly associated with the higher sales in a black-coloured shirt, it means that they have a positive correlation. However, it does not mean that one causes the other. Correlation is always tested using A/B testing or hypothesis testing.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "27) What are some important properties of a normal distribution in Statistics?",
        "answer": "Normal distribution is used to specify the data, which is symmetric to the mean, and data far from the mean occurred less frequently. It appears as a bell-shaped curve in graphical form, which is symmetrical along the axes. In Statistics, a normal distribution is also known as Gaussian distribution. It appears as a bell-shaped curve in graphical form, which is symmetrical along the axes. In Statistics, a normal distribution is also known as Gaussian distribution.\nA normal distribution consists of the following properties:\nSymmetrical: The symmetrical property specifies the shape changes with that of parameter values.\nUnimodal: As the name specifies, this property has only one mode.\nMean: This property is used to measure the central tendency.\nCentral tendency: It specifies that the mean, median, and mode lie at the centre, which means they are all equal, and the curve is perfectly symmetrical at the midpoint.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "28) In which cases median is a better measure than the mean?",
        "answer": "In the cases where there are a lot of outliers that can positively or negatively skew data, we prefer the median as it provides an accurate measure in this case of determination.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "29) What is the 'p-value' in Statistics? How would you describe it?",
        "answer": "In Statistics, a p-value is a number that indicates the likelihood of data occurring by a random chance. It is calculated during hypothesis testing. If the p-value is 0.5 and is less than alpha, we can conclude that there is a probability of 5% that the experiment results occurred by chance. In other words, we can say that 5% of the time, we can observe these results by chance.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "30) How can you calculate the p-value using MS Excel in Statistics?",
        "answer": "In Excel, the p-value is called probability value. It is used to understand the statistical significance of a finding. The main use of the p-value is to test the validity of the Null Hypothesis. If the Null Hypothesis is not seemed according to the p-value, we have to believe that the alternative hypothesis might be true. P-value allows us to determine whether the provided results are caused by chance or whether we are testing two unrelated things. So, the p-value is considered an investigator and not a judge.\nIt is a number between 0 and 1, but it is generally denoted in percentages. If the p-value is 0.05, it will be denoted as 5%. A smaller p-value leads to the rejection of the Null Hypothesis.\nFollowing is the formula to calculate the p-value using MS Excel in Statistics:\np-value = tdist(x,deg_freedom,tails)\nThe p-value is expressed in decimals in Excel. Follow the steps given below to calculate the p-value in Excel:\nFirst, find the Data tab.\nAfter that, click on the data analysis icon on the Analysis tab.\nSelect Descriptive Statistics and then click OK.\nSelect the relevant column.\nInput the confidence level and other variables.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "31) What do you understand by DOE in Statistics?",
        "answer": "DOE is an acronym that stands for the Design of Experiments in Statistics. In this process, we design a task that describes the information and the change of the same based on the changes to the independent input variables.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "32) What do you understand by Covariance?",
        "answer": "Covariance is a measure that specifies how much two random variables vary together. It indicates how two variables move in sync with each other. It also specifies the direction of the relationship between two variables. There are two types of Covariance: positive and negative Covariance. The positive Covariance specifies that both variables tend to be high or low simultaneously. On the other hand, the negative Covariance specifies that the other tends to be below when one variable is high.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "33) What is the Pareto principle used in Statistics?",
        "answer": "The Pareto principle used in Statistics is also called the 80/20 principle or 80/20 rule. This principle specifies that 80 per cent of the results are obtained from 20 per cent of the causes in an experiment.\nFor example, you will have observed in your real life that 80 per cent of the wheat comes from the 20 per cent of the wheat plants on a farm.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "34) What type of data does not have a log-normal or Gaussian distribution?",
        "answer": "The exponential distributions types of data do not have a log-normal distribution or a Gaussian distribution. Any type of categorized data will not have these distributions as well.\nFor example, duration of a phone call, time until the next earthquake, etc.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "35) What is IQR in Statistics? How can you calculate the IQR?",
        "answer": "IQR is an acronym that stands for interquartile range. It is a measurement of the \"middle fifty\" in a data set. The IQR describes the middle 50% of values when ordered from lowest to highest.\nFollow the steps given below to find the interquartile range (IQR) in Statistics:\nFirst, find the median (middle value) of the lower and upper half of the data.\nThese values are quartile 1 (Q1) and quartile 3 (Q3).\nThe IQR is the difference between Q3 and Q1.\nIQR = Q3 - Q1\nQ3 is the third quartile (75 percentile), and Q1 is the first quartile (25 percentile).",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "36) What do you understand by the five-number summary in Statistics?",
        "answer": "In Statistics, the five-number summary is used to measure five entities covering the entire data range. It is mainly used in descriptive analysis or during the preliminary investigation of a large data set.\nThe five-number summary contains the following five values:\nLow extreme (Min)\nThe first quartile (Q1)\nMedian\nUpper quartile (Q3)\nHigh extreme (Max)\nNote: These values are selected to summarise the data set as each value describes a specific part of a data set. Here, the median specifies the centre of a data set, the upper and lower quartiles span the middle half of a data set, and the highest and lowest observations provide additional information about the actual dispersion of the data.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "37) What is the advantage of using the box plot?",
        "answer": "The box plot shows the 5-number summary pictorially. It is mainly used to compare a group of histograms.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "38) What is the difference between the 1st quartile, the 2nd quartile, and the 3rd quartile?",
        "answer": "In Statistics, quartiles are used to describe data distribution by dividing the data into three equal portions. In this partition of the data, the boundary or edge of these portions is called quartiles.\nThere are three types of quartile:\nThe lower quartile (Q1) specifies the 25th percentile of the data.\nThe middle quartile (Q2): It is also called the median and specifies the 50th percentile of the data.\nThe upper quartile (Q3) specifies the 75th percentile of the data.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "39) What do you understand by skewness?",
        "answer": "Skewness can be described as a distortion or asymmetry that deviates from a data set's symmetrical bell curve or normal distribution. You can assume it as a degree of asymmetry observed in a probability distribution.\nDepending on the varying degrees, skewness can be of two types, i.e. the right (positive) skewness and the left (negative) skewness. Skewness is centred on the mean. If skewness is negative, the data is spread more on the left of the mean than the right. If skewness is positive, the data moves more to the right. A normal distribution (bell curve) shows zero skewness.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "40) What is the difference between a left-skewed distribution and right-skewed distribution?",
        "answer": "The key difference between the left-skewed distribution and the right-skewed distribution is that the left tail is longer than the right side in the left-skewed distribution. Here, mean < median < mode. On the other hand, the right tail is longer than the right side in the right-skewed distribution. Here, mode < median < mean.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "41) What are the different types of data sampling in Statistics?",
        "answer": "There are mainly four types of data sampling in Statistics:\nSimple random: This data sampling type specifies the pure random division.\nCluster: The population is divided into clusters\nin this data sampling type.\nStratified: Data is divided into unique groups in this data sampling type.\nSystematical: This data sampling type picks up every 'n' member in the data.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "42) What is Bessel's correction? Why is it used in Statistics?",
        "answer": "In Statistics, Bessel's correction is a factor used to estimate the standard deviation of populations from its sample. It causes a less biased standard deviation and is mainly used to provide more accurate results.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "43) What is the difference between type I vs type II errors?",
        "answer": "Type I errors occur when the null hypothesis is rejected, even if true. It is also known as false positive. On the other hand, type II errors occur when the null hypothesis fails to get rejected, even if false. It is also known as a false negative.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "44) What is the relationship between the significance level and the confidence level in Statistics?",
        "answer": "In Statistics, the significance level is the probability of getting a completely different result from the condition where the null hypothesis is true. On the other hand, the confidence level is used as a range of similar values in a population.\nWe can specify the similarity between the significance level and the confidence level by the following formula:\nSignificance level = 1 - Confidence level",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "45) What do you understand by the Binomial Distribution formula?",
        "answer": "Following is the formula for the Binomial Distribution:\nb(x; n, P) = nCx * Px * (1 - P)n - x\nParameter explanation:\nb = It specifies the binomial probability.\nx = It specifies the total number of \"successes\" (pass or fail, heads or tails, etc.)\nP = It specifies the probability of success on an individual trial.\nn = It specifies the number of trials.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "46) What are the examples of symmetric distribution in Statistics?",
        "answer": "Symmetric distribution specifies that the data on the left side of the median is the same as the data on the left side of the median.\nFollowing are the three most widely used examples of symmetric distribution:\nNormal distribution\nUniform distribution\nBinomial distribution",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "47) What is the empirical rule in Statistics?",
        "answer": "In Statistics, the empirical rule is also known as the 68-95-99.7 rule. It specifies that every piece of data in a normal distribution lies within three standard deviations of the mean.\nAccording to the empirical rule,\n68% of values fall within one standard deviation of the mean.\n95% of values fall within two standard deviations of the mean.\n75% of values fall within three standard deviations of the mean.",
        "reference": "javatpoint.com",
        "role": "statistics"
    },
    {
        "question": "48) What is the relationship between mean and median in a normal distribution?",
        "answer": "Mean and median are equal in a normal distribution. So, if the distribution of a dataset is normal, the mean and median would be the same.",
        "reference": "javatpoint.com",
        "role": "statistics"
    }
]