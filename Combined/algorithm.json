[
    {
        "question": "1. How can we compare between two algorithms written for the same problem?",
        "answer": "The complexity of an algorithm is a technique that is used to categorise how efficient it is in comparison to other algorithms. It focuses on how the size of the data set to be processed affects execution time. In computing, the algorithm's computational complexity is critical. It is a good idea to categorise algorithms according to how much time or space they take up and to describe how much time or space they take up as a function of input size. Complexity of Time: The running time of a program as a function of the size of the input is known as time complexity.\nComplexity of Space: Space complexity examines algorithms based on how much space they require to fulfil their tasks. In the early days of computers, space complexity analysis was crucial (when storage space on the computer was limited). Complexity of Time: The running time of a program as a function of the size of the input is known as time complexity. Complexity of Time: Complexity of Space: Space complexity examines algorithms based on how much space they require to fulfil their tasks. In the early days of computers, space complexity analysis was crucial (when storage space on the computer was limited). Complexity of Space: Note: Nowadays, a lack of space is rarely an issue because computer storage is plentiful. Therefore, it is mostly the Time Complexity that is given more importance while evaluating an Algorithm. Note: Nowadays, a lack of space is rarely an issue because computer storage is plentiful. Therefore, it is mostly the Time Complexity that is given more importance while evaluating an Algorithm.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "2. What do you understand about the DFS (Depth First Search) algorithm.",
        "answer": "Depth First Search or DFS is a technique for traversing or exploring data structures such as trees and graphs. The algorithm starts at the root node (in the case of a graph, any random node can be used as the root node) and examines each branch as far as feasible before retracing. So the basic idea is to start at the root or any arbitrary node and mark it, then advance to the next unmarked node and repeat until there are no more unmarked nodes. After that, go back and check for any more unmarked nodes to cross. Finally, print the path's nodes. The DFS algorithm is given below: Step1: Create a recursive function that takes the node's index and a visited array as input.\nStep 2: Make the current node a visited node and print it.\nStep 3: Call the recursive function with the index of the adjacent node after traversing all nearby and unmarked nodes. Step1: Create a recursive function that takes the node's index and a visited array as input. Step 2: Make the current node a visited node and print it. Step 3: Call the recursive function with the index of the adjacent node after traversing all nearby and unmarked nodes.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "3. What do you understand about the BFS (Breadth First Search) algorithm.",
        "answer": "BFS or Breadth-First Search is a graph traversal technique. It begins by traversing the graph from the root node and explores all of the nodes in the immediate vicinity. It chooses the closest node and then visits all of the nodes that have yet to be visited. Until it reaches the objective node, the algorithm repeats the same method for each of the closest nodes. The BFS Algorithm is given below: Step 1: Set status = 1 as the first step for all the nodes(ready state).\nStep 2: Set the status of the initial node A to 2, that is, waiting state.\nStep 3: Repeat steps 4 and 5 until the queue is not empty.\nStep 4: Dequeue and process node N from the queue, setting its status to 3, that is, the processed state.\nStep 5: Put all of N's neighbours in the ready state (status = 1) in the queue and set their status to 2 (waiting state)\nStep 6: Exit. Step 1: Set status = 1 as the first step for all the nodes(ready state). Step 2: Set the status of the initial node A to 2, that is, waiting state. Step 3: Repeat steps 4 and 5 until the queue is not empty. Step 4: Dequeue and process node N from the queue, setting its status to 3, that is, the processed state. Step 5: Put all of N's neighbours in the ready state (status = 1) in the queue and set their status to 2 (waiting state) Step 6: Exit.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "4. Write down a string reversal algorithm. If the given string is \"kitiR,\" for example, the output should be \"Ritik\".",
        "answer": "An algorithm for string reversal is as follows: Step 1: Start.\nStep 2: We take two variables l and r.\nStep 3: We set the values of l as 0 and r as (length of the string  - 1).\nStep 4: We interchange the values of the characters at positions l and r in the string.\nStep 5: We increment the value of l by one.\nStep 6: We decrement the value of r by one.\nStep 7: If the value of r is greater than the value of l, we go to step 4\nStep 8: Stop. Step 1: Start. Step 2: We take two variables l and r. Step 3: We set the values of l as 0 and r as (length of the string  - 1). Step 4: We interchange the values of the characters at positions l and r in the string. Step 5: We increment the value of l by one. Step 6: We decrement the value of r by one. Step 7: If the value of r is greater than the value of l, we go to step 4 Step 8: Stop.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "5. What do you understand about the Dynamic Programming (DP) Algorithmic Paradigm? List a few problems which can be solved using the same.",
        "answer": "Dynamic Programming is primarily a recursion optimization. We can use Dynamic Programming to optimise any recursive solution that involves repeated calls for the same inputs. The goal is to simply save the results of subproblems so that we do not have to recalculate them later. The time complexity of this simple optimization is reduced from exponential to polynomial. For example, if we create a simple recursive solution for Fibonacci Numbers, the time complexity is exponential, but if we optimise it by storing subproblem answers using Dynamic Programming, the time complexity is linear.   The following codes illustrate the same: With Recursion (no DP): The time complexity of the given code will be exponential. With Recursion (no DP): /*Sample C++ code for finding nth fibonacci number without DP*/\nint nFibonacci(int n){\n   if(n == 0 || n == 1) return n;\n   else return nFibonacci(n - 1) + nFibonacci(n - 2);\n} /*Sample C++ code for finding nth fibonacci number without DP*/\nint nFibonacci(int n){\n   if(n == 0 || n == 1) return n;\n   else return nFibonacci(n - 1) + nFibonacci(n - 2);\n} /*Sample C++ code for finding nth fibonacci number without DP*/ int nFibonacci(int n) int nFibonacci (int n) int if 0 1 return else return nFibonacci 1 nFibonacci 2 With DP: The time complexity of the given code will be linear because of Dynamic Programming. With DP: /*Sample C++ code for finding nth fibonacci number with DP*/\nint nFibonacci(int n){\n   vector<int> fib(n + 1);\n    fib[0] = 0;\n    fib[1] = 1;\n    for(int i = 2;i <= n;i ++){\n         fib[i] = fib[i - 1] + fib[i - 2];\n    }\n    return fib[n]; \n} /*Sample C++ code for finding nth fibonacci number with DP*/\nint nFibonacci(int n){\n   vector<int> fib(n + 1);\n    fib[0] = 0;\n    fib[1] = 1;\n    for(int i = 2;i <= n;i ++){\n         fib[i] = fib[i - 1] + fib[i - 2];\n    }\n    return fib[n]; \n} /*Sample C++ code for finding nth fibonacci number with DP*/ int nFibonacci(int n) int nFibonacci (int n) int vector<int> fib(n + 1) int fib (n + 1) 1 0 0 1 1 for int 2 1 2 return A few problems which can be solved using the Dynamic Programming (DP) Algorithmic Paradigm are as follows: Finding the nth Fibonacci number\nFinding the Longest Common Subsequence between two strings.\nFinding the Longest Palindromic Substring in a string.\nThe discrete (or 0-1) Knapsack Problem.\nShortest Path between any two nodes in a graph (Floyd Warshall Algorithm) Finding the nth Fibonacci number Finding the Longest Common Subsequence between two strings. Finding the Longest Palindromic Substring in a string. The discrete (or 0-1) Knapsack Problem. Shortest Path between any two nodes in a graph (Floyd Warshall Algorithm)",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "6. Write an algorithm for counting the number of leaf nodes in a binary tree.",
        "answer": "An algorithm for counting the number of leaf nodes in a binary tree is given below: Step 1: If the current node is null, return a value 0.\nStep 2: If a leaf node is encountered, that is, if the current node's left and right nodes are both null, then return 1.\nStep 3: Calculate the number of leaf nodes recursively by adding the number of leaf nodes in the left subtree by the number of leaf nodes in the right subtree. Step 1: If the current node is null, return a value 0. Step 2: If a leaf node is encountered, that is, if the current node's left and right nodes are both null, then return 1. Step 3: Calculate the number of leaf nodes recursively by adding the number of leaf nodes in the left subtree by the number of leaf nodes in the right subtree.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "7. Write down an algorithm for adding a node to a linked list sorted in ascending order(maintaining the sorting property).",
        "answer": "An algorithm for adding a node to a link list sorted in ascending order (maintaining the sorting property) is given below: Step 1: Check if the linked list has no value (or is empty). If yes, then set the new node as the head and return it.\nStep 2: Check if the value of the node to be inserted is smaller than the value of the head node. If yes, place it at the beginning and make it the head node.\nStep 3: Find the suitable node after which the input node should be added in a loop. To discover the required node, begin at the head and work your way forward until you reach a node whose value exceeds the input node. The preceding node is the correct node.\nStep 4: After the correct node is found in step 3, insert the node. Step 1: Check if the linked list has no value (or is empty). If yes, then set the new node as the head and return it. Step 2: Check if the value of the node to be inserted is smaller than the value of the head node. If yes, place it at the beginning and make it the head node. Step 3: Find the suitable node after which the input node should be added in a loop. To discover the required node, begin at the head and work your way forward until you reach a node whose value exceeds the input node. The preceding node is the correct node. Step 4: After the correct node is found in step 3, insert the node.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "8. Describe the Binary Search Algorithm.",
        "answer": "To apply binary search on a list of elements, the prerequisite is that the list of elements should be sorted. It is based on the Divide and Conquers Algorithmic paradigm. In the Binary Search Algorithm, we divide the search interval in half periodically to search the sorted list. We begin by creating an interval that spans the entire list. If the search key's value is less than the item in the interval's midpoint, the interval should be narrowed to the lower half. Otherwise, we limit it to the upper half of the page. We check for the value until it is discovered or the interval is empty. Given below is an algorithm describing Binary Search: (Let us assume that the element to be searched is x and the array of elements is sorted in ascending order) Step 1: x should be firstly compared to the middle element.\nStep 2: We return the middle element's index if x matches the middle element.\nStep 3: Else If x is greater than the middle element, x can only be found after the middle element in the right half subarray since the array is sorted in the ascending order. As a result, we repeat the process for the right half.\nStep 4: Otherwise, we repeat for the left half (x is smaller).\nStep 5: If the interval is empty, we terminate the binary search. Step 1: x should be firstly compared to the middle element. Step 2: We return the middle element's index if x matches the middle element. Step 3: Else If x is greater than the middle element, x can only be found after the middle element in the right half subarray since the array is sorted in the ascending order. As a result, we repeat the process for the right half. Step 4: Otherwise, we repeat for the left half (x is smaller). Step 5: If the interval is empty, we terminate the binary search. The time complexity of the Binary Search Algorithm is O(log(n)) where n is the size of the list of elements and its space complexity is constant, that is, O(1).",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "9. Describe the Linear Search Algorithm.",
        "answer": "To find an element in a group of elements, the linear search can be used. It works by traversing the list of elements from the beginning to the end and inspecting the properties of all the elements encountered along the way. Let us consider the case of an array containing some integer elements. We want to find out and print all of the elements' positions that match a particular value (also known as the \"key\" for the linear search). The linear search works in a flow here, matching each element with the number from the beginning to the end of the list, and then printing the element's location if the element at that position is equal to the key. Given below is an algorithm describing Linear Search: Step 1: Using a loop, traverse the list of elements given.\nStep 2: In each iteration, compare the target value (or key-value) to the list's current value.\nStep 3: If the values match, print the array's current index.\nStep 4: Move on to the next array element if the values do not match.\nStep 5: Repeat Steps 1 to 4 till the end of the list of elements is reached. Step 1: Using a loop, traverse the list of elements given. Step 2: In each iteration, compare the target value (or key-value) to the list's current value. Step 3: If the values match, print the array's current index. Step 4: Move on to the next array element if the values do not match. Step 5: Repeat Steps 1 to 4 till the end of the list of elements is reached.   The time complexity of the Linear Search Algorithm is O(n) where n is the size of the list of elements and its space complexity is constant, that is, O(1).",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "10. What do you understand by a searching algorithm? List a few types of searching algorithms.",
        "answer": "Searching Algorithms are used to look for an element or get it from a data structure (usually a list of elements). These algorithms are divided into two categories based on the type of search operation: Sequential Search: This method traverses the list of elements consecutively, checking each element and reporting if the element to be searched is found. Linear Search is an example of a Sequential Search Algorithm.\nInterval Search: These algorithms were created specifically for searching sorted data structures. Because they continually target the centre of the search structure and divide the search space in half, these types of search algorithms are far more efficient than Sequential Search algorithms. Binary Search is an example of an Interval Search Algorithm. Sequential Search: This method traverses the list of elements consecutively, checking each element and reporting if the element to be searched is found. Linear Search is an example of a Sequential Search Algorithm. Sequential Search: Interval Search: These algorithms were created specifically for searching sorted data structures. Because they continually target the centre of the search structure and divide the search space in half, these types of search algorithms are far more efficient than Sequential Search algorithms. Binary Search is an example of an Interval Search Algorithm. Interval Search:",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "11. What do you understand about greedy algorithms? List a few examples of greedy algorithms.",
        "answer": "A greedy algorithm is an algorithmic method that aims to choose the best optimal decision at each sub-step, eventually leading to a globally optimal solution. This means that the algorithm chooses the best answer available at the time, regardless of the consequences. In other words, when looking for an answer, an algorithm always selects the best immediate, or local, option. Greedy algorithms may identify less than perfect answers for some cases of other problems while finding the overall, ideal solution for some idealistic problems. The Greedy algorithm is used in the following algorithms to find their solutions: Prim's Minimal Spanning Tree Algorithm\nKruskal's Minimal Spanning Tree Algorithm\nTravelling Salesman Problem\nFractional Knapsack Problem\nDijkstra's Algorithm\nJob Scheduling Problem\nGraph  Map Coloring\nGraph  Vertex Cover. Prim's Minimal Spanning Tree Algorithm Kruskal's Minimal Spanning Tree Algorithm Travelling Salesman Problem Fractional Knapsack Problem Dijkstra's Algorithm Job Scheduling Problem Graph  Map Coloring Graph  Vertex Cover.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "12. Explain the Divide and Conquer Algorithmic Paradigm. Also list a few algorithms which use this paradigm.",
        "answer": "Divide and Conquer is an algorithm paradigm, not an algorithm itself. It is set up in such a way that it can handle a large amount of data, split it down into smaller chunks, and determine the solution to the problem for each of the smaller chunks. It combines all of the piecewise solutions of the smaller chunks to form a single global solution. This is known as the divide and conquer technique. The Divide and Conquer algorithmic paradigm employ the steps given below: Divide: The algorithm separates the original problem into a set of subproblems in this step.\nConquer: The algorithm solves each subproblem individually in this step.\nCombine: In this step, the algorithm combines the solutions to the subproblems to obtain the overall solution. Divide: The algorithm separates the original problem into a set of subproblems in this step. Divide: Conquer: The algorithm solves each subproblem individually in this step. Conquer: Combine: In this step, the algorithm combines the solutions to the subproblems to obtain the overall solution. Combine:   Some of the algorithms which use the Divide and Conquer Algorithmic paradigm are as follows: Binary Search\nMerge Sort\nStrassen's Matrix Multiplication\nQuick Sort\nClosest pair of points. Binary Search Merge Sort Strassen's Matrix Multiplication Quick Sort Closest pair of points.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "13. Write an algorithm to swap two given numbers in Java without using a temporary variable.",
        "answer": "It is a trick question that is frequently asked in the interviews of various companies. This problem can be solved in a variety of ways. However, while solving the problem, we must solve it without using a temporary variable, which is an essential condition. For this problem, if we can consider the possibility of integer overflow in our solution while coming up with an approach to solving it, we can make a great impression on interviewers. Let us say that we have two integers a and b, with a's value equal to 5 and b's value equal to 6, and we want to swap them without needing a third variable. We will need to use Java programming constructs to solve this problem. Mathematical procedures such as addition, subtraction, multiplication, and division can be used to swap numbers. However, it is possible that it will cause an integer overflow problem. Let us take a look at two approaches to solve this problem: Using Addition and subtraction: Using Addition and subtraction: a = a + b;\nb = a - b; // this will act like (a+b) - b, and now b equals a.\na = a - b; // this will act like (a+b) - a, and now an equals b. a = a + b;\nb = a - b; // this will act like (a+b) - b, and now b equals a.\na = a - b; // this will act like (a+b) - a, and now an equals b. // this will act like (a+b) - b, and now b equals a. // this will act like (a+b) - a, and now an equals b. It is a clever trick. However, if the addition exceeds the maximum value of the int primitive type as defined by Integer.MAX_VALUE in Java, or if the subtraction is less than the minimum value of the int primitive type as defined by Integer.MIN_VALUE in Java, there will be an integer overflow. Using the XOR method: Using the XOR method: Another way to swap two integers without needing a third variable (temporary variable) is using the XOR method. This is often regarded as the best approach because it works in languages that do not handle integer overflows, such as Java, C, and C++. Java has a number of bitwise operators. XOR (denoted by ^) is one of them. x = x ^ y; \ny = x ^ y; \nx = x ^ y; x = x ^ y; \ny = x ^ y; \nx = x ^ y;",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "14. What do you understand by the Asymptotic Notations?",
        "answer": "Asymptotic analysis is a technique that is used for determining the efficiency of an algorithm that does not rely on machine-specific constants and avoids the algorithm from comparing itself to the time-consuming approach. For asymptotic analysis, asymptotic notation is a mathematical technique that is used to indicate the temporal complexity of algorithms. The following are the three most common asymptotic notations. Big Theta Notation: (θ Notation)\nThe exact asymptotic behaviour is defined using the theta (θ) Notation. It binds functions from above and below to define behaviour. Dropping low order terms and ignoring leading constants is a convenient approach to get Theta notation for an expression. Big Theta Notation: (θ Notation)\nThe exact asymptotic behaviour is defined using the theta (θ) Notation. It binds functions from above and below to define behaviour. Dropping low order terms and ignoring leading constants is a convenient approach to get Theta notation for an expression. Big Theta Notation: (θ Notation)    Big O Notation:\nThe Big O notation defines an upper bound for an algorithm by bounding a function from above. Consider the situation of insertion sort: in the best case scenario, it takes linear time, and in the worst case, it takes quadratic time. Insertion sort has a time complexity O(n^2). It is useful when we just have an upper constraint on an algorithm's time complexity. Big O Notation:\nThe Big O notation defines an upper bound for an algorithm by bounding a function from above. Consider the situation of insertion sort: in the best case scenario, it takes linear time, and in the worst case, it takes quadratic time. Insertion sort has a time complexity O(n^2). It is useful when we just have an upper constraint on an algorithm's time complexity. Big O Notation:    Big Omega (Ω) Notation:\nThe Ω Notation provides an asymptotic lower bound on a function, just like Big O notation does. It is useful when we have a lower bound on an algorithm's time complexity. Big Omega (Ω) Notation:\nThe Ω Notation provides an asymptotic lower bound on a function, just like Big O notation does. It is useful when we have a lower bound on an algorithm's time complexity. Big Omega (Ω) Notation:   ",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "15. What do you understand by the best case, worst case and average case scenario of an algorithm?",
        "answer": "The mathematical foundation/framing of an algorithm's run time performance is defined by asymptotic analysis. We can easily determine the best case, average case, and worst-case scenarios of an algorithm using asymptotic analysis. Best Case Scenario of an Algorithm: The best-case scenario for an algorithm is defined as the data arrangement in which the algorithm performs the best. Take a binary search, for example, where the best-case scenario is if the target value is in the very centre of the data we are looking for. The best-case scenario for binary search would have a time complexity of O(1) or constant time complexity.\nWorst Case Scenario of an Algorithm: The worst collection of input for a given algorithm is referred to as the worst-case scenario of an Algorithm. For example, quicksort can perform poorly if the pivot value is set to the largest or smallest element of a sublist. Quicksort will degenerate into an algorithm with a time complexity of O(n^2), where n is the size of the list to be sorted.\nAverage Case Scenario of an Algorithm: The average-case complexity of an algorithm is the amount of some computational resource (usually time) used by the process, averaged over all possible inputs, according to computational complexity theory. For example, the average-case complexity of the randomised quicksort algorithm is O(n*log(n)), where n is the size of the list to be sorted. Best Case Scenario of an Algorithm: The best-case scenario for an algorithm is defined as the data arrangement in which the algorithm performs the best. Take a binary search, for example, where the best-case scenario is if the target value is in the very centre of the data we are looking for. The best-case scenario for binary search would have a time complexity of O(1) or constant time complexity. Best Case Scenario of an Algorithm: Worst Case Scenario of an Algorithm: The worst collection of input for a given algorithm is referred to as the worst-case scenario of an Algorithm. For example, quicksort can perform poorly if the pivot value is set to the largest or smallest element of a sublist. Quicksort will degenerate into an algorithm with a time complexity of O(n^2), where n is the size of the list to be sorted. Worst Case Scenario of an Algorithm: Average Case Scenario of an Algorithm: The average-case complexity of an algorithm is the amount of some computational resource (usually time) used by the process, averaged over all possible inputs, according to computational complexity theory. For example, the average-case complexity of the randomised quicksort algorithm is O(n*log(n)), where n is the size of the list to be sorted. Average Case Scenario of an Algorithm:",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "1. How do the encryption algorithms work?",
        "answer": "e process of transforming plaintext into a secret code format known as \"Ciphertext'' is known as encryption. For calculations, this technique uses a string of bits known as \"keys\" to convert the text. The larger the key, the more potential patterns for producing ciphertext there are. The majority of encryption algorithms use fixed blocks of input with lengths ranging from 64 to 128 bits, while others use the stream technique.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "2. What is the space complexity of the selection sort algorithm?",
        "answer": "Selection sort is an in-place sorting method, which implies it does not require any additional or minimal data storage. Therefore, the selection sort algorithm has a constant space complexity or O(1) space complexity. Conclusion So, in conclusion, we would like to convey to our readers that the Algorithm Interviews are usually the most crucial and tough interviews of all in the Recruitment process of a lot of Software Companies and a sound understanding of Algorithms usually implies that the candidate is very good in logical thinking and has the ability to think out of the box. Algorithm interview questions can be easily solved if one has a sound understanding of Algorithms and has gone through a lot of Algorithm Examples and Algorithm MCQs (which we will be covering in the next section of this article). Therefore, we suggest to all the budding coders of today to develop a strong grasp on the various Algorithms that have been discovered to date so that they can ace their next Technical Interviews. Useful Resources: Useful Resources: Data Structures and Algorithms\nData Structures Interview Questions\nBest Data Structures and Algorithms Books\nBest Courses for Data Structures and Algorithms\nData Structure MCQ With Answers\nTechnical Interview Questions\nCoding Interview Questions Data Structures and Algorithms Data Structures and Algorithms Data Structures Interview Questions Data Structures Interview Questions Best Data Structures and Algorithms Books Best Data Structures and Algorithms Books Best Courses for Data Structures and Algorithms Best Courses for Data Structures and Algorithms Data Structure MCQ With Answers Data Structure MCQ With Answers Technical Interview Questions Technical Interview Questions Coding Interview Questions Coding Interview Questions",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "3. What is the space complexity of the insertion sort algorithm?",
        "answer": "Insertion sort is an in-place sorting method, which implies it does not require any additional or minimal data storage. In insertion sort, only a single list element must be stored outside of the starting data, resulting in a constant space complexity or O(1) space complexity.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "4. Describe the heap sort algorithm.",
        "answer": "Heap sort is a comparison-based sorting algorithm. Heapsort is similar to selection sort in that it separates its input into a sorted and an unsorted region, then successively decreases the unsorted part by taking the largest element from it and putting it into the sorted region. Unlike selection sort, heapsort does not waste time scanning the unsorted region in linear time; instead, heap sort keeps the unsorted region in a heap data structure to identify the largest element in each step more rapidly. Let us take a look at the heap sort algorithm: The Heapsort algorithm starts by converting the list to a max heap. The algorithm then swaps the first and last values in the list, reducing the range of values considered in the heap operation by one, and filters the new first value into its heap place. This process is repeated until the range of values considered is only one value long. On the list, use the buildMaxHeap() function. This function, also known as heapify(), creates a heap from a list in O(n) operations.\nChange the order of the list's first and last elements. Reduce the list's considered range by one.\nTo sift the new initial member to its appropriate index in the heap, use the siftDown() function on the list.\nUnless the list's considered range is one element, proceed to step 2. On the list, use the buildMaxHeap() function. This function, also known as heapify(), creates a heap from a list in O(n) operations. Change the order of the list's first and last elements. Reduce the list's considered range by one. To sift the new initial member to its appropriate index in the heap, use the siftDown() function on the list. Unless the list's considered range is one element, proceed to step 2. Note: The buildMaxHeap() operation runs only one time with a linear time complexity or O(n) time complexity. The siftDown() function works in O(log n) time complexity, and is called n times. Therefore, the overall time complexity of the heap sort algorithm is O(n + n log (n)) = O(n log n). Note: The buildMaxHeap() operation runs only one time with a linear time complexity or O(n) time complexity. The siftDown() function works in O(log n) time complexity, and is called n times. Therefore, the overall time complexity of the heap sort algorithm is O(n + n log (n)) = O(n log n).",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "5. Define tree traversal and list some of the algorithms to traverse a binary tree.",
        "answer": "The process of visiting all the nodes of a tree is known as tree traversal. Some of the algorithms to traverse a binary tree are as follows: Pre-order Traversal.\nIn order Traversal.\nPost order Traversal.\nBreadth First Search\nZigZag Traversal. Pre-order Traversal. In order Traversal. Post order Traversal. Breadth First Search ZigZag Traversal.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "6. Define insertion sort and selection sort.",
        "answer": "Insertion sort: Insertion sort separates the list into sorted and unsorted sub-lists. It inserts one element at a time into the proper spot in the sorted sub-list. After insertion, the output is a sorted sub-list. It iteratively works on all the elements of an unsorted sub-list and inserts them into a sorted sub-list in order.\nSelection sort: Selection sort is an in-place sorting technique. It separates the data collection into sorted and unsorted sub-lists. The minimum element from the unsorted sub-list is then selected and placed in the sorted list. This loops until all of the elements in the unsorted sub-list have been consumed by the sorted sub-list. Insertion sort: Insertion sort separates the list into sorted and unsorted sub-lists. It inserts one element at a time into the proper spot in the sorted sub-list. After insertion, the output is a sorted sub-list. It iteratively works on all the elements of an unsorted sub-list and inserts them into a sorted sub-list in order. Insertion sort: Selection sort: Selection sort is an in-place sorting technique. It separates the data collection into sorted and unsorted sub-lists. The minimum element from the unsorted sub-list is then selected and placed in the sorted list. This loops until all of the elements in the unsorted sub-list have been consumed by the sorted sub-list. Selection sort: Note: Both sorting strategies keep two sub-lists, sorted and unsorted, and place one element at a time into the sorted sub-list. Insertion sort takes the currently selected element and places it in the sorted array at the right point while keeping the insertion sort attributes. Selection sort, on the other hand, looks for the smallest element in an unsorted sub-list and replaces it with the current element. Note: Both sorting strategies keep two sub-lists, sorted and unsorted, and place one element at a time into the sorted sub-list. Insertion sort takes the currently selected element and places it in the sorted array at the right point while keeping the insertion sort attributes. Selection sort, on the other hand, looks for the smallest element in an unsorted sub-list and replaces it with the current element.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "7. Devise an algorithm to insert a node in a Binary Search Tree.",
        "answer": "An algorithm to insert a node in a Binary Search Tree is given below: Assign the current node to the root node.\nIf the root node's value is greater than the value that has to be added:\nIf the root node has a left child, go to the left.\nInsert node here if it does not have a left child.\nIf the root node's value is less than the value that has to be added:\nIf the root node has a right child, go to the right.\nInsert node here if it does not have the right child. Assign the current node to the root node. If the root node's value is greater than the value that has to be added:\nIf the root node has a left child, go to the left.\nInsert node here if it does not have a left child. If the root node has a left child, go to the left.\nInsert node here if it does not have a left child. If the root node has a left child, go to the left. Insert node here if it does not have a left child. If the root node's value is less than the value that has to be added:\nIf the root node has a right child, go to the right.\nInsert node here if it does not have the right child. If the root node has a right child, go to the right.\nInsert node here if it does not have the right child. If the root node has a right child, go to the right. Insert node here if it does not have the right child.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "8. What are recursive algorithms? State the important rules which every recursive algorithm must follow.",
        "answer": "Recursive algorithm is a way of tackling a difficult problem by breaking it down into smaller and smaller subproblems until the problem is small enough to be solved quickly. It usually involves a function that calls itself (property of recursive functions). The three laws which must be followed by all recursive algorithms are as follows: There should be a base case.\nIt is necessary for a recursive algorithm to call itself.\nThe state of a recursive algorithm must be changed in order for it to return to the base case. There should be a base case. It is necessary for a recursive algorithm to call itself. The state of a recursive algorithm must be changed in order for it to return to the base case.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "9. Can we use the binary search algorithm for linked lists? Justify your answer.",
        "answer": "No, we cannot use the binary search algorithm for linked lists. \nExplanation: Because random access is not allowed in linked lists, reaching the middle element in constant or O(1) time is impossible. As a result, the usage of a binary search algorithm on a linked list is not possible.  Explanation:",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "10. Explain the Dijkstra's Algorithm to find the shortest path between a given node in a graph to any other node in the graph.",
        "answer": "Dijkstra's algorithm is a method for determining the shortest pathways between nodes in a graph, which might be used to depict road networks. Edsger W. Dijkstra, a computer scientist, conceived it in 1956 and published it three years later. There are numerous variations of the algorithm. The original Dijkstra algorithm discovered the shortest path between two nodes, but a more frequent form fixes a single node as the \"source\" node and finds the shortest pathways from the source to all other nodes in the network, resulting in a shortest-path tree. Let us take a look at Dijkstra's Algorithm to find the shortest path between a given node in a graph to any other node in the graph: Let us call the node where we are starting the process as the initial node. Let the distance from the initial node to Y be the distance of node Y. Dijkstra's algorithm will begin with unlimited distances and attempt to improve them incrementally. Step 1: Mark all nodes that have not been visited yet. The unvisited set is a collection of all the nodes that have not been visited yet.\nStep 2: Assign a tentative distance value to each node: set it to zero for our first node and infinity for all others. The length of the shortest path discovered so far between the node v and the initial node is the tentative distance of a node v. Because no other vertex other than the source (which is a path of length zero) is known at the start, all other tentative distances are set to infinity. Set the current node to the beginning node.\nStep 3: Consider all of the current node's unvisited neighbours and determine their approximate distances through the current node. Compare the newly calculated tentative distance to the current assigned value and choose the one that is less. If the present node A has a distance of 5 and the edge linking it to a neighbour B has a length of 3, the distance to B through A will be 5 +3 = 8. Change B to 8 if it was previously marked with a distance greater than 8. If this is not the case, the current value will be retained.\nStep 4: Mark the current node as visited and remove it from the unvisited set once we have considered all of the current node's unvisited neighbours. A node that has been visited will never be checked again.\nStop if the destination node has been marked visited (when planning a route between two specific nodes) or if the smallest tentative distance between the nodes in the unvisited set is infinity (when planning a complete traversal; occurs when there is no connection between the initial node and the remaining unvisited nodes). The algorithm is now complete.\nStep 5: Otherwise, return to step 3 and select the unvisited node indicated with the shortest tentative distance as the new current node. Step 1: Mark all nodes that have not been visited yet. The unvisited set is a collection of all the nodes that have not been visited yet. Step 2: Assign a tentative distance value to each node: set it to zero for our first node and infinity for all others. The length of the shortest path discovered so far between the node v and the initial node is the tentative distance of a node v. Because no other vertex other than the source (which is a path of length zero) is known at the start, all other tentative distances are set to infinity. Set the current node to the beginning node. Step 3: Consider all of the current node's unvisited neighbours and determine their approximate distances through the current node. Compare the newly calculated tentative distance to the current assigned value and choose the one that is less. If the present node A has a distance of 5 and the edge linking it to a neighbour B has a length of 3, the distance to B through A will be 5 +3 = 8. Change B to 8 if it was previously marked with a distance greater than 8. If this is not the case, the current value will be retained. Step 4: Mark the current node as visited and remove it from the unvisited set once we have considered all of the current node's unvisited neighbours. A node that has been visited will never be checked again. Stop if the destination node has been marked visited (when planning a route between two specific nodes) or if the smallest tentative distance between the nodes in the unvisited set is infinity (when planning a complete traversal; occurs when there is no connection between the initial node and the remaining unvisited nodes). The algorithm is now complete. Step 5: Otherwise, return to step 3 and select the unvisited node indicated with the shortest tentative distance as the new current node.   It is not required to wait until the target node is \"visited\" as described above while constructing a route: the algorithm can end once the destination node has the least tentative distance among all \"unvisited\" nodes (and thus could be selected as the next \"current\"). For arbitrary directed graphs with unbounded non-negative weights, Dijkstra's algorithm is asymptotically the fastest known single-source shortest path algorithm with time complexity of O(|E| + |V|log(|V|)), where  |V| is the number of nodes and|E| is the number of edges in the graph.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "11. Write an algorithm to find the maximum subarray sum for a given array. In other words, find the maximum sum that can be achieved by taking contiguous elements from a given array of integers.",
        "answer": "Kadane's algorithm can be used to find the maximum subarray sum for a given array.  From left to right, Kadane's algorithm searches the provided array. It then computes the subarray with the largest sum ending at position j in the jth step, and this sum is stored in the variable \"currentSum\". Furthermore, it computes the subarray with the biggest sum anywhere in the subarray starting from the first position to the jth position, that is, in A[1...j], and stores it in the variable \"bestSum\". This is done by taking the maximum value of the variable \"currentSum\" till now and then storing it in the variable \"bestSum\".  In the end, the value of \"bestSum\" is returned as the final answer to our problem. Formally, Kadane's algorithm can be stated as follows: Step 1: Initialize the following variables:\nbestSum = INT_MIN\ncurrentSum = 0 // for empty subarray, it is initialized as value 0\nStep 2: Loop for each element of the array A\n(a) currentSum  = currentSum  + A[i]\n(b) if(bestSum < currentSum)\n           bestSum = currentSum \n(c) if(currentSum  < 0)\n           currentSum = 0\nStep 3: return bestSum Step 1: Initialize the following variables:\nbestSum = INT_MIN\ncurrentSum = 0 // for empty subarray, it is initialized as value 0 bestSum = INT_MIN\ncurrentSum = 0 // for empty subarray, it is initialized as value 0 bestSum = INT_MIN currentSum = 0 // for empty subarray, it is initialized as value 0 Step 2: Loop for each element of the array A\n(a) currentSum  = currentSum  + A[i]\n(b) if(bestSum < currentSum)\n           bestSum = currentSum \n(c) if(currentSum  < 0)\n           currentSum = 0 (a) currentSum  = currentSum  + A[i]\n(b) if(bestSum < currentSum)\n           bestSum = currentSum \n(c) if(currentSum  < 0)\n           currentSum = 0 (a) currentSum  = currentSum  + A[i] (b) if(bestSum < currentSum)\n           bestSum = currentSum  (c) if(currentSum  < 0)\n           currentSum = 0  Step 3: return bestSum",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "12. Describe the bubble sort algorithm with the help of an example.",
        "answer": "Bubble sort, also known as sinking sort, is a basic sorting algorithm that iterates through a list, comparing neighbouring elements and swapping them if they are out of order. The list is sent through again and again until it is sorted. The comparison sort method is named from the manner that smaller or larger components \"bubble\" to the top of the list. This simplistic method performs badly in real-world situations and is mostly used as a teaching aid. Let us take an example to understand how bubble sort works: Let us assume that the array to be sorted is (50 10 40 20 80). The various passes or rounds of bubble sort are given below: First Pass:\n(50 10 40 20 80) –> ( 10 50 40 20 80 ), Since 50 > 10, the algorithm compares the first two elements and swaps them.\n( 10 50 40 20 80 ) –>  ( 10 40 50 20 80 ), Since 50 > 40, the algorithm swaps the values at the second and third positions.\n(10 40 50 20 80) –> (10 40 20 50 80), Since 50 > 3, the algorithm swaps the third and fourth elements.\n(10 40 20 50 80) -> ( 10 40 20 50 80 ), The method does not swap the fourth and fifth elements because they are already in order (80 > 50).\nSecond Pass:\n( 10 40 20 50 80 ) –> ( 10 40 20 50 80 ) , Elements at first and second position are in order so now swapping.\n( 10 40 20 50 80 ) –> ( 10 20 40 50 80 ), Since 40 > 20, the algorithm swaps the values at the second and third positions.\n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping.\n( 10 20 40 50 80 ) –>  ( 10 20 40 50 80 ), Elements at fourth and fifth position are in order so now swapping. First Pass:\n(50 10 40 20 80) –> ( 10 50 40 20 80 ), Since 50 > 10, the algorithm compares the first two elements and swaps them.\n( 10 50 40 20 80 ) –>  ( 10 40 50 20 80 ), Since 50 > 40, the algorithm swaps the values at the second and third positions.\n(10 40 50 20 80) –> (10 40 20 50 80), Since 50 > 3, the algorithm swaps the third and fourth elements.\n(10 40 20 50 80) -> ( 10 40 20 50 80 ), The method does not swap the fourth and fifth elements because they are already in order (80 > 50). First Pass: (50 10 40 20 80) –> ( 10 50 40 20 80 ), Since 50 > 10, the algorithm compares the first two elements and swaps them.\n( 10 50 40 20 80 ) –>  ( 10 40 50 20 80 ), Since 50 > 40, the algorithm swaps the values at the second and third positions.\n(10 40 50 20 80) –> (10 40 20 50 80), Since 50 > 3, the algorithm swaps the third and fourth elements.\n(10 40 20 50 80) -> ( 10 40 20 50 80 ), The method does not swap the fourth and fifth elements because they are already in order (80 > 50). (50 10 40 20 80) –> ( 10 50 40 20 80 ), Since 50 > 10, the algorithm compares the first two elements and swaps them. ( 10 50 40 20 80 ) –>  ( 10 40 50 20 80 ), Since 50 > 40, the algorithm swaps the values at the second and third positions. (10 40 50 20 80) –> (10 40 20 50 80), Since 50 > 3, the algorithm swaps the third and fourth elements. (10 40 20 50 80) -> ( 10 40 20 50 80 ), The method does not swap the fourth and fifth elements because they are already in order (80 > 50). Second Pass:\n( 10 40 20 50 80 ) –> ( 10 40 20 50 80 ) , Elements at first and second position are in order so now swapping.\n( 10 40 20 50 80 ) –> ( 10 20 40 50 80 ), Since 40 > 20, the algorithm swaps the values at the second and third positions.\n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping.\n( 10 20 40 50 80 ) –>  ( 10 20 40 50 80 ), Elements at fourth and fifth position are in order so now swapping. Second Pass: ( 10 40 20 50 80 ) –> ( 10 40 20 50 80 ) , Elements at first and second position are in order so now swapping.\n( 10 40 20 50 80 ) –> ( 10 20 40 50 80 ), Since 40 > 20, the algorithm swaps the values at the second and third positions.\n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping.\n( 10 20 40 50 80 ) –>  ( 10 20 40 50 80 ), Elements at fourth and fifth position are in order so now swapping. ( 10 40 20 50 80 ) –> ( 10 40 20 50 80 ) , Elements at first and second position are in order so now swapping. ( 10 40 20 50 80 ) –> ( 10 20 40 50 80 ), Since 40 > 20, the algorithm swaps the values at the second and third positions. ( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping. ( 10 20 40 50 80 ) –>  ( 10 20 40 50 80 ), Elements at fourth and fifth position are in order so now swapping. The array is now sorted, but our algorithm is unsure whether it is complete. To know if the algorithm is sorted, it must complete one complete pass without any swaps. Third Pass: \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the first and second position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the second and third position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 5 80 ), Elements at the fourth and fifth position are in order so now swapping. Third Pass: \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the first and second position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the second and third position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 5 80 ), Elements at the fourth and fifth position are in order so now swapping. Third Pass: ( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the first and second position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the second and third position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping. \n( 10 20 40 50 80 ) –> ( 10 20 40 5 80 ), Elements at the fourth and fifth position are in order so now swapping. ( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the first and second position are in order so now swapping. ( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the second and third position are in order so now swapping. ( 10 20 40 50 80 ) –> ( 10 20 40 50 80 ), Elements at the third and fourth position are in order so now swapping. ( 10 20 40 50 80 ) –> ( 10 20 40 5 80 ), Elements at the fourth and fifth position are in order so now swapping.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "13. Describe the quick sort algorithm.",
        "answer": "Quicksort is a sorting algorithm that is in place (in-place algorithm is an algorithm that transforms input using no auxiliary data structure). It was created by the British computer scientist Tony Hoare in 1959 and was published in 1961, and it is still a popular sorting algorithm. It can be somewhat quicker than merge sort and two or three times faster than heapsort when properly done. Quicksort is based on the divide and conquer algorithmic paradigm. It operates by picking a 'pivot' element from the array and separating the other elements into two subarrays based on whether they are greater or less than the pivot. As a result, it is also known as partition exchange sort. The subarrays are then recursively sorted. This can be done in place, with only a little amount of additional RAM (Random Access Memory) required for sorting. Quicksort is a comparison sorting algorithm, which means it can sort objects of any type that have a \"less-than\" relation (technically, a total order) declared for them. Quicksort is not a stable sort, which means that the relative order of equal sort items is not retained in efficient implementations. Quicksort (like the partition method) must be written in such a way that it can be called for a range within a bigger array, even if the end purpose is to sort the entire array, due to its recursive nature. The following are the steps for in-place quicksort: If there are less than two elements in the range, return immediately because there is nothing else to do. A special-purpose sorting algorithm may be used for other very small lengths, and the rest of these stages may be avoided.\nOtherwise, choose a pivot value, which is a value that occurs in the range (the precise manner of choice depends on the partition routine, and can involve randomness).\nPartition the range by reordering its elements while determining a point of division so that all elements with values less than the pivot appear before the division and all elements with values greater than the pivot appear after it; elements with values equal to the pivot can appear in either direction. Most partition procedures ensure that the value that ends up at the point of division is equal to the pivot, and is now in its ultimate location because at least one instance of the pivot is present (but termination of quicksort does not depend on this, as long as sub-ranges strictly smaller than the original are produced).\nApply the quicksort recursively to the sub-range up to the point of division and the sub-range after it, optionally removing the element equal to the pivot at the point of division from both ranges. (If the partition creates a potentially bigger sub-range near the boundary with all elements known to be equal to the pivot, these can also be omitted.) If there are less than two elements in the range, return immediately because there is nothing else to do. A special-purpose sorting algorithm may be used for other very small lengths, and the rest of these stages may be avoided. Otherwise, choose a pivot value, which is a value that occurs in the range (the precise manner of choice depends on the partition routine, and can involve randomness). Partition the range by reordering its elements while determining a point of division so that all elements with values less than the pivot appear before the division and all elements with values greater than the pivot appear after it; elements with values equal to the pivot can appear in either direction. Most partition procedures ensure that the value that ends up at the point of division is equal to the pivot, and is now in its ultimate location because at least one instance of the pivot is present (but termination of quicksort does not depend on this, as long as sub-ranges strictly smaller than the original are produced). Apply the quicksort recursively to the sub-range up to the point of division and the sub-range after it, optionally removing the element equal to the pivot at the point of division from both ranges. (If the partition creates a potentially bigger sub-range near the boundary with all elements known to be equal to the pivot, these can also be omitted.) Quicksort's mathematical analysis reveals that, on average, it takes O(nlog (n) time complexity to sort n items. In the worst-case scenario, it performs in time complexity of O(n^2). Note: The algorithm's performance can be influenced by the partition routine (including the pivot selection) and other details not fully defined above, possibly to a large extent for specific input arrays. It is therefore crucial to define these alternatives before discussing quicksort's efficiency. Note: The algorithm's performance can be influenced by the partition routine (including the pivot selection) and other details not fully defined above, possibly to a large extent for specific input arrays. It is therefore crucial to define these alternatives before discussing quicksort's efficiency.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "14. Describe the merge sort algorithm.",
        "answer": "Merge sort (also known as mergesort) is a general-purpose, comparison-based sorting algorithm developed in computer science. The majority of its implementations result in a stable sort, which indicates that the order of equal elements in the input and output is the same. In 1945, John von Neumann devised the merge sort method, which is a divide and conquer algorithm. The following is how a merge sort works conceptually: Separate the unsorted list into n sublists, each with one element (a list of one element is considered sorted).\nMerge sublists repeatedly to create new sorted sublists until only one sublist remains. The sorted list will be displayed then. Separate the unsorted list into n sublists, each with one element (a list of one element is considered sorted). Merge sublists repeatedly to create new sorted sublists until only one sublist remains. The sorted list will be displayed then. The time complexity of the Merge Sort Algorithm is O(nlog(n)) where n is the size of the list of the elements to be sorted while the space complexity of the Merge Sort Algorithm is O(n), that is, linear space complexity.  ",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "15. What are few of the most widely used cryptographic algorithms?",
        "answer": "A few of the most widely used cryptographic algorithms are as follows: IDEA\nCAST\nCMEA\n3-way\nBlowfish\nGOST\nLOKI\nDES and Triple DES. IDEA CAST CMEA 3-way Blowfish GOST LOKI DES and Triple DES.",
        "reference": "interviewbit.com",
        "role": "algorithm"
    },
    {
        "question": "1) What is an algorithm? What is the need for an algorithm?",
        "answer": "An algorithm is a well-defined computational procedure that takes some values or the set of values, as an input and produces a set of values or some values, as an output.\nNeed for Algorithm\nADVERTISEMENT\nThe algorithm provides the basic idea of the problem and an approach to solve it. Some reasons to use an algorithm are as follows.\nADVERTISEMENT\nThe algorithm improves the efficiency of an existing technique.\nTo compare the performance of the algorithm with respect to other techniques.\nThe algorithm gives a strong description of requirements and goal of the problems to the designer.\nThe algorithm provides a reasonable understanding of the flow of the program.\nThe algorithm measures the performance of the methods in different cases (Best cases, worst cases, average cases).\nThe algorithm identifies the resources (input/output, memory) cycles required by the algorithm.\nWith the help of an algorithm, we can measure and analyze the complexity time and space of the problems.\nThe algorithm also reduces the cost of design.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "2) What is the Complexity of Algorithm?",
        "answer": "The complexity of the algorithm is a way to classify how efficient an algorithm is compared to alternative ones. Its focus is on how execution time increases with the data set to be processed. The computational complexity of the algorithm is important in computing.\nIt is very suitable to classify algorithm based on the relative amount of time or relative amount of space they required and specify the growth of time/ space requirement as a function of input size.\nTime complexity\nTime complexity is a Running time of a program as a function of the size of the input.\nSpace complexity\nSpace complexity analyzes the algorithms, based on how much space an algorithm needs to complete its task. Space complexity analysis was critical in the early days of computing (when storage space on the computer was limited).\nNowadays, the problem of space rarely occurs because space on the computer is broadly enough.\nWe achieve the following types of analysis for complexity\nWorst-case: f(n)\nIt is defined by the maximum number of steps taken on any instance of size n.\nBest-case: f(n)\nIt is defined by the minimum number of steps taken on any instance of size n.\nAverage-case: f(n)\nIt is defined by the average number of steps taken on any instance of size n.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "",
        "answer": "Algorithm to reverse a string.\nStep1: start\nStep2: Take two variable i and j\n\nStep3: do length (string)-1, to set J at last position\nStep4: do string [0], to set i on the first character.\nStep5: string [i] is interchanged with string[j]\nStep6: Increment i by 1\nStep7: Increment j by 1\nStep8: if i>j then go to step3\n\nStep9: Stop",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "",
        "answer": "Algorithm to insert a node in a sorted linked list.\nCase1:\nCheck if the linked list is empty then set the node as head and return it.\nNew_node-> Next= head;  \nHead=New_node  \nCase2:\nInsert the new node in middle\nWhile( P!= insert position)  \n{  \nP= p-> Next;  \n}  \nStore_next=p->Next;  \nP->Next= New_node;  \nNew_Node->Next = Store_next;  \nCase3:\nInsert a node at the end\nWhile (P->next!= null)  \n{  \nP= P->Next;  \n}  \nP->Next = New_Node;  \nNew_Node->Next = null;",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "5) What are the Asymptotic Notations?",
        "answer": "Asymptotic analysis is used to measure the efficiency of an algorithm that doesn't depend on machine-specific constants and prevents the algorithm from comparing the time taking algorithm. Asymptotic notation is a mathematical tool that is used to represent the time complexity of algorithms for asymptotic analysis.\nThe three most used asymptotic notation is as follows.\nθ Notation\nθ Notation defines the exact asymptotic behavior. To define a behavior, it bounds functions from above and below. A convenient way to get Theta notation of an expression is to drop low order terms and ignore leading constants.\n\nBig O Notation\nThe Big O notation bounds a function from above, it defines an upper bound of an algorithm. Let's consider the case of insertion sort; it takes linear time in the best case and quadratic time in the worst case. The time complexity of insertion sort is O(n2). It is useful when we only have upper bound on time complexity of an algorithm.\n\nΩ Notation\nJust like Big O notation provides an asymptotic upper bound, the Ω Notation provides an asymptotic lower bound on a function. It is useful when we have lower bound on time complexity of an algorithm.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "6) Explain the Bubble sort algorithm?",
        "answer": "Bubble sort is the simplest sorting algorithm among all sorting algorithm. It repeatedly works by swapping the adjacent elements if they are in the wrong order.\ne.g.\n(72538) we have this array for sorting.\nPass1:\n(72538) -> (27538) swap 7 and 2.\n(27538) -> (25738) swap 7 and 5.\n(25738) -> (25378) swap 7 and 3.\n(25378) -> (25378) algorithm does not swap 7 and 8 because 7<8.\nPass2:\n(25378) -> (25378) algorithm does not swap 2 and 5 because 2<5.\n(25378) -> (23578) swap 3 and 5.\n(23578) -> (23578) algorithm does not swap 5 and 7 because 5<7.\n(23578) -> (23578) algorithm does not swap 7 and 8 because 7<8.\nHere, the sorted element is (23578).",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "7) How to swap two integers without swapping the temporary variable in Java?",
        "answer": "It's a very commonly asked trick question. There are many ways to solve this problem.\nBut the necessary condition is we have to solve it without swapping the temporary variable.\nIf we think about integer overflow and consider its solution, then it creates an excellent impression in the eye of interviewers.\nSuppose we have two integers I and j, the value of i=7 and j=8 then how will you swap them without using a third variable. This is a journal problem.\nWe need to do this using Java programming constructs. We can swap numbers by performing some mathematical operations like addition, subtraction, multiplication, and division. But maybe it will create the problem of integer overflow.\nUsing addition and subtraction\na= a + b;  \nb=a - b; // this will act like (a+b)-b, now b is equal to a.  \na=a - b; // (a+b)-a, now, a is equal to b.  \nIt is a nice trick. But in this trick, the integer will overflow if the addition is more than the maximum value of int primitive as defined by Integer.MAX_VALUE and if subtraction is less than minimum value i.e., Integer.MIN_VALUE.\nUsing XOR trick\nAnother solution to swap two integers without using a third variable (temp variable) is widely recognized as the best solution, as it will also work in a language which doesn't handle integer overflow like Java example C, C++. Java supports several bitwise operators. One of them is XOR (denoted by ^).\nx=x^y;  \ny=x^y;  \nx=x^y;",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "8) What is a Hash Table? How can we use this structure to find all anagrams in a dictionary?",
        "answer": "A Hash table is a data structure for storing values to keys of arbitrary type. The Hash table consists of an index into an array by using a Hash function. Indexes are used to store the elements. We assign each possible element to a bucket by using a hash function. Multiple keys can be assigned to the same bucket, so all the key and value pairs are stored in lists within their respective buckets. Right hashing function has a great impact on performance.\nTo find all anagrams in a dictionary, we have to group all words that contain the same set of letters in them. So, if we map words to strings representing their sorted letters, then we could group words into lists by using their sorted letters as a key.\nFUNCTION find_anagrams(words)  \n    word_groups = HashTable<String, List>  \n    FOR word IN words  \n        word_groups.get_or_default(sort(word), []).push(word)  \n    END FOR  \n    anagrams = List  \n    FOR key, value IN word_groups  \n        anagrams.push(value)  \n    END FOR  \n    RETURN anagrams  \nThe hash table contains lists mapped to strings. For each word, we add it to the list at the suitable key, or create a new list and add it to it.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "9) What is Divide and Conquer algorithms?",
        "answer": "Divide and Conquer is not an algorithm; it's a pattern for the algorithm. It is designed in a way as to take dispute on a huge input, break the input into minor pieces, and decide the problem for each of the small pieces. Now merge all of the piecewise solutions into a global solution. This strategy is called divide and conquer.\nDivide and conquer uses the following steps to make a dispute on an algorithm.\nDivide: In this section, the algorithm divides the original problem into a set of subproblems.\nConquer: In this section, the algorithm solves every subproblem individually.\nCombine: In this section, the algorithm puts together the solutions of the subproblems to get the solution to the whole problem.\n10) Explain the BFS algorithm?\nBFS (Breadth First Search) is a graph traversal algorithm. It starts traversing the graph from the root node and explores all the neighboring nodes. It selects the nearest node and visits all the unexplored nodes. The algorithm follows the same procedure for each of the closest nodes until it reaches the goal state.\nAlgorithm\nStep1: Set status=1 (ready state)\n\nStep2: Queue the starting node A and set its status=2, i.e. (waiting state)\nStep3: Repeat steps 4 and 5 until the queue is empty.\nStep4: Dequeue a node N and process it and set its status=3, i.e. (processed state)\nStep5: Queue all the neighbors of N that are in the ready state (status=1) and set their status =2 (waiting state)\n[Stop Loop]\nStep6: Exit",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "10) Explain the BFS algorithm?",
        "answer": "BFS (Breadth First Search) is a graph traversal algorithm. It starts traversing the graph from the root node and explores all the neighboring nodes. It selects the nearest node and visits all the unexplored nodes. The algorithm follows the same procedure for each of the closest nodes until it reaches the goal state.\nAlgorithm\nStep1: Set status=1 (ready state)\n\nStep2: Queue the starting node A and set its status=2, i.e. (waiting state)\nStep3: Repeat steps 4 and 5 until the queue is empty.\nStep4: Dequeue a node N and process it and set its status=3, i.e. (processed state)\nStep5: Queue all the neighbors of N that are in the ready state (status=1) and set their status =2 (waiting state)\n[Stop Loop]\nStep6: Exit",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "11) What is Dijkstra's shortest path algorithm?",
        "answer": "Dijkstra's algorithm is an algorithm for finding the shortest path from a starting node to the target node in a weighted graph. The algorithm makes a tree of shortest paths from the starting vertex and source vertex to all other nodes in the graph.\nSuppose you want to go from home to office in the shortest possible way. You know some roads are heavily congested and challenging to use this, means these edges have a large weight. In Dijkstra's algorithm, the shortest path tree found by the algorithm will try to avoid edges with larger weights.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "12) Give some examples of Divide and Conquer algorithm?",
        "answer": "Some problems that use Divide and conquer algorithm to find their solution are listed below.\nMerge Sort\nQuick Sort\nBinary Search\nStrassen's Matrix Multiplication\nClosest pair (points)",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "13) What are Greedy algorithms? Give some example of it?",
        "answer": "A greedy algorithm is an algorithmic strategy which is made for the best optimal choice at each sub stage with the goal of this, eventually leading to a globally optimum solution. This means that the algorithm chooses the best solution at the moment without regard for consequences.\nIn other words, an algorithm that always takes the best immediate, or local, solution while finding an answer.\nGreedy algorithms find the overall, ideal solution for some idealistic problems, but may discover less-than-ideal solutions for some instances of other problems.\nBelow is a list of algorithms that finds their solution with the use of the Greedy algorithm.\nTravelling Salesman Problem\nPrim's Minimal Spanning Tree Algorithm\nKruskal's Minimal Spanning Tree Algorithm\nDijkstra's Minimal Spanning Tree Algorithm\nGraph - Map Coloring\nGraph - Vertex Cover\nKnapsack Problem\nJob Scheduling Problem",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "14) What is a linear search?",
        "answer": "Linear search is used on a group of items. It relies on the technique of traversing a list from start to end by visiting properties of all the elements that are found on the way.\nFor example, suppose an array of with some integer elements. You should find and print the position of all the elements with their value. Here, the linear search acts in a flow like matching each element from the beginning of the list to the end of the list with the integer, and if the condition is `True then printing the position of the element.'\nImplementing Linear Search\nBelow steps are required to implement the linear search.\nStep1: Traverse the array using for loop.\nStep2: In every iteration, compare the target value with the current value of the array\nStep3: If the values match, return the current index of the array\nStep4: If the values do not match, shift on to the next array element.\nStep5: If no match is found, return -1",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "15) What is a Binary Search Tree?",
        "answer": "The binary search tree is a special type of data structure which has the following properties.\nNodes which are less than root will be in the left subtree.\nNodes which are greater than root (i.e., contains more value) will be right subtree.\nA binary search tree should not have duplicate nodes.\nBoth sides subtree (i.e., left and right) also should be a binary search tree.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "16) Write an algorithm to insert a node in the Binary search tree?",
        "answer": "Insert node operation is a smooth operation. You need to compare it with the root node and traverse left (if smaller) or right (if greater) according to the value of the node to be inserted.\nAlgorithm:\nMake the root node as the current node\nIf the node to be inserted < root\nIf it has left child, then traverse left\nIf it does not have left child, insert node here\nIf the node to be inserted > root\nIf it has the right child, traverse right\nIf it does not have the right child, insert node here.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "17) How to count leaf nodes of the binary tree?",
        "answer": "Algorithm-\nSteps for counting the number of leaf nodes are:\nIf the node is null (contains null values) then return 0.\nIf encountered leaf node. Left is null and node Right is null then return 1.\nRecursively calculate the number of leaf nodes using\nNo. of leaf nodes= no of leaf nodes in left subtree + number of leaf nodes in the right subtree.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "18) How to find all possible words in a board of characters (Boggle game)?",
        "answer": "In the given dictionary, a process to do a lookup in the dictionary and an M x N board where every cell has a single character. Identify all possible words that can be formed by order of adjacent characters. Consider that we can move to any of the available 8 adjacent characters, but a word should not have multiple instances of the same cell.\nExample:\ndictionary[] = {\"Java\", \"Point\",\"Quiz\"};  \nArray[][]    = {{'J', 'T', 'P',},  \n        {'U', 'A', 'A'},  \n        {'Q', 'S', 'V'}};  \nisWord(str): returns true if str is present in dictionary   \n    else false.  \nOutput:\nFollowing words of the dictionary are present\nJAVA",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "19) Write an algorithm to insert a node in a link list?",
        "answer": "Algorithm\nCheck If the Linked list does not have any value then make the node as head and return it\nCheck if the value of the node to be inserted is less than the value of the head node, then insert the node at the start and make it head.\nIn a loop, find the appropriate node after which the input node is to be inserted. To find the just node start from the head, keep forwarding until you reach a node whose value is greater than the input node. The node just before is the appropriate node.\nInsert the node after the proper node found in step 3.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "20) How to delete a node in a given link list? Write an algorithm and a program?",
        "answer": "Write a function to delete a given node from a Singly Linked List. The function must follow the following constraints:\nThe function must accept a pointer to the start node as the first argument and node to be deleted as the second argument, i.e., a pointer to head node is not global.\nThe function should not return a pointer to the head node.\nThe function should not accept pointer to pointer to head node.\nWe may assume that the Linked List never becomes empty.\nSuppose the function name is delNode(). In a direct implementation, the function needs to adjust the head pointer when the node to be deleted the first node.\nC program for deleting a node in Linked List\nWe will handle the case when the first node to be deleted then we copy the data of the next node to head and delete the next node. In other cases when a deleted node is not the head node can be handled generally by finding the previous node.\n#include <stdio.h>   \n#include <stdlib.h>   \nstruct Node   \n{     \n    int data;   \n    struct Node *next;   \n};   \n  void delNode(struct Node *head, struct Node *n)   \n{   \n    if(head == n)   \n    {     \n        if(head->next == NULL)   \n        {   \n            printf(\"list can't be made empty because there is only one node. \");   \n            return;   \n        }   \n        head->data = head->next->data;   \n        n = head->next;   \n        head->next = head->next->next;   \n        free(n);   \n        return;   \n    }   \n        struct Node *prev = head;   \n    while(prev->next != NULL && prev->next != n)   \n        prev = prev->next;   \n    if(prev->next == NULL)   \n    {   \n        printf(\"\\n This node is not present in  List\");   \n        return;   \n    }   \n    prev->next = prev->next->next;   \n    free(n);   \n    return;   \n}   \nvoid push(struct Node **head_ref, int new_data)   \n{   \n    struct Node *new_node =   \n        (struct Node *)malloc(sizeof(struct Node));   \n    new_node->data = new_data;   \n    new_node->next = *head_ref;   \n    *head_ref = new_node;   \n}   \nvoid printList(struct Node *head)   \n{   \n    while(head!=NULL)   \n    {   \n        printf(\"%d \",head->data);   \n        head=head->next;   \n    }   \n    printf(\"\\n\");   \n}   \nint main()   \n{   \n    struct Node *head = NULL;   \n    push(&head,3);   \n    push(&head,2);   \n    push(&head,6);   \n    push(&head,5);   \n    push(&head,11);   \n    push(&head,10);   \n    push(&head,15);   \n    push(&head,12);   \n    printf(\"Available Link list: \");   \n    printList(head);   \n    printf(\"\\nDelete node %d: \", head->next->next->data);   \n    delNode(head, head->next->next);   \n      printf(\"\\nUpdated  Linked List: \");   \n    printList(head);   \n      /* Let us delete the the first node */  \n    printf(\"\\nDelete first node \");   \n    delNode(head, head);   \n       printf(\"\\nUpdated Linked List: \");   \n    printList(head);   \n      getchar();   \n    return 0;   \n}  \nOutput:\nAvailable Link List: 12 15 10 11 5 6 2 3 \nDelete node 10:\nUpdated Linked List: 12 15 11 5 6 2 3\nDelete first node\nUpdated Linked list: 15 11 5 6 2 3",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "21) Write a c program to merge a link list into another at an alternate position?",
        "answer": "We have two linked lists, insert nodes of the second list into the first list at substitute positions of the first list.\nExample\nif first list is 1->2->3 and second is 12->10->2->4->6, the first list should become 1->12->2->10->17->3->2->4->6 and second list should become empty. The nodes of the second list should only be inserted when there are positions available.\nUse of extra space is not allowed i.e., insertion must be done in a place. Predictable time complexity is O(n) where n is number of nodes in first list.\n#include <stdio.h>   \n#include <stdlib.h>   \nstruct Node   \n{   \n    int data;   \n    struct Node *next;   \n};   \nvoid push(struct Node ** head_ref, int new_data)   \n{   \n    struct Node* new_node =   \n        (struct Node*) malloc(sizeof(struct Node));   \n    new_node->data = new_data;   \n    new_node->next = (*head_ref);   \n    (*head_ref) = new_node;   \n}   \nvoid printList(struct Node *head)   \n{   \n    struct Node *temp = head;   \n    while (temp != NULL)   \n    {   \n        printf(\"%d \", temp->data);   \n        temp = temp->next;   \n    }   \n    printf(\"\\n\");   \n}    \nvoid merge(struct Node *p, struct Node **q)   \n{   \n    struct Node *p_curr = p, *q_curr = *q;   \n    struct Node *p_next, *q_next;   \n    while (p_curr != NULL && q_curr != NULL)   \n    {  \n        p_next = p_curr->next;   \n        q_next = q_curr->next;   \n        q_curr->next = p_next;  \n        p_curr->next = q_curr;   \n        p_curr = p_next;   \n        q_curr = q_next;   \n    }   \n      *q = q_curr;  \n}   \nint main()   \n{   \n    struct Node *p = NULL, *q = NULL;   \n    push(&p, 3);   \n    push(&p, 2);   \n    push(&p, 1);   \n    printf(\"I Linked List:\\n\");   \n    printList(p);   \n      push(&q, 8);   \n    push(&q, 7);   \n    push(&q, 6);   \n    push(&q, 5);   \n    push(&q, 4);   \n    printf(\"II Linked List:\\n\");   \n    printList(q);   \n      merge(p, &q);   \n      printf(\"Updated I  Linked List:\\n\");   \n    printList(p);   \n      printf(\"Updated II Linked List:\\n\");   \n    printList(q);   \n            getchar();   \n    return 0;   \n}  \nOutput:\nI Linked List:        \n1 2 3\nII Linked List:      \n4 5 6 7 8                \nUpdated I Linked List:         \n1 4 2 5 3 6           \nUpdated II Linked List:          \n7 8",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "22) Explain how the encryption algorithm works?",
        "answer": "Encryption is the technique of converting plaintext into a secret code format it is also called as \"Ciphertext.\" To convert the text, the algorithm uses a string of bits called as \"keys\" for calculations. The larger the key, the higher the number of potential patterns for Encryption. Most of the algorithm use codes fixed blocks of input that have a length of about 64 to 128 bits, while some uses stream method for encryption.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "23) What Are The Criteria Of Algorithm Analysis?",
        "answer": "An algorithm is generally analyzed by two factors.\nTime complexity\nSpace complexity\nTime complexity deals with the quantification of the amount of time taken by a set of code or algorithm to process or run as a function of the amount of input. In other words, the time complexity is efficiency or how long a program function takes to process a given input.\nSpace complexity is the amount of memory used by the algorithm to execute and produce the result.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "24) What are the differences between stack and Queue?",
        "answer": "Stack and Queue both are non-primitive data structure used for storing data elements and are based on some real-world equivalent.\nLet's have a look at key differences based on the following parameters.\nWorking principle\nThe significant difference between stack and queue is that stack uses LIFO (Last in First Out) method to access and add data elements whereas Queue uses FIFO (First in first out) method to obtain data member.\nStructure\nIn Stack, the same end is used to store and delete elements, but in Queue, one end is used for insertion, i.e., rear end and another end is used for deletion of elements.\nNumber of pointers used\nStack uses one pointer whereas Queue uses two pointers (in the simple case).\nOperations performed\nStack operates as Push and pop while Queue operates as Enqueue and dequeuer.\nVariants\nStack does not have variants while Queue has variants like a circular queue, Priority queue, doubly ended Queue.\nImplementation\nThe stack is simpler while Queue is comparatively complex.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    },
    {
        "question": "25) What is the difference between the Singly Linked List and Doubly Linked List data structure?",
        "answer": "This is a traditional interview question on the data structure. The major difference between the singly linked list and the doubly linked list is the ability to traverse.\nYou cannot traverse back in a singly linked list because in it a node only points towards the next node and there is no pointer to the previous node.\nOn the other hand, the doubly linked list allows you to navigate in both directions in any linked list because it maintains two pointers towards the next and previous node.",
        "reference": "javatpoint.com",
        "role": "algorithm"
    }
]